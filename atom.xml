<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>某科学のBLOG</title>
  
  <subtitle>与其感慨路难行，不如马上出发</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://a-kali.github.io/"/>
  <updated>2019-10-26T02:06:38.439Z</updated>
  <id>http://a-kali.github.io/</id>
  
  <author>
    <name>Hsaki</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>FCN论文解读</title>
    <link href="http://a-kali.github.io/2019/10/26/FCN%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB/"/>
    <id>http://a-kali.github.io/2019/10/26/FCN论文解读/</id>
    <published>2019-10-26T02:06:38.000Z</published>
    <updated>2019-10-26T02:06:38.439Z</updated>
    
    <summary type="html">
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>RSNA Intracranial Hemorrhage Detection 比赛记录</title>
    <link href="http://a-kali.github.io/2019/10/16/RSNA-Intracranial-Hemorrhage-Detection-%E6%AF%94%E8%B5%9B%E8%AE%B0%E5%BD%95/"/>
    <id>http://a-kali.github.io/2019/10/16/RSNA-Intracranial-Hemorrhage-Detection-比赛记录/</id>
    <published>2019-10-16T07:24:54.000Z</published>
    <updated>2019-10-20T10:00:19.983Z</updated>
    
    <content type="html"><![CDATA[<div id="hbe-security">  <div class="hbe-input-container">  <input type="password" class="hbe-form-control" id="pass" placeholder="Please enter the password to read the blog." />    <label for="pass">Please enter the password to read the blog.</label>    <div class="bottom-line"></div>  </div></div><div id="decryptionError" style="display: none;">Incorrect Password!</div><div id="noContentError" style="display: none;">No content to display!</div><div id="encrypt-blog" style="display:none">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</div><script src="/lib/crypto-js.js"></script><script src="/lib/blog-encrypt.js"></script><link href="/css/blog-encrypt.css" rel="stylesheet" type="text/css">]]></content>
    
    <summary type="html">
    
      The article has been encrypted, please enter your password to view.&lt;br&gt;
    
    </summary>
    
    
      <category term="计算机视觉" scheme="http://a-kali.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/"/>
    
      <category term="Kaggle" scheme="http://a-kali.github.io/tags/Kaggle/"/>
    
      <category term="深度学习" scheme="http://a-kali.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="图片分类" scheme="http://a-kali.github.io/tags/%E5%9B%BE%E7%89%87%E5%88%86%E7%B1%BB/"/>
    
  </entry>
  
  <entry>
    <title>R-CNN, Fast R-CNN, Faster R-CNN, Mask R-CNN 系列论文解读</title>
    <link href="http://a-kali.github.io/2019/10/10/R-CNN-Fast-R-CNN-Faster-R-CNN-Mask-R-CNN-%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB/"/>
    <id>http://a-kali.github.io/2019/10/10/R-CNN-Fast-R-CNN-Faster-R-CNN-Mask-R-CNN-论文解读/</id>
    <published>2019-10-10T09:21:36.000Z</published>
    <updated>2019-10-26T02:05:18.404Z</updated>
    
    <content type="html"><![CDATA[<h1 id="R-CNN"><a href="#R-CNN" class="headerlink" title="R-CNN"></a>R-CNN</h1><p>论文地址：<a href="https://arxiv.org/pdf/1311.2524.pdf" target="_blank" rel="noopener">Rich feature hierarchies for accurate object detection and semantic segmentation</a></p><p>发布时间：2014.10.22</p><h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>伴随着AlexNet的横空出世，卷积神经网络开始进入人们的视线，R-CNN便是将卷积神经网络运用于目标检测和语义分割的一个成功典范，其在 VOC 2012 将最佳mAP提高了30%。其成绩对卷积神经网络在目标检测的运用产生了深远的影响。</p><p>但在这之前，需要解决两个主要的问题：</p><ol><li>与图片分类不同，目标检测需要在图片上定位目标的位置。那么如何利用深度的神经网络去做目标的定位？</li><li>如何在一个小规模的数据集上训练能力强劲的网络模型？</li></ol><p>R-CNN全称为Regions with CNN features，其名字来源于其主要使用的两项技术：卷积神经网络（CNN）和<strong>区域推荐</strong>（Region Proposals），而区域推荐正是第一个问题的解决方法。当时已有许多现成的区域推荐算法，本文作者使用的是<strong>选择性搜索(selective search)算法</strong>。</p><h2 id="选择性搜索"><a href="#选择性搜索" class="headerlink" title="选择性搜索"></a>选择性搜索</h2><p><img src="https://s2.ax1x.com/2019/10/25/KwZVHS.png" alt="KwZVHS.png"></p><p>大概就是根据临近颜色的相似度将左边的原图变成像右边由色块组成的图片，然后根据色块选出候选框。这样可以减少对一些不必要的区域进行卷积运算，比如左图左上角那个框。该算法被后续几代网络沿用，直到 Faster R-CNN 使用神经网络进行区域推荐。</p><h2 id="整体架构"><a href="#整体架构" class="headerlink" title="整体架构"></a>整体架构</h2><p>R-CNN整体过程如下：</p><ol><li>给定一张输入图片，使用selective search从图片中提取 2000 个类别独立的候选区域。</li><li>将每个候选区域缩放到227×227，输入到 CNN中抽取一个固定长度的特征向量。</li><li>使用<strong>各个类别对应的SVM对特征向量进行二分类</strong>，判断该候选区域是否包含该类别，之后对每个类别的窗口进行极大值抑制。</li></ol><p><img src="https://img-blog.csdnimg.cn/20181210155342586.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2JyaWJsdWU=,size_16,color_FFFFFF,t_70" alt></p><p>对于第二个问题，作者给出的解决方法是：在大型图片分类数据集ILSVRC上预训练卷积神经网络，并微调（fine-tuning）到小型目标检测数据集PASCAL上，这使得mAP上升了8个百分点。</p><p>R-CNN高效的原因：</p><ol><li>所有类别共享CNN参数</li><li>特征维度相对较小</li></ol><h1 id="SPP-Net"><a href="#SPP-Net" class="headerlink" title="SPP-Net"></a>SPP-Net</h1><p>论文地址：<a href="https://arxiv.org/abs/1406.4729" target="_blank" rel="noopener">Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition</a></p><p>发布时间：2015.4.23</p><h2 id="背景-1"><a href="#背景-1" class="headerlink" title="背景"></a>背景</h2><p>由于 CNN 需要固定大小的输入，在将图片输入到神经网络之前需要对图片进行缩放(warp)或裁剪(crop)。缩放会造成图片几何失真，而裁剪则可能损失部分目标物像素，这将会对图片识别精确度有所影响。</p><p><img src="https://s2.ax1x.com/2019/10/22/K8nKrd.png" alt="K8nKrd.png"></p><p>CNN 只能接收固定尺寸图片的原因是其全连接层节点数目固定，而其卷积层是可以接收不同尺寸的图片的。于是作者设计了用于神经网络中的 <strong>SPP</strong> (spatial pytamid pooling, 空间金字塔池化) 模块，位于卷积层和全连接层之间，用于<strong>接收任意尺寸的图片、提取其特征并产生固定大小的输出</strong>。而且实验表明，训练时使用不同尺寸的输入，可以提高测试精度。</p><h2 id="空间金字塔池化层"><a href="#空间金字塔池化层" class="headerlink" title="空间金字塔池化层"></a>空间金字塔池化层</h2><p><img src="https://s2.ax1x.com/2019/10/22/KGQ98P.png" alt="KGQ98P.png"></p><p>作者将 CNN 中的最后一个池化层用 SPP 替代。如图所示，<strong>SPP 将最后一层卷积层输出的特征图分割成不同尺寸的网格，分别为4×4、2×2、1×1，然后对每个小格进行max pooling，再将池化后的结果连接起来，就能得到（16+4+1）× 256 的固定长度的输出</strong>（这里的256为256个channel）。</p><h2 id="SPP-在目标检测中的应用"><a href="#SPP-在目标检测中的应用" class="headerlink" title="SPP 在目标检测中的应用"></a>SPP 在目标检测中的应用</h2><p>前面提到，R-CNN 在图像中选出2000个候选窗口，并将每个窗口缩放后输入到神经网络中，这样对一张图片反复使用深度卷积网络十分耗时。测试时，特征提取是其主要的时间瓶颈。</p><p>论文中提到，特征图的ROI与原图中的目标物的位置存在一定的映射关系，如下图：</p><p><img src="https://s2.ax1x.com/2019/10/22/KG6IIA.png" alt="KG6IIA.png"></p><p>于是<strong>对于一张图片，只需要提取一次特征，然后将特征图的2000个候选区域输入 SPP 模块就能得到固定长度的表示。由于只需要进行一次卷积操作，节省了大量候选区域通过神经网络的时间。</strong></p><h1 id="Fast-R-CNN"><a href="#Fast-R-CNN" class="headerlink" title="Fast R-CNN"></a>Fast R-CNN</h1><p>论文地址：<a href="https://arxiv.org/abs/1504.08083" target="_blank" rel="noopener">Fast R-CNN</a></p><p>发布时间：2015.9.27</p><h2 id="背景-2"><a href="#背景-2" class="headerlink" title="背景"></a>背景</h2><p>SPPnet 虽然对R-CNN进行了一些改进，但仍然存在许多问题：</p><ul><li>需要大量产生候选框</li><li>对目标的定位只能靠候选框来粗略定位</li><li>多阶段pipeline，特征提取、模型训练、SVM分类器训练、边框回归要分别进行</li><li>特征图要存在本地磁盘，影响速度</li></ul><p>于是 Fast R-CNN 改进了在目标检测任务中的性能，其优势如下：</p><ul><li>相比 R-CNN、SPPnet 有着更高的 mAP</li><li>单阶段(single-stage)训练，使用多任务损失(multi-task loss)</li><li>训练可以更新网络每一层的参数</li><li>无需使用磁盘缓存特征</li></ul><h2 id="架构细节和模型训练"><a href="#架构细节和模型训练" class="headerlink" title="架构细节和模型训练"></a>架构细节和模型训练</h2><p><img src="https://s2.ax1x.com/2019/10/23/KtoCi6.png" alt="KtoCi6.png"></p><p>从上图直观上来看，Fast R-CNN 与 SPPnet 的结构有两个区别：</p><ol><li>SPP模块被换成了RoI池化层</li><li>网络末端有两个输出，分别用于图像分类和边框回归。分类器被换成了softmax。使用softmax的好处在于不用单独训练一个SVM分类器；缺点在于对于一个候选框最多只能分出一类物体，即使一个候选框包含了多个类别的目标（大概）。</li></ol><p>另外值得一提的是，Fast R-CNN 采用的是固定大小的输入，而不像SPPnet使用任意大小的输入。</p><h3 id="RoI-池化层"><a href="#RoI-池化层" class="headerlink" title="RoI 池化层"></a>RoI 池化层</h3><p>RoI 池化层实质上就是单层的 SPP 模块。其将一个候选窗口划分为 H×W 的网格，对每个网格内进行最大池化，最后输出一个长度为 H×W 的特征。超参数 H 和 W 视具体网络结构而定。</p><h3 id="多任务损失"><a href="#多任务损失" class="headerlink" title="多任务损失"></a>多任务损失</h3><p>多任务损失由分类任务损失和边框回归任务损失线性组合而成：</p><script type="math/tex; mode=display">L=L_{cls}(p,u)+\lambda [u\geq 1]L_{loc}(t^u,v)\\</script><p>其中：</p><script type="math/tex; mode=display">L_{cls}(p,u)=-\log p_u\\L_{loc}(t^u,v)=\sum smooth_{L_1}(t^u_i-v_i)</script><h3 id="Mini-batch-sampling"><a href="#Mini-batch-sampling" class="headerlink" title="Mini-batch sampling"></a>Mini-batch sampling</h3><p>（其实这一段我没看太懂，以下仅作参考）</p><p>在调优(fine tuning)训练时，每个mini-batch中首先加入 N 张完整图片，从 N 张图片中选出一共 R 个 IoU&gt;0.5 的候选区域，然后将这 R 个候选区域作为训练样本放入网络训练。</p><h1 id="Faster-R-CNN"><a href="#Faster-R-CNN" class="headerlink" title="Faster R-CNN"></a>Faster R-CNN</h1><p>论文地址：<a href="https://arxiv.org/abs/1506.01497" target="_blank" rel="noopener">Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks</a></p><p>发布时间：2016.1.6</p><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>性能优越的目标检测网络都依赖区域推荐(region proposal)算法来假定目标位置，比如R-CNN中的选择搜索(search selective)算法，而这些区域推荐的计算消耗正是整个网络性能的瓶颈。本文作者引入了<strong>区域推荐网络(Region Proposal Network, RPN)</strong>，尝试使用神经网络来进行区域提取。并将 RPN 和 Fast R-CNN 融合在一起，共享卷积特征，成为一个端到端的神经网络。</p><h2 id="架构概览"><a href="#架构概览" class="headerlink" title="架构概览"></a>架构概览</h2><p><img src="https://s2.ax1x.com/2019/10/25/KdqldS.png" alt="KdqldS.png"></p><p>Fast R-CNN 大致结构如图。可以看出，网络由四步组成：</p><ol><li>输入的图片经过卷积层输出一张特征图</li><li>将特征图输入 RPN，得到候选区域</li><li>将特征图上候选区域的对应位置输入到 RoI 池化层</li><li>输入到分类器得出分类结果</li></ol><p>那么 RPN 具体是怎样的呢？</p><h2 id="RPN"><a href="#RPN" class="headerlink" title="RPN"></a>RPN</h2><p><img src="https://s2.ax1x.com/2019/10/25/KdIwZQ.png" alt="KdIwZQ.png"></p><p>从上图中Faster R-CNN更具体的结构，包括左下方的RPN模块。RPN具体流程如下：</p><ol><li><p>使用<strong>滑动窗口(slide window)</strong>遍历整个特征图(feature map)，遍历过程中以window中心产生9个预设<strong>锚框(anchor)</strong>，9个锚框分别对应3种尺寸和3种长宽比。</p><p><img src="https://s2.ax1x.com/2019/10/25/KwJZQS.png" alt="KwJZQS.png"></p></li><li><p>将锚框分别输入到<strong>线性分类层(cls layer)</strong>和<strong>边框回归层(reg layer)</strong>中，初步判断该锚框里是否包含目标物以及进一步修正锚框，使锚框定位更精确。</p><p><img src="https://images2018.cnblogs.com/blog/75922/201803/75922-20180306112242001-1446513216.png" alt></p></li></ol><ol><li>将筛选、修正后的锚框映射到特征图上，输入到ROI池化层。后续操作和Fast R-CNN一样。</li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;R-CNN&quot;&gt;&lt;a href=&quot;#R-CNN&quot; class=&quot;headerlink&quot; title=&quot;R-CNN&quot;&gt;&lt;/a&gt;R-CNN&lt;/h1&gt;&lt;p&gt;论文地址：&lt;a href=&quot;https://arxiv.org/pdf/1311.2524.pdf&quot; target=
      
    
    </summary>
    
      <category term="计算机视觉" scheme="http://a-kali.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/"/>
    
    
      <category term="论文解读" scheme="http://a-kali.github.io/tags/%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB/"/>
    
      <category term="计算机视觉" scheme="http://a-kali.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/"/>
    
      <category term="语义分割" scheme="http://a-kali.github.io/tags/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2/"/>
    
      <category term="深度学习" scheme="http://a-kali.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="R-CNN" scheme="http://a-kali.github.io/tags/R-CNN/"/>
    
      <category term="目标检测" scheme="http://a-kali.github.io/tags/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/"/>
    
  </entry>
  
  <entry>
    <title>计算机视觉算法岗面试归纳</title>
    <link href="http://a-kali.github.io/2019/10/05/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E7%AE%97%E6%B3%95%E5%B2%97%E9%9D%A2%E8%AF%95%E5%BD%92%E7%BA%B3/"/>
    <id>http://a-kali.github.io/2019/10/05/计算机视觉算法岗面试归纳/</id>
    <published>2019-10-05T01:32:59.000Z</published>
    <updated>2019-10-28T14:12:55.835Z</updated>
    
    <content type="html"><![CDATA[<h1 id="ML"><a href="#ML" class="headerlink" title="ML"></a>ML</h1><ul><li>介绍一下调参的经验</li><li>Softmax的公式和伪代码</li><li>分类常见的指标有什么，如何理解AUC？</li><li>介绍决策树、RF、XGBoost、GBDT和 LightGBM</li><li>XGboost的loss函数的推导（mse以及非mse形式），以及求解推导。</li><li>使用O(N)复杂度完成GBDT分裂</li><li>介绍 F1-score，AUC，交叉熵，ROC</li><li>介绍 Adboost，GBDT，XGBoost</li><li>介绍不同的聚类算法：K-Means、GMM、DBSCAN等</li><li>CCA和PCA的区别</li><li>牛顿法能用于非凸函数吗？</li><li>XGBoost里处理缺失值的方法</li><li>样本不平衡对 SVM 的影响</li><li>KNN和Kmeans的算法中K的含义，K对算法的影响，怎么选择K</li><li>LR的全过程，从train到inference，损失函数</li><li>介绍常见的集成方法</li><li>LR + softmax做多分类和LR + multiLoss 做多分类区别在哪里</li><li>LR为什么用交叉熵作为loss函数</li><li>Kmeans的缺点？如何改善？</li><li>讲一下K-means算法的过程以及原理</li><li>为什么Bagging降方差，Boosting降偏差？</li><li>介绍XGBoost对GBDT的提升，LightGBM对XGBoost的提升</li><li>为什么要对连续型数值进行离散化，这样做有什么优势</li><li>LR 为什么用sigmoid函数？</li><li>怎么解决样本不均衡（重点考核损失函数优化）</li><li>HMM 和 CRF的区别</li><li>XGBoost 如何处理缺失数据？</li><li>写一下 LR 和 SVM 的损失函数</li><li>正负样本不均衡时的解决方案</li><li>知道哪些降维的方法，具体讲讲</li><li>线性模型和非线性模型都有哪些？</li><li>手写AUC的计算（小矩形积分得到总面积即可）</li><li>决策树分支的原理</li><li>offerpolicy 和 onpolicy 的区别</li><li>为什么随机森林的树比 GBDT 的深一点？</li><li>逻辑回归的目标函数(损失函数)是凸函数吗？</li><li>完全二叉树的概念</li><li>朴素贝叶斯与贝叶斯有什么区别？</li><li>SVM 为什么变成对偶问题来求解？</li><li>缺失值如何处理，什么情况下均值、众数，什么情况下丢弃特征。</li><li>诸如ID类的特征如何处理，编码方式one-hot还是其他的，高维时？什么样才算高维，有没有界定？</li><li>聚类的算法有哪些？评价方法？优化算法？</li><li>解释几何间隔和函数间隔</li><li>描述决策树，如何选特征，怎么划分，怎么剪枝，介绍信息增益</li><li>K-Means 聚类这种方法一定会收敛嘛？如果不收敛，怎么办？</li><li>SVM 的目标函数，为什么能用拉格朗日乘子法讲原始最优化问题转化为极大极小问题，数学原理是什么</li><li>介绍SVM，其中的软间隔是什么意思？</li><li>使用线性回归的时候什么时候会需要用L2？</li><li>如果F1已经趋于平稳，如何在保持F1稳定的前提下提高precision，降低recall；</li><li>LR 为什么不用 MSE，SVM 为什么用hinge不用logloss</li><li>XGBoost 怎么解决过拟合？怎么剪枝？怎么选择特征？怎么处理缺失值？</li><li>XGBoost 的默认深度</li><li>各种决策树模型的优劣（从最简单的ID3到最后的LGB）</li><li>SVM 核函数哪些是高维空间维度已知，哪些是未知的？</li><li>LR介绍、LR对特征需要做什么特殊处理吗？类别特征、连续特征</li><li>损失函数正则项的本质是什么? </li><li>SVM 有哪些核函数？</li><li>L1 正则化为什么能使特征稀疏？</li><li>Stacking原理，还有怎么调优？</li><li>XGBoost怎么调参？用了多少棵树？</li><li>各种决策树模型的优劣（从最简单的ID3到最后的LGB）</li><li>ID3 C4.5 CART的区别</li><li>手推 SVM, GBDT, XGBoost</li><li>CRF 怎么训练的（传统+深度学习）</li><li>得到AUC的两种计算方法</li><li>树的分裂方式（id3,gini,gdbt,xgboost）</li><li>监督学习的概念？什么是随机森林，随机森林的优点？</li><li>LR和SVM区别（计算复杂度）</li><li>Adam优化器的迭代公式</li><li>SGD每步做什么，为什么能online learning</li><li>L1 L2正则化区别</li><li>PCA原理和执行步骤</li><li>特征工程知道吗？举几个特征归一化的例子</li><li>SVM为什么可以处理非线性问题</li><li>L1正则化的先验分布？</li><li>L1的不知道，L2的先验分布知道吧？</li><li>多标签分类问题怎么解决，从损失函数角度考虑</li></ul><h1 id="NN"><a href="#NN" class="headerlink" title="NN"></a>NN</h1><ul><li>激活函数 除了 Sigmoid tanh ReLU 还有什么介绍一下？</li><li>BFE 和 Dropout的关系</li><li>Dropout是失活神经元还是失活连接</li><li>手推梯度反向传播</li><li>介绍 Leaky Relu 并写公式</li><li>分类网络样本不均衡怎么办？</li><li>dropout层作用，如何实现有什么作用？</li><li>Dropout 前向和反向的处理</li><li>神经网络如果没有激活函数还能解决线性不可分问题吗？</li><li>Tensorflow的动态图和静态图有什么区别</li><li>GN，BN，LN，IN 它们的共性和特性</li><li>为什么BN有泛化能力的改善. 什么场景用什么normalization方法，效果如何.</li><li>Dropout为什么能防止过拟合？具体实现</li><li>dropout在训练和测试时不同，怎么保证测试结果稳定</li><li>如何计算神经网络的 FLOPS？</li><li>梯度下降陷入局部最优有什么解决办法</li></ul><h1 id="图像处理"><a href="#图像处理" class="headerlink" title="图像处理"></a>图像处理</h1><ul><li>手写灰度直方图代码</li><li>介绍一下开运算和闭运算</li><li>介绍双目相机识别目标深度的原理</li><li>单目视觉如何测量深度？</li><li>介绍常见的边缘检测算法</li><li>SIFT 特征是如何保持旋转不变性的？</li><li>如何快速判断图中有环？</li><li>介绍常见的边缘检测算子</li><li>Hough 变换原理（直线和圆检测）</li><li>为什么 Sobel 算子中间是2，两边是1</li><li>算法题：实现 OpenCV中的图像缩放，包括实现双线性插值</li><li>输入图像灰度值对模型的影响，为什么要把0-255转化成0-1？</li><li>介绍 RANSAC</li><li>介绍一阶二阶边缘检测算子一阶二阶边缘检测算子</li><li>OpenCV里面findcontour函数的原理是什么？</li><li>相机里面的标定参数有哪些？是怎么计算这些参数的？</li><li>如何求边缘，45°边缘，高斯滤波和双边滤波</li><li>代码题：手撕实现图像的resize和rotate90度</li><li>手写中值滤波</li><li>介绍一下高斯滤波，均值滤波，中值滤波</li><li>SIFT特征提取怎么做的，具备什么性质，为什么</li><li>讲一下CTC的原理</li><li>夜间拍照的多图对齐和融合</li></ul><h1 id="CV"><a href="#CV" class="headerlink" title="CV"></a>CV</h1><ul><li>介绍你读到的19年 Anchor-free 目标检测论文</li><li>简单介绍Fast RCNN -&gt; Faster RCNN -&gt; mask RCNN (这个真的好高频)</li><li>256×256×3 -&gt; 128×128×64的卷积，stride，padding和待优化的参数有多少</li><li>手撕 SoftNMS代码</li><li>CNN反向传播公式推导；参数共享指的是？</li><li>介绍熟悉的NAS网络</li><li>介绍目标检测中的多尺度训练/测试？</li><li>为什么 DenseNet 比 ResNet 更耗显存？</li><li>为什么深度学习中的图像分割要先编码再解码？</li><li>1*1 卷积有什么作用？</li><li>如何计算语义分割的 mIoU（写伪代码）</li><li>原始图片中的 RoI 如何映射到 feature map ?</li><li>PyTorch的高效convolution实现</li><li>PyTorch 不用库函数如何实现多机多卡</li><li>哪些情况用 MaxPool比AveragePool效果好？原因</li><li>介绍Anchor based 和Anchor free目标检测网络的优缺点</li><li>YOLOv3在小缺陷检测上也很好，RPN上和two-stage的有什么区别</li><li>MobileNetV2 module的参数量和FLOPs计算</li><li>CNN 的感受野受什么影响</li><li>CNN 如何保持平移方向不变性</li><li>如果分类的数据图像每一类只有几张，你会用什么方法？</li><li>RPN怎么计算 box 的实际坐标</li><li>介绍常见的 Anchor free 目标检测算法</li><li>算法题：编程实现目标检测中的 IoU 计算</li><li>公式及讲解soft attention，hard attention，multi head attention</li><li>卷积操作是线性的吗？CNN是线性的吗？为什么？（激活函数）常用的激活函数？</li><li>3×3 卷积核 与 5×5 卷积核相比的优点</li><li>CNN Maxpooling 怎么反向传播？</li><li>Inception（V1-V4）网络结构以及优缺点</li><li>写出 YOLOv3 的损失函数</li><li>YOLOV1~V3系列介绍，以及每一版的改进，优缺点介绍</li><li>介绍金字塔池化，ASPP，深度可分，带孔卷积</li><li>VGG网络什么特点，用到了哪几种卷积核？</li><li>介绍 anchor-based和anchor-free两者的优缺点</li><li>PyTorch 多gpu训练机制的原理，优化器以及网络参数保存机制</li><li>讲下faster-rcnn？Faster-rcnn里面的NMS的算法原理是什么？</li><li>Mask R-CNN 如何提高mask的分辨率？</li><li>普通卷积、DW+PW卷积计算量推导</li><li>MobileNet V2中的Residual结构最先是哪个网络提出来的</li><li>CornerNet介绍，CornerPooling是怎么做的，怎么解决cornernet检测物体合并为一个框的问题</li><li>GoogLeNet中为什么采用小的卷积核？</li><li>说一下UNet的结构</li><li>熟悉deeplab吗，aspp是怎样的，与其他的state-of-art的模型对比，deeplab还可以做哪些改进？</li><li>retinanet的focal loss是解决的什么问题</li><li>CRF后处理的目的</li><li>介绍deeplabv3，画出backbone（串联和并联），论文中认为这两种哪种方式更好？如何避免friding efect、deeplabv3的损失函数</li></ul><h1 id="SLAM"><a href="#SLAM" class="headerlink" title="SLAM"></a>SLAM</h1><ul><li>PnP求解最少需要几个点？</li><li>ORBSLAM的哪个部分最耗时？</li><li>ORBSLAM怎么克服尺度漂移问题？</li><li>回环原理讲一下，要估计哪些量？</li><li>后端BA中，如何存在outlier一般怎么解决？</li><li>BA中，海塞矩阵的求逆有哪些可以加速的方法？</li><li>单应矩阵(homography)为什么只有8个自由度？</li><li>如何设计一个视觉+IMU+RTK+Lidar的定位系统？</li><li>对于光照明暗变化、动态场景，视觉SLAM如何去解决？</li><li>ROS中，node属于多进程，如何把两个node放在一个进程中？</li><li>ORBSLAM 后端H矩阵求解的算法复杂度是多少？如何去加速后端求解？</li><li>ORB-SLAM的初始化步骤</li><li>介绍 Bundle Adjustment</li><li>机器人学中表示旋转的方式有哪些？区别是什么？</li><li>检测圆的方法有哪些？</li><li>霍夫圆变换的原理是什么？</li><li>你知道哪些点云匹配的算法？原理是什么？</li><li>ROS里面的一些基本操作怎么实现？</li><li>怎么估计3D姿态？用什么表示姿态？</li><li>相机标定方法与流程，内外参矩阵求解</li><li>什么是闭环检测？常用的方法有哪些？你用的哪种方法？有没有创新？</li><li>解释一下Gauss-Netwon和LM算法。</li><li>熟悉Ceres优化库吗？说一下。</li><li>描述（扩展）卡尔曼滤波与粒子滤波，你自己在用卡尔曼滤波时遇到什么问题没有？</li><li>除了视觉传感，还用过其他传感吗？比如GPS，激光雷达。。。</li></ul><h1 id="反向面试"><a href="#反向面试" class="headerlink" title="反向面试"></a>反向面试</h1><p>再也不用担心面试官灵魂拷问：你有什么要问我的么？</p><p>下面列表里的问题对于参加技术面试的人来说很有用：</p><ul><li>我的日常工作是什么？</li><li>入职培训会是什么样的？</li><li>你们怎么使用源码控制系统？</li><li>团队内/团队间的交流通常是怎样的？</li><li>有标准的开发环境吗？是强制的吗？</li><li>我可以为开源项目做贡献吗？是否需要审批？</li><li>团队里面初级和高级工程师的比例是多少？</li><li>晋升流程是怎样的？要求/预期是怎样沟通的？</li><li>我入职的岗位是新增还是接替之前离职的同事？</li><li>入职之后在哪个项目组，项目是新成立还是已有的？b公司是否有技术分享交流活动？有的话，多久一次呢？</li><li>更多提问可以在 <a href="https://github.com/yifeikong/reverse-interview-zh" target="_blank" rel="noopener">https://github.com/yifeikong/reverse-interview-zh</a> 找到</li></ul><p>出了以上几种类型的题目，还常见编程算法题、C++语言细节、Python语言细节、英语题、数学题、项目、计算机网络和操作系统</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;ML&quot;&gt;&lt;a href=&quot;#ML&quot; class=&quot;headerlink&quot; title=&quot;ML&quot;&gt;&lt;/a&gt;ML&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;介绍一下调参的经验&lt;/li&gt;
&lt;li&gt;Softmax的公式和伪代码&lt;/li&gt;
&lt;li&gt;分类常见的指标有什么，如何理解AUC？&lt;/
      
    
    </summary>
    
    
      <category term="机器学习" scheme="http://a-kali.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="计算机视觉" scheme="http://a-kali.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/"/>
    
      <category term="神经网络" scheme="http://a-kali.github.io/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
      <category term="语义分割" scheme="http://a-kali.github.io/tags/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2/"/>
    
      <category term="目标检测" scheme="http://a-kali.github.io/tags/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/"/>
    
      <category term="面试" scheme="http://a-kali.github.io/tags/%E9%9D%A2%E8%AF%95/"/>
    
      <category term="SLAM" scheme="http://a-kali.github.io/tags/SLAM/"/>
    
      <category term="图像处理" scheme="http://a-kali.github.io/tags/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/"/>
    
  </entry>
  
  <entry>
    <title>周志华《机器学习》</title>
    <link href="http://a-kali.github.io/2019/09/16/%E5%91%A8%E5%BF%97%E5%8D%8E%E3%80%8A%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E3%80%8B/"/>
    <id>http://a-kali.github.io/2019/09/16/周志华《机器学习》/</id>
    <published>2019-09-16T11:28:39.000Z</published>
    <updated>2019-09-18T12:36:28.450Z</updated>
    
    <content type="html"><![CDATA[<h1 id="第-1-章-绪论"><a href="#第-1-章-绪论" class="headerlink" title="第 1 章    绪论"></a>第 1 章    绪论</h1><h2 id="1-2-基本术语"><a href="#1-2-基本术语" class="headerlink" title="1.2 基本术语"></a>1.2 基本术语</h2><p>假设（hypothesis）：根据数据的潜在规律学习而得的模型。亦称为学习器。</p><p>簇（cluster）：聚类学习中的一个组。</p><p>泛化（generalization）：学得模型适用于新样本的能力。</p><h2 id="1-3-假设空间"><a href="#1-3-假设空间" class="headerlink" title="1.3 假设空间"></a>1.3 假设空间</h2><p>假设空间：机器学习中可能的函数构成的空间。学习的过程即是在假设空间中进行搜索的过程。</p><h1 id="第-2-章-模型评估与选择"><a href="#第-2-章-模型评估与选择" class="headerlink" title="第 2 章    模型评估与选择"></a>第 2 章    模型评估与选择</h1><h2 id="2-2-评估方法"><a href="#2-2-评估方法" class="headerlink" title="2.2 评估方法"></a>2.2 评估方法</h2><h3 id="2-2-1-留出法"><a href="#2-2-1-留出法" class="headerlink" title="2.2.1 留出法"></a>2.2.1 留出法</h3><p><strong>留出法</strong>（hold-out）将数据集划分为两个互斥的集合，分别作为训练集和测试集。</p><h3 id="2-2-2-交叉验证法"><a href="#2-2-2-交叉验证法" class="headerlink" title="2.2.2 交叉验证法"></a>2.2.2 交叉验证法</h3><h3 id="2-2-3-自助法"><a href="#2-2-3-自助法" class="headerlink" title="2.2.3 自助法"></a>2.2.3 自助法</h3><p><strong>自助采样法</strong>（bootstrap sampling）对大小为 m 的数据集进行 m 次放回采样，采样得到的数据作为训练集，初始数据集中大约有 36.8% 的数据未被采样过，这部分数据作为测试集。</p><p>自助法在数据集较小、难以划分测试集和训练集时比较有用。但会改变原有数据集的分布，引入估计偏差。</p><h3 id="2-2-4-调参与最佳模型"><a href="#2-2-4-调参与最佳模型" class="headerlink" title="2.2.4 调参与最佳模型"></a>2.2.4 调参与最佳模型</h3><p>模型评估与选择中，用于评估模型的数据集常称为<strong>验证集</strong>。</p><h2 id="2-3-性能度量"><a href="#2-3-性能度量" class="headerlink" title="2.3 性能度量"></a>2.3 性能度量</h2><p>性能度量：对模型泛化能力的评价标准。</p><p>均方误差（mean squared error）：$E(f;D)=\frac{1}{m} \sum^m_{i=1}(f(x_i)-y_i)^2.$ 常用于回归任务中。</p><h3 id="2-3-1-错误率与精度"><a href="#2-3-1-错误率与精度" class="headerlink" title="2.3.1 错误率与精度"></a>2.3.1 错误率与精度</h3><ul><li><strong>错误率</strong>（error rate）：分类错误的样本数占样本总数的比例</li><li><strong>精度</strong>（accuracy）：分类正确的样本数占样本总数的比例</li></ul><p>此处的评估标准仅仅是根据样本分类的正误个数进行评估，没有表现出单个样本的错误程度。</p><h3 id="2-3-2-查准率、查全率与-F1"><a href="#2-3-2-查准率、查全率与-F1" class="headerlink" title="2.3.2 查准率、查全率与 F1"></a>2.3.2 查准率、查全率与 F1</h3><p>在信息检索等应用场景中经常出现如下的需求，比如想知道“检索出的信息中有多少比例是用户感兴趣的”“用户感兴趣的信息中有多少被检索出来了”。此时用<strong>查准率</strong>（precision）和<strong>查全率</strong>（recall，也被称为召回率）更为适合此类需求。</p><p>混淆矩阵：</p><p><a href="https://imgchr.com/i/nfoRB9" target="_blank" rel="noopener"><img src="https://s2.ax1x.com/2019/09/16/nfoRB9.png" alt="nfoRB9.png"></a></p><p>查准率 P 和查全率 R 分别被定义为</p><script type="math/tex; mode=display">P=\frac{TP}{TP+FP}\\R=\frac{TP}{TP+FN}</script><p>查全率和查准率是一对矛盾的度量。一般来说，查全率高时查准率低，查准率高时查全率低。</p><p>P-R曲线、ROC和AUC可参考<a href="https://a-kali.github.io/2019/09/03/机器学习中的评价指标/">机器学习中的评价指标</a>。</p><h3 id="2-3-4-代价敏感错误率与代价曲线"><a href="#2-3-4-代价敏感错误率与代价曲线" class="headerlink" title="2.3.4 代价敏感错误率与代价曲线"></a>2.3.4 代价敏感错误率与代价曲线</h3><p>不同类型的错误所造成的后果不同，为权衡不同类型错误所造成的不同损失，可以为错误赋予<strong>非均等代价</strong>。</p><p>在非均等代价下，我们所希望的不再是简单地最小化错误次数，而是希望最小化<strong>总体代价</strong>。以二分类为例，其代价敏感错误率为：</p><script type="math/tex; mode=display">E = \frac{1}{m}(\sum_{x_i\in D^+}I(f(x_i)\not=y_i)\times cost_{01}+\sum_{x_i\in D^-}I(f(x_i)\not=y_i)\times cost_{10})</script><p>其中$I(·)$为指示函数，$cost$为错误的权重（即代价）。</p><p><strong>代价曲线</strong>可以直接反映非均等代价下学习器的期望总体代价。代价曲线的绘制很简单：ROC曲线上的每一点对应了代价平面上的一条线段，根据ROC曲线上的每一点的状态绘制一条从(0,FPR) 到 (1, FNR) 的线段，线段下的面积即表示了该条件下的期望总体代价。</p><p><img src="https://s2.ax1x.com/2019/09/18/n7Ri7j.png" alt="n7Ri7j.png"></p><h1 id="第-3-章-线性模型"><a href="#第-3-章-线性模型" class="headerlink" title="第 3 章    线性模型"></a>第 3 章    线性模型</h1>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;第-1-章-绪论&quot;&gt;&lt;a href=&quot;#第-1-章-绪论&quot; class=&quot;headerlink&quot; title=&quot;第 1 章    绪论&quot;&gt;&lt;/a&gt;第 1 章    绪论&lt;/h1&gt;&lt;h2 id=&quot;1-2-基本术语&quot;&gt;&lt;a href=&quot;#1-2-基本术语&quot; class
      
    
    </summary>
    
      <category term="机器学习" scheme="http://a-kali.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="机器学习" scheme="http://a-kali.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>Inception v1-v4 论文解读</title>
    <link href="http://a-kali.github.io/2019/09/04/Inception-v1-v4/"/>
    <id>http://a-kali.github.io/2019/09/04/Inception-v1-v4/</id>
    <published>2019-09-04T09:57:36.000Z</published>
    <updated>2019-10-10T13:20:51.549Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Inception-V1"><a href="#Inception-V1" class="headerlink" title="Inception V1"></a>Inception V1</h1><p>论文地址：<a href="https://arxiv.org/pdf/1409.4842v1.pdf" target="_blank" rel="noopener">Going deeper with convolutions</a></p><h2 id="动机与深层思考"><a href="#动机与深层思考" class="headerlink" title="动机与深层思考"></a>动机与深层思考</h2><p>直接提升神经网络性能的方法是提升网络的深度和宽度。然而，更深的网络意味着其参数的大幅增加，从而导致计算量爆炸。因此，作者希望能在计算资源消耗恒定不变的条件下，提升网络性能。</p><p>降低计算资源消耗的一个方法是使用<a href="https://baike.baidu.com/item/稀疏连接/22764619?fr=aladdin" target="_blank" rel="noopener">稀疏连接</a>结构，但不均匀的稀疏数值运算在当前适合密集运算的硬件条件下运行十分低效。作者希望将稀疏连接结构运用于卷积层，并以此解决稀疏连接在密集运算条件下效率低下的问题。于是Inception便应运而生。</p><h2 id="架构细节"><a href="#架构细节" class="headerlink" title="架构细节"></a>架构细节</h2><p> <img src="https://s2.ax1x.com/2019/10/04/uDtGDI.png" alt="uDtGDI.png"></p><p>作者希望“找到最优的局部结构，并在空间上重复它”，如上的Inception模块便是作者找到的最优局部结构。该结构有四个通道，同时使用了1×1、3×3、5×5的卷积核。作者表示“卷积核的大小并没有什么特殊含义，其便利性大于必要性”，在padding=0，1，2的时候特征图大小相同，方便对齐。</p><p>随着网路层数的加深，其特征图的抽象程度变高，空间集中程度下降。这意味着5×5卷积核占比应逐渐增加。然而在具有大量滤波器的卷积层，5×5卷积核运算量太大。这催生了对Inception的第二个改进：在计算量要求较多的地方使用1×1卷积核进行降维。于是便诞生了完整版的Inception V1模块：</p><p><img src="https://s2.ax1x.com/2019/10/04/uDB4kn.png" alt="uDB4kn.png"></p><h2 id="GoogLeNet"><a href="#GoogLeNet" class="headerlink" title="GoogLeNet"></a>GoogLeNet</h2><p>GoogLeNet是一个大量使用了Inception模块堆叠的一个神经网络，其结构如下（图太大了，这里就不放完整图片了）：</p><p><img src="https://s2.ax1x.com/2019/10/04/uDrWin.png" alt="#uDrWin.png"></p><p>值得一提的是，考虑到深层网络的梯度消失问题（当时还没出现批归一化和残差结构），GoogLeNet使用了在网络的中间隐藏层使用了<strong>辅助分类器</strong>（auxiliary classifiers），其训练时给出的分类结果的损失的以0.3的权重加到总损失上，以在一定程度上解决梯度消失问题。</p><h2 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h2><ul><li><p>很多文章中都有提到，Inception结构使用不同大小的卷积核能够适应不同尺度的特征。虽然并没有在原论文中看见相关阐述，但我觉得有点道理。论文中提到Inception在目标检测任务中有更出色的效果，这很可能与其能适应不同尺度特征有关。</p><p><img src="https://s2.ax1x.com/2019/10/04/uDo1Ds.png" alt="如图，图中三只狗狗所占图片区域大小不同"></p></li><li><p>作者并没有在原论文中提到Inception结构起作用的原因，但我认为Inception结构和ResNet的残差结构有异曲同工之妙（虽然ResNet的诞生在GoogLeNet之后）。残差结构能让神经网络自己通过调整参数来选择是否趋近于恒等映射，而Inception能让神经网络自己选择卷积核大小（3×3、5×5 convolutions），或是将这层作为全连接（1×1 convolutions，Inception结构最左边的那个1×1卷积核作用相当于全连接），抑或是池化（3×3 Max Pooling）。</p></li></ul><h1 id="Inception-V2-amp-V3"><a href="#Inception-V2-amp-V3" class="headerlink" title="Inception V2&amp;V3"></a>Inception V2&amp;V3</h1><p>论文链接：<a href="https://arxiv.org/abs/1512.00567" target="_blank" rel="noopener">Rethinking the Inception Architecture for Computer Vision</a></p><h2 id="通用设计准则"><a href="#通用设计准则" class="headerlink" title="通用设计准则"></a>通用设计准则</h2><p>该论文提出了4个神经网络的设计准则，并根据这些准则改进Inception。以下列出关键的两条：</p><ul><li>避免一次性大幅压缩（大尺寸卷积、池化等）特征图的尺寸，否则会造成<strong>表征性瓶颈</strong>，特征图中的信息会大量损失。</li><li>高维度的特征更容易局部处理，解耦更多的特征，加速网络训练。</li></ul><h2 id="分解（Factorization）大尺寸卷积"><a href="#分解（Factorization）大尺寸卷积" class="headerlink" title="分解（Factorization）大尺寸卷积"></a>分解（Factorization）大尺寸卷积</h2><p>作者提出，大尺寸卷积的计算量和它的尺寸是不成比例的。于是将原来的5×5卷积改成了两个3×3卷积：</p><p><img src="https://s2.ax1x.com/2019/10/07/uRSdMD.png" alt="uRSdMD.png"></p><p>然后减少了28%的计算量。</p><h2 id="分解为不对称的卷积"><a href="#分解为不对称的卷积" class="headerlink" title="分解为不对称的卷积"></a>分解为不对称的卷积</h2><p>然后作者想把3×3分解成更小的卷积……尝试了分解成两个2×2，节省了11%的计算量。然后尝试了分解成1×3和3×1，节省了33%计算量。于是便多出了如下两类不对称分解的Inception模块：</p><p><img src="https://s2.ax1x.com/2019/10/07/uRCVIA.png" alt="uRCVIA.png"></p><p>左图模块特性：</p><ul><li>在网络的浅层表现不佳，但在网络的中层有较好的效果。</li><li>由于比原版模块增加了一层非线性层，提高了模型的表达能力。</li></ul><p>右图模块特性：</p><ul><li>能够维持特征的高维度，符合上述通用设计准则的第二条。</li></ul><h2 id="减少特征图尺寸"><a href="#减少特征图尺寸" class="headerlink" title="减少特征图尺寸"></a>减少特征图尺寸</h2><p>当网络需要将一个尺寸为 2d×2d、维度为 k 的特征图转换为一个尺寸为 d×d、维度为 2k 的特征图时，问题就来了：如果先减小尺寸，那么将会损失大量信息，造成准则第一条中的表征性瓶颈；如果先增大维度，那么计算量将翻3倍。如何高效地减小特征图尺寸呢？作者提出了以下结构：</p><p><img src="https://s2.ax1x.com/2019/10/07/uRkv3n.png" alt="uRkv3n.png"></p><p>该结构在增加特征维度、减少特征图尺寸的同时避免了表征性瓶颈和计算量过大的问题。</p><h2 id="Inception-v2"><a href="#Inception-v2" class="headerlink" title="Inception-v2"></a>Inception-v2</h2><p><img src="https://s2.ax1x.com/2019/10/07/uRVxgA.png" alt="uRVxgA.png"></p><p>其中使用了三种Inception模块（图中红框处），包括3个普通分解模块和5个不对称分解堆叠模块以及2个不对称分解扩展模块。值得一提的是原网络中的7×7卷积被分解成了3个3×3卷积。</p><h2 id="Inception-v3"><a href="#Inception-v3" class="headerlink" title="Inception-v3"></a>Inception-v3</h2><p>在论文的后续中，作者对Inception v2进行了如下改进：</p><ul><li>使用RMSProp优化器</li><li>辅助分类器使用了BatchNorm</li><li>标签平滑（正则化）</li></ul><h1 id="Inception-V4-amp-Inception-Resnet"><a href="#Inception-V4-amp-Inception-Resnet" class="headerlink" title="Inception V4 &amp; Inception-Resnet"></a>Inception V4 &amp; Inception-Resnet</h1><p>论文地址：<a href="https://arxiv.org/pdf/1602.07261.pdf" target="_blank" rel="noopener">Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning</a></p><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>随着 ResNet 网络的出现及其在主流数据集上的良好表现，作者想将残差结构引入到 Inception 网络中，看看网络是否会有更好的表现；同时注意到Inception-v3的部分结构有不必要的复杂性，于是尝试在不引入残差结构的情况下改进原本的Inception结构，并将改进后的Inception结构命名为Inception-v4。</p><p>我感觉这篇论文的知识量不大，整篇论文一半都是图，看看了解下就行。</p><h2 id="Inception-v4"><a href="#Inception-v4" class="headerlink" title="Inception-v4"></a>Inception-v4</h2><p><img src="https://s2.ax1x.com/2019/10/08/uhaJjs.png" alt="uhaJjs.png"></p><p>图中是v4使用的三个Inception模块。分别命名为Inception-A、Inception-B、Inception-C。除了所有的池化层都使用了<strong>Avg Pooling</strong>以外，没有什么特别的变动。另外网络整体结构也发生了一些改变，这里直接用网图了：</p><p><img src="https://img-blog.csdnimg.cn/2018102913400312.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3p6YzE1ODA2,size_27,color_FFFFFF,t_70" alt></p><h2 id="Inception-Resnet"><a href="#Inception-Resnet" class="headerlink" title="Inception-Resnet"></a>Inception-Resnet</h2><p><a href="https://imgchr.com/i/uhwGmn" target="_blank" rel="noopener"><img src="https://s2.ax1x.com/2019/10/08/uhwGmn.md.png" alt="uhwGmn.md.png"></a></p><p><img src="https://img-blog.csdnimg.cn/20181029135504384.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3p6YzE1ODA2,size_27,color_FFFFFF,t_70" alt></p><p>上图是 Inception-Resnet-v1 的模块和结构， Inception-Resnet-v2只是在v1的基础上使用了Inception-v4的stem结构。</p><h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><p><a href="http://baijiahao.baidu.com/s?id=1601882944953788623&amp;wfr=spider&amp;for=pc" target="_blank" rel="noopener">一文概览Inception家族的「奋斗史」</a></p><p><a href="https://blog.csdn.net/zzc15806/article/details/83504130" target="_blank" rel="noopener">【深度学习】GoogLeNet系列解读 —— Inception v4</a></p><p><a href="https://blog.csdn.net/weixin_39953502/article/details/80966046" target="_blank" rel="noopener">inception-v1,v2,v3,v4——论文笔记</a></p><p>以及文中所述的论文链接。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Inception-V1&quot;&gt;&lt;a href=&quot;#Inception-V1&quot; class=&quot;headerlink&quot; title=&quot;Inception V1&quot;&gt;&lt;/a&gt;Inception V1&lt;/h1&gt;&lt;p&gt;论文地址：&lt;a href=&quot;https://arxiv.or
      
    
    </summary>
    
      <category term="计算机视觉" scheme="http://a-kali.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/"/>
    
    
      <category term="论文解读" scheme="http://a-kali.github.io/tags/%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB/"/>
    
      <category term="Inception" scheme="http://a-kali.github.io/tags/Inception/"/>
    
      <category term="计算机视觉" scheme="http://a-kali.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/"/>
    
      <category term="神经网络" scheme="http://a-kali.github.io/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>线性回归与逻辑回归</title>
    <link href="http://a-kali.github.io/2019/09/03/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E4%B8%8E%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/"/>
    <id>http://a-kali.github.io/2019/09/03/线性回归与逻辑回归/</id>
    <published>2019-09-03T13:21:16.000Z</published>
    <updated>2019-09-04T09:56:45.073Z</updated>
    
    <content type="html"><![CDATA[<h1 id="线性回归"><a href="#线性回归" class="headerlink" title="线性回归"></a>线性回归</h1><p>​    <strong>线性回归</strong>通常是解决连续数值预测问题, 利用数理统计的回归分析, 来确定变量之间的相互依赖关系. 其公式通常表示如下:</p><script type="math/tex; mode=display">h_\theta(x)=\theta_0 +\theta_1x_1+\theta_2x_2+……+\theta_nx_n=θ^Tx</script><h1 id="逻辑回归"><a href="#逻辑回归" class="headerlink" title="逻辑回归"></a>逻辑回归</h1><p>​    <strong>逻辑（Logistic，又称 Sigmoid）回归</strong>常用于解决二分类问题，用于估算某种事物的可能性。Sigmoid 函数公式如下：</p><script type="math/tex; mode=display">g(z)=\frac{1}{1+e^{-z}}</script><p>该函数的值域为 (0, 1)，其值的意义为输入特征被分到 1 类的概率。逻辑回归的本质是在线性回归之后加了一层函数映射。将线性回归方程带入到逻辑回归方程中，得到逻辑回归表达式：</p><script type="math/tex; mode=display">h_\theta(x) = g(\theta^Tx)=\frac{1}{1+e^{-\theta^Tx}}</script>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;线性回归&quot;&gt;&lt;a href=&quot;#线性回归&quot; class=&quot;headerlink&quot; title=&quot;线性回归&quot;&gt;&lt;/a&gt;线性回归&lt;/h1&gt;&lt;p&gt;​    &lt;strong&gt;线性回归&lt;/strong&gt;通常是解决连续数值预测问题, 利用数理统计的回归分析, 来确定变量之间的
      
    
    </summary>
    
      <category term="机器学习" scheme="http://a-kali.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="机器学习" scheme="http://a-kali.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="线性回归" scheme="http://a-kali.github.io/tags/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/"/>
    
      <category term="逻辑回归" scheme="http://a-kali.github.io/tags/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/"/>
    
  </entry>
  
  <entry>
    <title>机器学习中的评价指标</title>
    <link href="http://a-kali.github.io/2019/09/03/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E8%AF%84%E4%BB%B7%E6%8C%87%E6%A0%87/"/>
    <id>http://a-kali.github.io/2019/09/03/机器学习中的评价指标/</id>
    <published>2019-09-03T08:52:16.000Z</published>
    <updated>2019-09-18T07:01:26.902Z</updated>
    
    <content type="html"><![CDATA[<h1 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h1><h2 id="混淆矩阵"><a href="#混淆矩阵" class="headerlink" title="混淆矩阵"></a>混淆矩阵</h2><div class="table-container"><table><thead><tr><th style="text-align:center">-</th><th style="text-align:center">Positive Predictions</th><th style="text-align:center">Negative Predictions</th></tr></thead><tbody><tr><td style="text-align:center">Positive Label</td><td style="text-align:center">TP (True Positive)</td><td style="text-align:center">FN</td></tr><tr><td style="text-align:center">Negative Label</td><td style="text-align:center">FP</td><td style="text-align:center">TN</td></tr></tbody></table></div><h2 id="Accuracy（ACC，准确率）"><a href="#Accuracy（ACC，准确率）" class="headerlink" title="Accuracy（ACC，准确率）"></a>Accuracy（ACC，准确率）</h2><script type="math/tex; mode=display">ACC= \frac{TP+TN}{FP+FN+TP+TN}=\frac{预测正确的样本数}{总样本数}</script><h2 id="Precision（PRE，精度、查准率）"><a href="#Precision（PRE，精度、查准率）" class="headerlink" title="Precision（PRE，精度、查准率）"></a>Precision（PRE，精度、查准率）</h2><script type="math/tex; mode=display">PRE=\frac{TP}{TP+FP}=\frac{预测正确的正样本数}{所有预测为正的样本数}</script><h2 id="True-Positive-Rate（TPR，召回率、查全率）"><a href="#True-Positive-Rate（TPR，召回率、查全率）" class="headerlink" title="True Positive Rate（TPR，召回率、查全率）"></a>True Positive Rate（TPR，召回率、查全率）</h2><script type="math/tex; mode=display">TPR=\frac{TP}{TP+FN}= \frac{预测正确的正样本数}{总正样本数}</script><h2 id="False-Positive-Rate（FPR，误报率）"><a href="#False-Positive-Rate（FPR，误报率）" class="headerlink" title="False Positive Rate（FPR，误报率）"></a>False Positive Rate（FPR，误报率）</h2><script type="math/tex; mode=display">FPR=\frac{FP}{TN+FP}=\frac{预测为正的负样本数}{总负样本数}</script><h2 id="False-Negative-Rate（FNR，漏报率）"><a href="#False-Negative-Rate（FNR，漏报率）" class="headerlink" title="False Negative Rate（FNR，漏报率）"></a>False Negative Rate（FNR，漏报率）</h2><script type="math/tex; mode=display">FNR=\frac{FN}{TN+FN}=\frac{预测为负的正样本数}{预测成负样本的总数量}</script><h1 id="评估曲线"><a href="#评估曲线" class="headerlink" title="评估曲线"></a>评估曲线</h1><h2 id="PR-曲线"><a href="#PR-曲线" class="headerlink" title="PR 曲线"></a>PR 曲线</h2><p>精度又名查准率, 关心的是 “查出的所有正例中, 哪些正例是查对的”<br>召回率又名查全率, 关心的是 “对于所有的正例, 正确查出了多少个”</p><p>这二者是一对矛盾的度量, 因为我们很容易知道:</p><ul><li>如果我们希望查准率高, 那么可以认为是 “只有当十成把握认为其是正例时, 才将其挑出”。</li><li>而如果我们希望召回率高, 那么可以认为是 “宁错杀一百, 不放过一个”. 查准率和查全率的曲线又叫 PR 曲线, 如下图所示：</li></ul><p><img src="https://s2.ax1x.com/2019/09/03/nkRp6J.jpg" alt="nkRp6J.jpg"></p><p>通常情况下, 如果一个学习器的 PR 曲线被另一个学习器 <strong>完全包住</strong>. 那么我们就认为后者的性能优于前者. 当二者存在交叉时, 我们可以通过四种方式来确定学习器的优劣：</p><ol><li><p>计算 PR 曲线与横纵坐标轴围成的面积, 面积越大越好；</p></li><li><p>利用平衡点 (BEP, 查准率=查全率), BEP 越大越好；</p></li><li><p>利用$F<em>\beta$度量, 当 $\beta<1$ 时， 查准率(精度)权重更大, 当$\beta>1$时， 查全率(召回率)权重更大。$F</1$></em>\beta$的计算公式来自于加权调和平均数：</p><script type="math/tex; mode=display">\frac{1}{F_\beta}=\frac{1}{1+β^2}(\frac{1}{P}+\frac{β^2}{R})</script><script type="math/tex; mode=display">F_β=\frac{(1+β^2)×P×R}{β^2×P+R}</script></li></ol><h2 id="ROC-曲线"><a href="#ROC-曲线" class="headerlink" title="ROC 曲线"></a>ROC 曲线</h2><p>​    很多学习器是为测试样本产生一个实值或概率预测，然后将这个预测值与一个分类阈值进行比较，若大于阈值分为正例，否则分为负例，因此<strong>分类过程可以看做是选取一个合适的截断点</strong>。那么到底什么样的截断点更合适呢？ ROC 正是从这个角度来研究学习器好坏的工具。</p><p>​    ROC 曲线的纵坐标和横坐标分别是召回率和误诊率，下图为 ROC 曲线图，实际任务中会利用有限个测试样本来绘制 ROC 图，所以产生的大多不是平滑的曲线。</p><p><img src="https://s2.ax1x.com/2019/09/03/nk7o59.jpg" alt="nk7o59.jpg"></p><h3 id="绘制-ROC-曲线"><a href="#绘制-ROC-曲线" class="headerlink" title="绘制 ROC 曲线"></a>绘制 ROC 曲线</h3><p>​    假设已经得出一系列样本被划分为正类的概率，然后按照大小排序，下图是一个示例，图中共有20个测试样本，”Class” 一栏表示每个测试样本真正的标签（p表示正样本，n表示负样本），”Score” 表示每个测试样本属于正样本的概率。</p><p><img src="https://s2.ax1x.com/2019/09/03/nkLzOP.jpg" alt="nkLzOP.jpg"></p><p>​    接下来，我们从高到低，依次将“Score”值作为阈值threshold，当测试样本属于正样本的概率大于或等于这个threshold时，我们认为它为正样本，否则为负样本。举例来说，对于图中的第4个样本，其“Score”值为0.6，那么样本1，2，3，4都被认为是正样本，因为它们的“Score”值都大于等于0.6，而其他样本则都认为是负样本。每次选取一个不同的threshold，我们就可以得到一组FPR和TPR，即ROC曲线上的一点。这样一来，我们一共得到了20组FPR和TPR的值，将它们画在ROC曲线的结果如下图：</p><p><img src="https://s2.ax1x.com/2019/09/03/nkOQkF.jpg" alt="nkOQkF.jpg"></p><h3 id="ROC-曲线的意义"><a href="#ROC-曲线的意义" class="headerlink" title="ROC 曲线的意义"></a>ROC 曲线的意义</h3><p>​    有助于选择最佳的阈值。ROC曲线越靠近左上角，模型的准确性就越高。最靠近左上角的ROC曲线上的点是分类错误最少的最好阈值，其假正例和假反例总数最少。</p><h2 id="AUC-的含义及计算"><a href="#AUC-的含义及计算" class="headerlink" title="AUC 的含义及计算"></a>AUC 的含义及计算</h2><p>​    <strong>AUC</strong>（Area Under Curve）被定义为ROC曲线下与坐标轴围成的面积，显然这个面积的数值不会大于1。又由于ROC曲线一般都处于y=x这条直线的上方，所以AUC的取值范围在0.5和1之间。</p><p>​    在进行学习器的比较时，若一个学习器的ROC曲线被另一个学习器的曲线完全“包住”，则可断言后者的性能优于前者；若两个学习器的ROC曲线发生交叉，则难以一般性的断言两者孰优孰劣。此时如果一定要进行比较，则比较合理的判断依据是比较AUC，AUC大的学习器通常性能更好。</p><h1 id="参考文献："><a href="#参考文献：" class="headerlink" title="参考文献："></a>参考文献：</h1><p><a href="https://hellozhaozheng.github.io/z_post/计算机视觉-计算机视觉知识点总结/" target="_blank" rel="noopener">计算机视觉知识总结</a></p><p><a href="https://baike.baidu.com/item/AUC/19282953?fr=aladdin" target="_blank" rel="noopener">AUC 百度百科</a></p><p><a href="https://zdkswd.github.io/2018/11/20/精确率、召回率、真正类率（TPR）、假正类率（FPR）ROC曲线/" target="_blank" rel="noopener">精确率、召回率、真正类率（TPR）、假正类率（FPR）ROC曲线</a></p><p><a href="https://blog.csdn.net/Libo_Learner/article/details/83615715" target="_blank" rel="noopener">机器学习笔记~F-score beta衡量precision和recall之间重要性</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;基本概念&quot;&gt;&lt;a href=&quot;#基本概念&quot; class=&quot;headerlink&quot; title=&quot;基本概念&quot;&gt;&lt;/a&gt;基本概念&lt;/h1&gt;&lt;h2 id=&quot;混淆矩阵&quot;&gt;&lt;a href=&quot;#混淆矩阵&quot; class=&quot;headerlink&quot; title=&quot;混淆矩阵&quot;&gt;&lt;/a
      
    
    </summary>
    
      <category term="机器学习" scheme="http://a-kali.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="机器学习" scheme="http://a-kali.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="评价指标" scheme="http://a-kali.github.io/tags/%E8%AF%84%E4%BB%B7%E6%8C%87%E6%A0%87/"/>
    
  </entry>
  
  <entry>
    <title>Kaggle 比赛记录之 Severstal: Steel Defect Detection</title>
    <link href="http://a-kali.github.io/2019/09/02/Severstal-Steel-Defect-Detection-%E6%AF%94%E8%B5%9B%E8%AE%B0%E5%BD%95/"/>
    <id>http://a-kali.github.io/2019/09/02/Severstal-Steel-Defect-Detection-比赛记录/</id>
    <published>2019-09-02T02:18:54.000Z</published>
    <updated>2019-10-16T15:08:55.522Z</updated>
    
    <content type="html"><![CDATA[<p>​    看论文看腻了，正好抽空看看隔壁的 Severstal 比赛。希望能吸取一点之前的教训，在这场比赛上好好发挥。</p><h1 id="比赛概览"><a href="#比赛概览" class="headerlink" title="比赛概览"></a>比赛概览</h1><h2 id="描述"><a href="#描述" class="headerlink" title="描述"></a>描述</h2><p>​    大概就是一家中国企业为了提高扁钢的生产质量而希望使用计算机视觉来检测扁钢损坏而发布的一场比赛。</p><h2 id="成绩评价指标"><a href="#成绩评价指标" class="headerlink" title="成绩评价指标"></a>成绩评价指标</h2><p>​    <strong>Dice系数：</strong></p><script type="math/tex; mode=display">Dice(s_1, s_2)=2*\frac{s_1\cap s_2}{s_1+ s_2}</script><p>用于比较两字符串的相似度，大概就是两字符串相同字符的个数乘2比上长度之和。这里应该是用来比较 RLE 编码的相似度。</p><p>​    提交的数据的三分之一用于公榜展示，剩下的三分之二作为最终成绩。这意味着可能比赛结束成绩就出来了。</p><h2 id="比赛时间"><a href="#比赛时间" class="headerlink" title="比赛时间"></a>比赛时间</h2><ul><li><p>2019.10.17 加入比赛、数据公开和组队的截止日期。</p></li><li><p>2019.10.24 提交最终成绩。</p></li><li>2019.11.10 高效奖争夺最终提交。（该比赛的前 50 可以进入高效奖的争夺）</li></ul><h2 id="这是一个-Kernels-only-比赛"><a href="#这是一个-Kernels-only-比赛" class="headerlink" title="这是一个 Kernels-only 比赛"></a>这是一个 Kernels-only 比赛</h2><p>​    最终的提交文件必须在 kernel 上生成，比赛者需要上传模型并在 kernel 上进行最后的测试。并需要满足以下条件：</p><ul><li>单 GPU 情况下运行时间不超过<strong>一小时</strong>。</li><li>断网。</li></ul><h1 id="比赛数据"><a href="#比赛数据" class="headerlink" title="比赛数据"></a>比赛数据</h1><p>​    训练图集、测试图集、训练样本数据和提交样本。每张图占4行csv，分别表示其4种损坏的RLE码。</p><h1 id="EDA"><a href="#EDA" class="headerlink" title="EDA"></a>EDA</h1><p>在做EDA之前先说说自己对数据的想法：</p><ul><li>既然每个样本有 4 种损坏类型，那是不是每种损坏可以单独用一个模型来训练。</li><li>扁钢损坏率似乎不大，这意味着大多数扁钢或许只有1-2种损坏。</li></ul><p>以上有待EDA考究。</p><p>让我们来找一篇<a href="https://www.kaggle.com/go1dfish/clear-mask-visualization-and-simple-eda" target="_blank" rel="noopener">点赞数最多的 EDA</a> 瞅一瞅，得出以下信息：</p><ul><li>训练样本数为 12568，其中有损坏的样本数为 5902，接近一半</li><li>测试样本数为1801</li><li>图片长宽为 (1600, 256)</li><li>四类损坏的数量：{1: 897, 2: 247, 3: 5150, 4: 801}，可见绝大部分损坏都包含第三类损坏</li><li>每个样本具有损坏的种类：{0: 5902, 1: 6239, 2: 425, 3: 2}</li><li>第一类损坏呈密集斑点（猜想）和小矩形状</li><li>第二类损坏呈长条矩形状，似乎是刮损裂纹。竖直长度通常大于横向长度，一张图只有少数损坏。常伴生第一类损坏。</li><li>第三类损坏常呈现大块状，边缘较直，出现概率很高</li><li>第四类损坏扁钢有明显不规则突起，形状十分不规则，常伴生第三类损坏</li></ul><h1 id="疑问"><a href="#疑问" class="headerlink" title="疑问"></a>疑问</h1><ul><li>那个网状的钢是什么？有没有其他形状的？</li><li>有没有哪些易于被混淆的损坏和普通纹路？如果有可以进行可视化来找出原因。</li><li>根据类型比例来设定阈值</li><li>统计各类损坏的密集程度、长宽最大值和最小值以及比例、mask size</li><li>统计两类损坏之间有没有伴生现象</li><li>不同的类型可以使用不同的minsize和阈值</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;​    看论文看腻了，正好抽空看看隔壁的 Severstal 比赛。希望能吸取一点之前的教训，在这场比赛上好好发挥。&lt;/p&gt;
&lt;h1 id=&quot;比赛概览&quot;&gt;&lt;a href=&quot;#比赛概览&quot; class=&quot;headerlink&quot; title=&quot;比赛概览&quot;&gt;&lt;/a&gt;比赛概览&lt;/h
      
    
    </summary>
    
      <category term="计算机视觉" scheme="http://a-kali.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/"/>
    
    
      <category term="计算机视觉" scheme="http://a-kali.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/"/>
    
      <category term="语义分割" scheme="http://a-kali.github.io/tags/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2/"/>
    
      <category term="Kaggle" scheme="http://a-kali.github.io/tags/Kaggle/"/>
    
  </entry>
  
  <entry>
    <title>ResNet (CVPR, 2016)</title>
    <link href="http://a-kali.github.io/2019/09/01/ResNet-CVPR-2016/"/>
    <id>http://a-kali.github.io/2019/09/01/ResNet-CVPR-2016/</id>
    <published>2019-09-01T15:48:36.000Z</published>
    <updated>2019-10-09T02:51:22.799Z</updated>
    
    <content type="html"><![CDATA[<p><strong>论文地址：</strong><a href="https://arxiv.org/abs/1512.03385" target="_blank" rel="noopener">Deep Residual Learning for Image Recognition</a></p><h1 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h1><p>​    众所周知，深度的网络使各层特征和分类器在一个端到端多层网络中融为一个整体，最近的研究也表明网络的深度非常重要。但网络的学习是否像堆积更深层的网络那么简单呢？一个阻碍深层网络学习的阻碍就是臭名昭著的梯度消失和梯度爆炸问题，严重妨碍到神经网络的收敛。这个问题由于归一初始化和中间层归一化的诞生得到了一定的解决，这使得十层以上的神经网络在随机梯度下降的反向传播时也能得到很好的收敛。</p><p>​    然而，实验告诉我们，更深层的神经网络容易表现出<strong>退化</strong>问题（随着层数的加深，准确率达到饱和然后迅速下降），而模型退化的根本原因很大程度上不是因为过拟合，而是因为梯度消失问题。</p><p>​    退化问题表明不是所有的网络结构都能轻易得到优化。假设我们有一个浅层网络和一个深层网络，深层网络的一部分是浅层网络的拷贝，其余部分为恒等映射。在这种情况下深层网络不应该会比浅层网络有更大的误差。<strong>而导致深层网络比浅层网络准确率低的原因是深层网络更难以优化</strong>。</p><p>​    这篇论文将介绍一个深度残差学习框架如何解决退化问题。深度残差框架没有使用直接堆叠网络层来拟合期望的映射函数，而是选择<strong>让这些网络层来拟合一个残差映射</strong>。比如说，我们所期望得到的映射函数射函数为 H(x), 那么我们通过残差函数 F(x) := H(x) - x。那么原始的映射函数就可以通过 F(x) + x 得到。如图所示：</p><p><img src="https://s2.ax1x.com/2019/09/01/nS6Rc8.png" alt="nS6Rc8.png"></p><h1 id="深度残差学习"><a href="#深度残差学习" class="headerlink" title="深度残差学习"></a>深度残差学习</h1><h2 id="残差学习"><a href="#残差学习" class="headerlink" title="残差学习"></a>残差学习</h2><p>​    假设 H(x) 由几个堆叠层组成，其输入为 x，并且其最终能被训练为残差函数 F(x)，即 H(x) = F(x) + x。其也能起到所要求的函数的效果，但是使堆叠层训练成残差函数的难度和使用残差结构训练的难度是不一样的。</p><p>​    引言中所提到的反直觉现象促成了这种重构。如同我们在引言中所讨论的，额外增加的层次如果都是恒等映射，深层模型的不会比浅层模型有更大的误差。退化问题则表明，由多个非线性层的叠加而成的额外层很难近似于恒等映射。<strong>而在残差学习的结构下，如果恒等映射是可选择的，额外层可能会简单地将权重降低至接近0来实现恒等映射。</strong></p><h2 id="快捷恒等映射"><a href="#快捷恒等映射" class="headerlink" title="快捷恒等映射"></a>快捷恒等映射</h2><p>​    我们在每几层之间使用残差学习，如上图的结构。在这篇论文中我们将残差块定义为：</p><script type="math/tex; mode=display">y = F(x,{W_i})+x</script><p>x 和 y 分别表示残差块的输入和输出，函数 F 表示残差映射所需要学习的函数。上图中的 F(x) 为：</p><script type="math/tex; mode=display">F=W_2 \sigma(W_1x)</script><p>其中 σ 表示 ReLU，为了简化写法忽略偏置项。之后 F + x 通过快捷连接来完成，之后再进行一段ReLU。</p><p>​    第一条方程式中的 F 和 x 的维度必须是相等的。如果不是这种情况（比如当改变输入输出通道时），<strong>我们可以添加系数矩阵 $W_s$ 来使得 F 和 x 维度相等</strong>。</p><script type="math/tex; mode=display">y=F(x,W_i)+W_sx</script><p>​    <strong>残差函数 F 的形式时可变的。本文的实验中包含了两层和三层的结构，当然更多层也是可以的，甚至可以用于卷积层。</strong></p><h2 id="网络架构"><a href="#网络架构" class="headerlink" title="网络架构"></a>网络架构</h2><p><img src="https://img-blog.csdn.net/20171218163309386?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvUXVpbmN1bnRpYWw=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt></p><h1 id="ResNet-的意义"><a href="#ResNet-的意义" class="headerlink" title="ResNet 的意义"></a>ResNet 的意义</h1><ul><li><p>从关联性的角度来看，残差结构使得深层网络和浅层网络的关联性更强，输出端的损失能更加有效地调整到浅层网络的参数。当网络层数过深时，优化器会调低网络权重，使得反向传播“选择性地”使用捷径。</p></li><li><p>从函数角度来看，残差结构直接构建了一个更接近”绝对不比浅层网络差“的结构。</p></li></ul><h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><p><a href="https://hellozhaozheng.github.io/z_post/计算机视觉-ResNet-CVPR2016" target="_blank" rel="noopener">从零开始的BLOG</a></p><p><a href="https://blog.csdn.net/Quincuntial/article/details/77263562?locationNum=6" target="_blank" rel="noopener">ResNet 论文翻译</a></p><p><a href="https://arxiv.org/abs/1512.03385" target="_blank" rel="noopener">Deep Residual Learning for Image Recognition</a></p><p>恺明大佬牛逼！</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;strong&gt;论文地址：&lt;/strong&gt;&lt;a href=&quot;https://arxiv.org/abs/1512.03385&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Deep Residual Learning for Image Recognit
      
    
    </summary>
    
    
      <category term="论文解读" scheme="http://a-kali.github.io/tags/%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB/"/>
    
      <category term="计算机视觉" scheme="http://a-kali.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/"/>
    
      <category term="神经网络" scheme="http://a-kali.github.io/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
      <category term="ResNet" scheme="http://a-kali.github.io/tags/ResNet/"/>
    
  </entry>
  
  <entry>
    <title>Aiming to 谷歌机器学习冬令营</title>
    <link href="http://a-kali.github.io/2019/08/29/Aiming-to-%E8%B0%B7%E6%AD%8C%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%86%AC%E4%BB%A4%E8%90%A5/"/>
    <id>http://a-kali.github.io/2019/08/29/Aiming-to-谷歌机器学习冬令营/</id>
    <published>2019-08-29T15:02:43.000Z</published>
    <updated>2019-10-25T07:28:14.212Z</updated>
    
    <content type="html"><![CDATA[<div id="hbe-security">  <div class="hbe-input-container">  <input type="password" class="hbe-form-control" id="pass" placeholder="Please enter the password to read the blog." />    <label for="pass">Please enter the password to read the blog.</label>    <div class="bottom-line"></div>  </div></div><div id="decryptionError" style="display: none;">Incorrect Password!</div><div id="noContentError" style="display: none;">No content to display!</div><div id="encrypt-blog" style="display:none">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</div><script src="/lib/crypto-js.js"></script><script src="/lib/blog-encrypt.js"></script><link href="/css/blog-encrypt.css" rel="stylesheet" type="text/css">]]></content>
    
    <summary type="html">
    
      The article has been encrypted, please enter your password to view.&lt;br&gt;
    
    </summary>
    
      <category term="计划" scheme="http://a-kali.github.io/categories/%E8%AE%A1%E5%88%92/"/>
    
    
      <category term="Google" scheme="http://a-kali.github.io/tags/Google/"/>
    
      <category term="招聘" scheme="http://a-kali.github.io/tags/%E6%8B%9B%E8%81%98/"/>
    
      <category term="机器学习" scheme="http://a-kali.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="计划" scheme="http://a-kali.github.io/tags/%E8%AE%A1%E5%88%92/"/>
    
  </entry>
  
  <entry>
    <title>在深度学习过程中遇到的一些bug及解决方法</title>
    <link href="http://a-kali.github.io/2019/08/29/%E5%9C%A8%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%BF%87%E7%A8%8B%E4%B8%AD%E9%81%87%E5%88%B0%E7%9A%84%E4%B8%80%E4%BA%9Bbug%E5%8F%8A%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95/"/>
    <id>http://a-kali.github.io/2019/08/29/在深度学习过程中遇到的一些bug及解决方法/</id>
    <published>2019-08-29T09:15:55.000Z</published>
    <updated>2019-08-29T09:15:55.619Z</updated>
    
    <summary type="html">
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>《C++ Primer》 第4章 表达式</title>
    <link href="http://a-kali.github.io/2019/08/29/%E3%80%8AC-Primer%E3%80%8B-%E7%AC%AC4%E7%AB%A0-%E8%A1%A8%E8%BE%BE%E5%BC%8F/"/>
    <id>http://a-kali.github.io/2019/08/29/《C-Primer》-第4章-表达式/</id>
    <published>2019-08-29T08:14:27.000Z</published>
    <updated>2019-08-29T08:54:15.557Z</updated>
    
    <content type="html"><![CDATA[<h1 id="4-8-位运算符"><a href="#4-8-位运算符" class="headerlink" title="4.8 位运算符"></a>4.8 位运算符</h1><p><strong>位运算符</strong>主要作用于整型的运算对象，并把运算对象看成是二进制位的集合。</p><ul><li>~ 位求反</li><li>&lt;&lt; 左移</li><li>>&gt; 右移</li><li>&amp; 位与</li><li>^ 位异或</li><li>| 位或</li></ul><h1 id="4-9-sizeof-运算符"><a href="#4-9-sizeof-运算符" class="headerlink" title="4.9 sizeof 运算符"></a>4.9 sizeof 运算符</h1><p>​    <strong>sizeof</strong> 运算符返回的是表达式结果类型的大小，返回类型为 size_t。</p><p>就这样水完一篇博客（ -_-)</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;4-8-位运算符&quot;&gt;&lt;a href=&quot;#4-8-位运算符&quot; class=&quot;headerlink&quot; title=&quot;4.8 位运算符&quot;&gt;&lt;/a&gt;4.8 位运算符&lt;/h1&gt;&lt;p&gt;&lt;strong&gt;位运算符&lt;/strong&gt;主要作用于整型的运算对象，并把运算对象看成是二进制
      
    
    </summary>
    
      <category term="C++" scheme="http://a-kali.github.io/categories/C/"/>
    
    
      <category term="C++" scheme="http://a-kali.github.io/tags/C/"/>
    
  </entry>
  
  <entry>
    <title>《C++ Primer》 第3章 字符串、向量和数组</title>
    <link href="http://a-kali.github.io/2019/08/26/%E3%80%8AC-Primer%E3%80%8B-%E7%AC%AC3%E7%AB%A0-%E5%AD%97%E7%AC%A6%E4%B8%B2%E3%80%81%E5%90%91%E9%87%8F%E5%92%8C%E6%95%B0%E7%BB%84/"/>
    <id>http://a-kali.github.io/2019/08/26/《C-Primer》-第3章-字符串、向量和数组/</id>
    <published>2019-08-25T17:58:39.000Z</published>
    <updated>2019-08-29T03:37:23.617Z</updated>
    
    <content type="html"><![CDATA[<h1 id="3-1-命名空间的-using-声明"><a href="#3-1-命名空间的-using-声明" class="headerlink" title="3.1 命名空间的 using 声明"></a>3.1 命名空间的 using 声明</h1><p>​    <strong>域操作符</strong>（::）的含义是：编译器应从操作符左侧名字所示作用域中寻找右侧那个名字。因此，std::cin 的意思就是要使用命名空间 std 中的名字 cin。而使用 <strong>using 声明</strong>后则无需专门的前缀也能使用所需的名字了。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">using</span> <span class="built_in">std</span>::<span class="built_in">cin</span>;</span><br><span class="line"><span class="keyword">int</span> i;</span><br><span class="line"><span class="built_in">cin</span> &gt;&gt; i;</span><br></pre></td></tr></table></figure><p>更方便的方法：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br></pre></td></tr></table></figure><p>这样就可以使用 std 命名空间中所有的名字了。</p><h1 id="3-2-标准库类型-string"><a href="#3-2-标准库类型-string" class="headerlink" title="3.2 标准库类型 string"></a>3.2 标准库类型 string</h1><p>​    标准库类型 <strong>string</strong> 表示可变长的字符序列，使用 string 类型必须首先包含 string 头文件。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;string&gt; // 包含 string 头文件</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="built_in">std</span>::<span class="built_in">string</span>; <span class="comment">// string 定义在命名空间 std 中</span></span><br></pre></td></tr></table></figure><h2 id="3-2-1-定义和初始化-string-对象"><a href="#3-2-1-定义和初始化-string-对象" class="headerlink" title="3.2.1 定义和初始化 string 对象"></a>3.2.1 定义和初始化 string 对象</h2><p>​    如何初始化类的对象是由类本身决定的。如下是初始化 string 对象的常用方式：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="built_in">string</span> <span class="title">s1</span><span class="params">(s2)</span></span>;</span><br><span class="line"><span class="built_in">string</span> s1 = s2;    <span class="comment">// 同上</span></span><br><span class="line"><span class="function"><span class="built_in">string</span> <span class="title">s1</span><span class="params">(n, <span class="string">'c'</span>)</span>  <span class="comment">// 将s1初始化为由连续n个'c'组成的字符串</span></span></span><br></pre></td></tr></table></figure><h2 id="3-2-2-string-对象上的操作"><a href="#3-2-2-string-对象上的操作" class="headerlink" title="3.2.2 string 对象上的操作"></a>3.2.2 string 对象上的操作</h2><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">os &lt;&lt; s; <span class="comment">// output stream</span></span><br><span class="line">is &gt;&gt; s; <span class="comment">// 输入到s，字符串以空白分隔</span></span><br><span class="line">getline(is, s); <span class="comment">// 从is中读取一行到s</span></span><br><span class="line">s.empty();</span><br><span class="line">s.size();</span><br><span class="line">s[n];</span><br><span class="line">s1 + s2;</span><br><span class="line">&lt;, &lt;=, &gt;, &gt;=  <span class="comment">// 利用字符在字典中的顺序进行比较，大小写敏感</span></span><br></pre></td></tr></table></figure><h3 id="读写-string-对象"><a href="#读写-string-对象" class="headerlink" title="读写 string 对象"></a>读写 string 对象</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cin</span> &gt;&gt; s; <span class="comment">// 将 string 对象读入 s，遇到空白停止</span></span><br><span class="line"><span class="built_in">cin</span> &gt;&gt; s1 &gt;&gt; s2;   <span class="comment">// 把第一个输入到s1中，第二个输入到s2中</span></span><br></pre></td></tr></table></figure><h2 id="3-2-3-处理-string-对象中的字符"><a href="#3-2-3-处理-string-对象中的字符" class="headerlink" title="3.2.3 处理 string 对象中的字符"></a>3.2.3 处理 string 对象中的字符</h2><p>​    <strong>cctype头文件</strong>中定义了一组标准库函数来处理 string 对象中的字符。比如判断字符是否为数字、字母、控制字符、可打印字符、大写、小写、标点等，以及大小写转换。（p82）</p><h3 id="基于范围的-for-语句"><a href="#基于范围的-for-语句" class="headerlink" title="基于范围的 for 语句"></a>基于范围的 for 语句</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> (declaration: expression)  <span class="comment">// 跟python中 for declaration in expresson 类似</span></span><br><span class="line">    statement</span><br><span class="line"><span class="comment">// 举例    </span></span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">auto</span> c : str)</span><br><span class="line">    <span class="built_in">cout</span> &lt;&lt; c &lt;&lt; <span class="built_in">endl</span>;</span><br></pre></td></tr></table></figure><h3 id="使用范围-for-语句改变字符串中的字符"><a href="#使用范围-for-语句改变字符串中的字符" class="headerlink" title="使用范围 for 语句改变字符串中的字符"></a>使用范围 for 语句改变字符串中的字符</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> (<span class="keyword">auto</span> &amp;c : str)  <span class="comment">// c是一个引用，故赋值语句将改变s中字符的值</span></span><br><span class="line">    c = <span class="built_in">toupper</span>(c);</span><br></pre></td></tr></table></figure><h1 id="3-3-标准库类型-vector"><a href="#3-3-标准库类型-vector" class="headerlink" title="3.3 标准库类型 vector"></a>3.3 标准库类型 vector</h1><p>​    标准库类型 <strong>vector</strong> 表示对象的集合，其中所有对象的类型都相同。集合中每个对象都有一个与之对应的索引，索引用于访问对象。因为 vectot 容纳着其他对象，所以它也常被称作<strong>容器</strong>。</p><p>​    使用 vector：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta"># <span class="meta-keyword">include</span> <span class="meta-string">&lt;vector&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="built_in">std</span>::<span class="built_in">vector</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; ivec;  <span class="comment">// 定义一个能容纳int类型集合的对象</span></span><br><span class="line"><span class="built_in">vector</span>&lt;Sales_item&gt; Sales_vec;</span><br><span class="line"><span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="built_in">string</span>&gt;&gt; file;</span><br></pre></td></tr></table></figure><p>vector 能容纳绝大多数类型的对象作为其元素。</p><h2 id="3-3-1-定义和初始化-vector-对象"><a href="#3-3-1-定义和初始化-vector-对象" class="headerlink" title="3.3.1 定义和初始化 vector 对象"></a>3.3.1 定义和初始化 vector 对象</h2><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">vector</span>&lt;T&gt; v1;</span><br><span class="line"><span class="built_in">vector</span>&lt;T&gt; v2(v1);</span><br><span class="line"><span class="built_in">vector</span>&lt;T&gt; v3 = v1;</span><br><span class="line"><span class="built_in">vector</span>&lt;T&gt; v4(n, val);</span><br><span class="line"><span class="built_in">vector</span>&lt;T&gt; v5(n);</span><br><span class="line"><span class="built_in">vector</span>&lt;T&gt; v6&#123;a,b,c...&#125;;</span><br><span class="line"><span class="built_in">vector</span>&lt;T&gt; v7 = &#123;a,b,c...&#125;;</span><br></pre></td></tr></table></figure><h2 id="3-3-2-向-vector-对象中添加元素"><a href="#3-3-2-向-vector-对象中添加元素" class="headerlink" title="3.3.2 向 vector 对象中添加元素"></a>3.3.2 向 vector 对象中添加元素</h2><p>​    vector 的成员函数 <strong>push_back()</strong> 能将一个元素添加到 vector 的尾端。</p><h2 id="3-3-3-其他-vector-操作"><a href="#3-3-3-其他-vector-操作" class="headerlink" title="3.3.3 其他 vector 操作"></a>3.3.3 其他 vector 操作</h2><p>​    跟 string 差不多。</p><h1 id="3-4-迭代器介绍"><a href="#3-4-迭代器介绍" class="headerlink" title="3.4 迭代器介绍"></a>3.4 迭代器介绍</h1><p>​    <strong>迭代器</strong>能用于访问 string 对象和 vector 对象的元素，并且所有的标准库容器都能使用迭代器。使用迭代器能访问某个元素，迭代器也能从一个元素移动到另外一个元素。</p><h2 id="3-4-1-使用迭代器"><a href="#3-4-1-使用迭代器" class="headerlink" title="3.4.1 使用迭代器"></a>3.4.1 使用迭代器</h2><p>​    能使用迭代器的类型都拥有能返回迭代器的成员函数，比如 <strong>begin</strong> 和 <strong>end</strong>。其中 begin 成员负责指向第一个元素，end 成员则负责指向容器（或 string 对象）的”尾元素的下一个位置“的迭代器。end 成员返回的迭代器常被称为<strong>尾后迭代器</strong>。如果容器为空，则 begin 和 end 返回的是同一个元素。</p><h3 id="迭代器运算符"><a href="#迭代器运算符" class="headerlink" title="迭代器运算符"></a>迭代器运算符</h3><ul><li>*iter              返回迭代器iter所指元素的引用</li><li>iter-&gt;men  相当于(*iter).men</li><li>++iter           令 iter 指向容器下一个元素，同理有 —iter，iter + n，iter1 - iter2 等</li><li>iter1 &gt; iter2 比较位置关系，靠后的值大</li></ul><h3 id="迭代器类型"><a href="#迭代器类型" class="headerlink" title="迭代器类型"></a>迭代器类型</h3><p> 拥有迭代器迭代器的标准库类型使用 iterator 和 const_iterator 来表示迭代器的类型。<strong>const_iterator</strong> 和常量指针差不多，能读但不能修改所指元素的值，而 <strong>iterator</strong> 所指的对象可读可写。 如果容器对象是一个常量，则只能使用 const_iterator；否则两种类型都能使用。</p><h3 id="容器操作使迭代器失效"><a href="#容器操作使迭代器失效" class="headerlink" title="容器操作使迭代器失效"></a>容器操作使迭代器失效</h3><p>​    谨记，但凡是使用了迭代器的循环体，都不要向迭代器所属的容器添加元素。</p><h1 id="3-5-数组"><a href="#3-5-数组" class="headerlink" title="3.5 数组"></a>3.5 数组</h1><p>​    <strong>数组</strong> 是一种类似标准库类型 vector 的数据结构，与 vector 不同的是数组大小固定，不能随意向数组中增加元素。</p><h2 id="3-5-1-定义和初始化内置数组"><a href="#3-5-1-定义和初始化内置数组" class="headerlink" title="3.5.1 定义和初始化内置数组"></a>3.5.1 定义和初始化内置数组</h2><h3 id="显式初始化数组元素"><a href="#显式初始化数组元素" class="headerlink" title="显式初始化数组元素"></a>显式初始化数组元素</h3><p>​    如果声明时没有指明维度，编译器会根据初始值的数量计算并推断出来；如果指明了维度，那么初始值的总数量不应该超出指定的大小。</p><h3 id="字符数组的特殊性"><a href="#字符数组的特殊性" class="headerlink" title="字符数组的特殊性"></a>字符数组的特殊性</h3><p>​    当使用字符串字面值初始化字符数组时，一定要注意字符串字面值的结尾处还有一个隐藏的空字符，这个空字符也会像字符串的其它字符一样被拷贝到数组里去。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">char</span> a1[<span class="number">3</span>] = &#123;<span class="string">'c'</span>, <span class="string">'p'</span>, <span class="string">'p'</span>&#125;;  <span class="comment">// 正确</span></span><br><span class="line"><span class="keyword">char</span> a2[<span class="number">4</span>] = <span class="string">"cpp"</span>;            <span class="comment">// 正确</span></span><br><span class="line"><span class="keyword">char</span> a3[<span class="number">3</span>] = <span class="string">"cpp"</span>;            <span class="comment">// 错误</span></span><br></pre></td></tr></table></figure><h3 id="理解复杂的数组声明"><a href="#理解复杂的数组声明" class="headerlink" title="理解复杂的数组声明"></a>理解复杂的数组声明</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> *ptrs[<span class="number">10</span>];                  <span class="comment">// ptrs是含有10个整型指针的数组</span></span><br><span class="line"><span class="keyword">int</span> &amp;refs[<span class="number">10</span>] = <span class="comment">/*?*/</span>;          <span class="comment">// 错误：不存在引用的数组</span></span><br><span class="line"><span class="keyword">int</span> (*Parray)[<span class="number">10</span>];              <span class="comment">// Parray指向一个整型数组</span></span><br><span class="line"><span class="keyword">int</span> (&amp;arrRef)[<span class="number">10</span>];              <span class="comment">// arrRef引用一个整型数组</span></span><br></pre></td></tr></table></figure><h2 id="3-5-3-指针和数组"><a href="#3-5-3-指针和数组" class="headerlink" title="3.5.3 指针和数组"></a>3.5.3 指针和数组</h2><p>​    数组类型的对象其实是一个指向该数组首元素的指针。该指针也是一个迭代器。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;3-1-命名空间的-using-声明&quot;&gt;&lt;a href=&quot;#3-1-命名空间的-using-声明&quot; class=&quot;headerlink&quot; title=&quot;3.1 命名空间的 using 声明&quot;&gt;&lt;/a&gt;3.1 命名空间的 using 声明&lt;/h1&gt;&lt;p&gt;​    &lt;
      
    
    </summary>
    
      <category term="C++" scheme="http://a-kali.github.io/categories/C/"/>
    
    
      <category term="C++" scheme="http://a-kali.github.io/tags/C/"/>
    
  </entry>
  
  <entry>
    <title>Kaggle 比赛记录之 SIIM-ACR Pneumothorax Segmentation</title>
    <link href="http://a-kali.github.io/2019/08/21/SIIM%E6%AF%94%E8%B5%9B%E4%B8%AD%E9%81%87%E5%88%B0%E7%9A%84%E7%9F%A5%E8%AF%86%E7%9B%B2%E5%8C%BA/"/>
    <id>http://a-kali.github.io/2019/08/21/SIIM比赛中遇到的知识盲区/</id>
    <published>2019-08-21T14:23:24.000Z</published>
    <updated>2019-09-12T12:35:10.317Z</updated>
    
    <content type="html"><![CDATA[<h1 id="记事"><a href="#记事" class="headerlink" title="记事"></a>记事</h1><p>​    随着 <a href="https://www.kaggle.com/c/siim-acr-pneumothorax-segmentation" target="_blank" rel="noopener">Kaggle: SIIM-ACR Pneumothorax Segmentation</a> 接近尾声，我感觉有必要写一篇 blog 来记录一下这两个月的比赛经历，顺便总结一下经验。</p><p>​    刚开始的时候想着这不过是一场普通CV类的比赛而已，肝一肝就能上金牌。但现实狠狠地打了我的脸。最初三天看了看比赛规则，了解了下RLE等语义分割的基本概念，看了看各路大佬的EDA，算是入了个小门。随后就一直沉沦在MMDetection和COCO格式的配置中，由于网上资料太少太旧，导致我花了整整15天才把程序跑通orz，还是在各路大神的帮助下。详情可参考另一篇博客：<a href="https://a-kali.github.io/2019/08/04/%E4%BD%BF%E7%94%A8MMDetection%E8%BF%9B%E8%A1%8C%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2/#more">使用MMDetection进行语义分割</a>。最后出的结果也非常地不尽人意，分数才 0.6+，而把所有预测结果全填上 -1 都有 0.78 分，着实难搞&#x1F611;。</p><p>​    中间一个月基本在走亲访友旅游摸鱼，直到八月中旬回学校，才重回赛场，放弃了MMDetection，找了个比较高分的<a href="https://www.kaggle.com/rishabhiitbhu/unet-with-resnet34-encoder-pytorch" target="_blank" rel="noopener">PyTorch baseline</a>，开始调参，也算是为这场比赛正式拉开了序幕（虽然只剩半个月了）。</p><p>Baseline细节：</p><ul><li>网络模型：UNet + ResNet34，使用imagenet进行预训练</li><li>输入图片尺寸：512 * 512 （为了更加贴近模型预训练时使用的图片尺寸）</li><li>训练集：验证集 = 4：1，使用 sklearn 中的 StratifiedKFold 进行五折划分</li><li>在验证集和训练集中，正负样本数量1：1</li><li>学习率策略：ReduceLROnPlateau</li><li>Loss：Focal Loss &amp; Dice Loss</li><li>优化器：Adam</li><li>最优模型选择：根据Loss的值进行选择，loss越小模型越优</li><li>生成结果时，单个分割区域的最少像素数：min_size == 3500</li><li>输出：1024*1024 的概率矩阵（因为原数据图像大小是 1024*1024），每个元素对应像素点属于 mask 的概率。最后用一个 sigmoid 函数生成 mask</li></ul><p>虽然是个分数挺高的 baseline，但还是有一些瑕疵：</p><ul><li>某行代码的 ‘!=’ 写成了 ‘==’</li><li>Trainer 类里的部分属性与下面传入函数的参数不是同一个变量，导致改了属性后传入的参数依然没改</li><li>验证时没有加 with torch.no_grad() 导致显存溢出</li><li>对数据去重的时候把单图多分割区域给删成了单图单分割区域</li></ul><p>改完上述问题后单 resnet34 分数能上 0.84+。</p><p>​    改完 bug 后第一步，把模型换成 SENet154 &#x1F60F;，单折 0.855 左右，好像海星的亚子。</p><p>​    随后又测了 SE_ReNeXt101、EfficientUNet_B5、DPN131、DenseNet201、DenseNet121等模型，但只有 EfficientUNet_B5 能跟 SENet154 不相上下，而其他模型基本跟 ResNet34 差不多。</p><p>​    对 SENet154 进行五折交叉验证，分数提高到 0.863。</p><p>​    对 EfficientUNet_B5、ResNet34、SENet154 三模型进行等比例融合、min_size == 3000，分数提高到 0.869。同时 EfficientUNet_B5、SENet154 双模型 、min_size == 2800，分数提高到 0.868。</p><p>​    使用 EfficientNet 单独进行二分类，将二分类中的负样本对应的预测样本替换成负样本，结果不理想，大概多模型融合后的分类能力已经很强了。</p><p>​    对 EfficientUNet_B5、ResNet34、SENet154、SE_ReNeXt101 四模型按 3:2:3:2 的比例进行融合，min_size == 3000，分数提高到 0.8694。</p><p>​    与此同时的另一边使用了 chexnet 进行二分类，将二分类的正样本对应的三模型预测样本的min_size降低到2500，负样本保持3000，将三模型的分数也提升到了 0.8694 。在 public leaderboard 排行60名，位于银牌区。</p><p>​    可是离金牌还有 0.01 分的差距，光是这样调参怕是很难上金牌&#x1F62A;  —— 2019.8.28</p><p>​    比赛进入第二阶段，更换了测试集。以新测试集的 1% 数据的成绩作为公榜成绩，剩下 99% 作为最终成绩。—— 2019.8.31</p><h1 id="盲区"><a href="#盲区" class="headerlink" title="盲区"></a>盲区</h1><p>FocalLoss和diceLoss的实现细节和应用场景</p><p>Unet、Unet++、FastRCNN、MaskRCNN、FPN、DCN、Cascade、SENet、efficientNet的技术细节</p><p>学习率的相关优化算法及应用场景，如ReduceLROnPlateau、warm up</p><p>threshold的调整策略</p><p>PyTorch实战经验不足，baseline的自主编写</p><p>新兴模型复现</p><h1 id="疑问"><a href="#疑问" class="headerlink" title="疑问"></a>疑问</h1><ul><li><p>Q：为什么将训练集中的正负样本划为1：1能提高分数？</p><p>A：能避免模型分类时倾向某一方，减少在分类时出现的错误。</p></li><li><p>Q：代码中最佳模型的评判标准为什么不是iOU而是loss？</p><p>A：因为比赛分数的评判标准是Dice Loss</p></li><li><p>Q：每次五折验证的选择是否相同？</p><p>A：是。StratifiedKFold在随机种子不变的情况下，每次五折交叉验证选择的样本都是相同的。</p></li></ul><h1 id="改进"><a href="#改进" class="headerlink" title="改进"></a>改进</h1><p>下次比赛一定要记录每个模型提交的参数、文件和分数啊啊啊啊，不然最后多模型融合的时候不知道如何分配权重</p><p>通过对比两份分数的高低和csv的差别，是否能确定哪些预测是对的（好像有点场外）</p><p>下次比赛要从头跟到尾，这样能尝试到更多的tips和参数</p><h1 id="高分-Solution"><a href="#高分-Solution" class="headerlink" title="高分 Solution"></a>高分 Solution</h1><h2 id="1st-place-solution"><a href="#1st-place-solution" class="headerlink" title="1st place solution"></a><a href="https://www.kaggle.com/c/siim-acr-pneumothorax-segmentation/discussion/107824" target="_blank" rel="noopener">1st place solution</a></h2><h2 id="2rd-place-solution"><a href="#2rd-place-solution" class="headerlink" title="2rd place solution"></a><a href="https://www.kaggle.com/c/siim-acr-pneumothorax-segmentation/discussion/108009#latest-622580" target="_blank" rel="noopener">2rd place solution</a></h2><h2 id="3rd-place-solution"><a href="#3rd-place-solution" class="headerlink" title="3rd place solution"></a><a href="https://www.kaggle.com/c/siim-acr-pneumothorax-segmentation/discussion/108009#latest-622580" target="_blank" rel="noopener">3rd place solution</a></h2><h2 id="4th-place-solution"><a href="#4th-place-solution" class="headerlink" title="4th place solution"></a><a href="https://www.kaggle.com/c/siim-acr-pneumothorax-segmentation/discussion/108397#latest-624615" target="_blank" rel="noopener">4th place solution</a></h2><h2 id="5th-place-solution"><a href="#5th-place-solution" class="headerlink" title="5th place solution"></a><a href="https://www.kaggle.com/c/siim-acr-pneumothorax-segmentation/discussion/107603#latest-620358" target="_blank" rel="noopener">5th place solution</a></h2><ul><li>基于半监督学习，在网络添加了二分类器。</li><li>网络模型：带有 ASPP 结构的 UNet（ASPP 为 DeepLabV3+中的一种结构）</li><li>Backbone：se50 &amp; se101</li><li>图片尺寸：1024*1024</li><li>优化器：Adam</li><li>损失函数：1024 * BCE(results, masks) + BCE(cls, cls_target)</li><li>半监督学习：mean-teacher[1-2] with NIH Dataset </li></ul><p>mean-teacher 参考资料：</p><p>[1] <a href="https://github.com/CuriousAI/mean-teacher" target="_blank" rel="noopener">https://github.com/CuriousAI/mean-teacher</a><br>[2] <a href="https://arxiv.org/pdf/1703.01780.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1703.01780.pdf</a></p><h2 id="6th-place-solution"><a href="#6th-place-solution" class="headerlink" title="6th place solution"></a><a href="https://www.kaggle.com/c/siim-acr-pneumothorax-segmentation/discussion/107743#latest-620263" target="_blank" rel="noopener">6th place solution</a></h2><ul><li>网络模型<ul><li>EncodingNet (ResNets, 512 and 1024 size)</li><li>UNet (EfficientNet4, se-resnext50, SENet154 with 512, 640 and 1024 sizes)</li></ul></li><li>数据增强：Crops 和 Rotations 类型的增强</li><li>损失函数：BCE + Dice （表示FocalLoss不太好用）</li><li>比起原始尺寸的图像，小尺寸图像会少很多分</li><li>Tricks：<ul><li>在 EncodingNet 使用了 11 种 TTA</li><li>删除了预测结果种面积小的mask</li></ul></li></ul><h2 id="8th-place-solution"><a href="#8th-place-solution" class="headerlink" title="8th place solution"></a><a href="https://www.kaggle.com/c/siim-acr-pneumothorax-segmentation/discussion/107522#latest-619268" target="_blank" rel="noopener">8th place solution</a></h2><ul><li>数据分割：10%分出来用于融合(ensemble)，在剩下90%的数据里进行十折交叉验证</li><li>模型架构：DeepLabV3</li><li>Backbone：使用了组归一化的ResNet50/101 和 ResNeXt50/101</li><li>损失函数：BCE（在所有图像上训练）或者 Dice（只在正样本上训练）</li><li>优化器：Vanilla SGD, momentum 0.9</li><li>训练：<ul><li>batch size 4, 1024 x 1024</li><li>batch size 1, 1280 x 1280</li></ul></li><li>学习率策略：余弦退火，LR 0.01-0.0001</li><li>模型融合：<ul><li>4 个模型使用 Dice 损失函数，在正样本上训练</li><li>8 个模型使用 BCE 损失函数，在所有样本上训练。其中四个作为分类器使用</li><li>Max pixel value was taken as classification score, averaged across 4 models</li><li>Multiplied pixel-level scores from 4 models trained on positives only by this classification score, then averaged</li><li>Final ensemble: multiplied score as above averaged with pixel-level scores based on other 4/8 models trained on all images</li></ul></li><li>TTA：Hflip</li><li>后处理：删除了大小小于2048像素的mask（stage2），stage1中为4096像素</li></ul><p>没起到效果的工作：</p><ul><li>使用了Unet, LinkNet, PSPNet, EncNet, HRNet等架构，但效果没有DeepLab好</li><li>SGD 的效果比 Adam, Adabound 优化器的效果更好</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;记事&quot;&gt;&lt;a href=&quot;#记事&quot; class=&quot;headerlink&quot; title=&quot;记事&quot;&gt;&lt;/a&gt;记事&lt;/h1&gt;&lt;p&gt;​    随着 &lt;a href=&quot;https://www.kaggle.com/c/siim-acr-pneumothorax-segmen
      
    
    </summary>
    
      <category term="计算机视觉" scheme="http://a-kali.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/"/>
    
    
      <category term="计算机视觉" scheme="http://a-kali.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/"/>
    
      <category term="语义分割" scheme="http://a-kali.github.io/tags/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2/"/>
    
      <category term="Kaggle" scheme="http://a-kali.github.io/tags/Kaggle/"/>
    
      <category term="PyTorch" scheme="http://a-kali.github.io/tags/PyTorch/"/>
    
  </entry>
  
  <entry>
    <title>《C++ Primer》 第2章 变量和基本类型</title>
    <link href="http://a-kali.github.io/2019/08/20/%E3%80%8AC-Primer%E3%80%8B-%E7%AC%AC2%E7%AB%A0-%E5%8F%98%E9%87%8F%E5%92%8C%E5%9F%BA%E6%9C%AC%E7%B1%BB%E5%9E%8B/"/>
    <id>http://a-kali.github.io/2019/08/20/《C-Primer》-第2章-变量和基本类型/</id>
    <published>2019-08-20T12:41:12.000Z</published>
    <updated>2019-08-27T15:50:13.718Z</updated>
    
    <content type="html"><![CDATA[<p>数据类型决定了程序中数据和操作的意义。</p><h1 id="2-1-基本内置类型"><a href="#2-1-基本内置类型" class="headerlink" title="2.1 基本内置类型"></a>2.1 基本内置类型</h1><h2 id="2-1-1-算术类型"><a href="#2-1-1-算术类型" class="headerlink" title="2.1.1 算术类型"></a>2.1.1 算术类型</h2><p>​    算术类型分为两类：<strong>整型</strong>（包括字符和布尔型在内）和<strong>浮点型</strong>。</p><h3 id="带符号类型和无符号类型"><a href="#带符号类型和无符号类型" class="headerlink" title="带符号类型和无符号类型"></a>带符号类型和无符号类型</h3><p>​    除去布尔型和扩展的字符型之外，其他整形可以划分为<strong>带符号的</strong>（signed）和<strong>无符号的</strong>（unsigned）。带符号类型可以表示正数、负数或0，而无符号类型则仅能表示大于等于0的值。</p><p>​    类型 int、short、long 和 long long 都是带符号的，通过在这些类型名前添加<strong>unsigned</strong> 就可以得到无符号类型。其中 unsigned int 可以缩写为 unsigned。</p><p>​    与其他整型不同，<strong>字符型</strong>被分为了三种：char、signed char 和 unsigned char。但字符型的表现形式只有两种：带符号型和无符号型，char 的实际表现为哪种又编译器决定。</p><p>​    无符号类型中所有的比特都用来存储值。</p><h2 id="2-1-2-类型转换"><a href="#2-1-2-类型转换" class="headerlink" title="2.1.2 类型转换"></a>2.1.2 类型转换</h2><p>类型所能表示的值的范围决定了转换的过程：</p><ul><li>非布尔 → 布尔：除 0 以外均为 true。</li><li>布尔 → 非布尔：false → 0，true → 1。</li><li>浮点数 → 整数：保留小数点前的部分。</li><li>给无符号数赋值超范围：结果为取模后的余数。</li></ul><h3 id="含有无符号类型的表达式"><a href="#含有无符号类型的表达式" class="headerlink" title="含有无符号类型的表达式"></a>含有无符号类型的表达式</h3><p>​    当一个表达式中既有无符号数又有 int 值时，那个 int 值就会转换成无符号数。若 int 值为负数，则相当于将负数赋值给一个无符号数并运算，会产生意料之外的结果。</p><h2 id="2-1-3-字面值常量"><a href="#2-1-3-字面值常量" class="headerlink" title="2.1.3 字面值常量"></a>2.1.3 字面值常量</h2><p>​    每个字面值常量都对应着一种数据类型，字面值常量的形式和值决定了它的数据类型。</p><h3 id="整型和浮点型字面值"><a href="#整型和浮点型字面值" class="headerlink" title="整型和浮点型字面值"></a>整型和浮点型字面值</h3><p>​    我们可以将<strong>整型字面值</strong>写作十进制数、八进制数和十六进制数的形式。以 0 开头的整数代表八进制数，以 0x 或0X 开头的代表十六进制数。</p><p>​    整型字面值具体的数据类型由它的值和符号决定。默认情况下，十进制字面值的类型是能容纳当前值的最小带符号数类型，而八进制和十六进制字面值既可能是带符号的也可能是无符号的。</p><p>​    <strong>浮点型字面值</strong>表现为一个小数或以科学记数法表示的指数，默认类型为double。</p><h3 id="字符和字符串字面值"><a href="#字符和字符串字面值" class="headerlink" title="字符和字符串字面值"></a>字符和字符串字面值</h3><p>​    由单引号括起来的一个字符称为<strong>字符型字面值</strong>，双引号括起来的零个或多个字符则构成<strong>字符串型字面值</strong>。</p><p>​    字符串字面值的类型实际上是由常量字符构成的数组，编译器在每个字符串的结尾添加一个空字符（’\0’），因此字面值实际长度比它的内容多 1。</p><h3 id="布尔字面值和指针字面值"><a href="#布尔字面值和指针字面值" class="headerlink" title="布尔字面值和指针字面值"></a>布尔字面值和指针字面值</h3><p>​    true 和 false 是<strong>布尔类型的字面值</strong>。</p><h1 id="2-2-变量"><a href="#2-2-变量" class="headerlink" title="2.2 变量"></a>2.2 变量</h1><p>​    <strong>变量</strong>提供一个具名的、可供程序操作的存储空间。C++ 中每个变量都有其数据类型，数据类型决定变量所占内存空间的大小和布局方式等。对 C++ 程序员来说，“变量”和“对象”一般可以互换使用。</p><h2 id="2-2-1-变量定义"><a href="#2-2-1-变量定义" class="headerlink" title="2.2.1 变量定义"></a>2.2.1 变量定义</h2><h3 id="初始值"><a href="#初始值" class="headerlink" title="初始值"></a>初始值</h3><p>​    当对象在创建时获得了一个特定的值，我们说这个对象被<strong>初始化</strong>了。初始化不等同于赋值，赋值的含义是把对象的当前值擦除，以一个新的值替代。</p><h3 id="列表初始化"><a href="#列表初始化" class="headerlink" title="列表初始化"></a>列表初始化</h3><p>初始化问题复杂性，e.g. 定义一个名为 sold 的 int 变量并初始化为 0，以下代码均可实现：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> sold = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">int</span> sold = &#123;<span class="number">0</span>&#125;;</span><br><span class="line"><span class="keyword">int</span> sold&#123;<span class="number">0</span>&#125;;</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">sold</span><span class="params">(<span class="number">0</span>)</span></span>;</span><br></pre></td></tr></table></figure><p>用花括号来初始化变量的形式被称为<strong>列表初始化</strong>。</p><h2 id="2-2-2-变量声明和定义的关系"><a href="#2-2-2-变量声明和定义的关系" class="headerlink" title="2.2.2 变量声明和定义的关系"></a>2.2.2 变量声明和定义的关系</h2><p>​    为了允许把程序拆分成多个逻辑部分来编写，C++语言支持<strong>分离式编译</strong>机制，该机制允许将程序分割为若干个文件，每个文件可被独立编译。</p><p>​    为了支持分离式编译，C++将声明和定义区分开来。<strong>声明</strong>使得名字为程序所知，<font color="red">一个文件如果想使用别处定义的名字则必须包含对那个名字的声明</font>。而<strong>定义</strong>负责创建与名字关联的实体。声明和定义都规定了变量的类型和名字，而并以还包括了申请空间，也可能会为变量赋予初始值。</p><p>​    如果想声明一个变量而非定义，就在变量名前添加<strong>关键字extern</strong>，而且不要显示地初始化变量：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">extern</span> <span class="keyword">int</span> i; <span class="comment">// 声明i而非定义i</span></span><br><span class="line"><span class="keyword">int</span> j;        <span class="comment">// 声明并定义j</span></span><br></pre></td></tr></table></figure><p>​    变量只能被定义一次，但可以被多次声明。如果要在多个文件中使用同一个变量，就必须将声明和定义分离。此时变量的定义必须且只能出现在一个文件中，而其他用到该变量的文件必须且只能对其声明。</p><h1 id="2-3-复合类型"><a href="#2-3-复合类型" class="headerlink" title="2.3 复合类型"></a>2.3 复合类型</h1><p>​    <strong>复合类型</strong>是指基于其他类型定义的类型，其中两种为引用和指针。</p><h2 id="2-3-1-引用"><a href="#2-3-1-引用" class="headerlink" title="2.3.1 引用"></a>2.3.1 引用</h2><p>​    <strong>引用</strong>为对象起了另一个名字，引用类型引用另外一种类型。通过将声明符写成&amp;d的形式来定义引用类型，其中d是声明时的变量名：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> ival = <span class="number">1024</span>;     <span class="comment">// 声明了变量名为ival</span></span><br><span class="line"><span class="keyword">int</span> &amp;refVal = ival;  <span class="comment">// 此时refVal成了该变量的第二个名字</span></span><br></pre></td></tr></table></figure><h2 id="2-3-2-指针"><a href="#2-3-2-指针" class="headerlink" title="2.3.2 指针"></a>2.3.2 指针</h2><p>​    <strong>指针</strong>时“指向”另外一种类型的复合类型。定义指针类型的方法将声明符写成 *d 的形式，其中 d 是变量名。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> ip1, *ip2; <span class="comment">//ip1是int型对象，ip2是指向一个int型对象的指针</span></span><br></pre></td></tr></table></figure><h3 id="获取对象的地址"><a href="#获取对象的地址" class="headerlink" title="获取对象的地址"></a>获取对象的地址</h3><p>​    指针存放某个对象的地址，要想获取该地址，需要使用<strong>取地址符（&amp;）</strong>。</p><h3 id="利用指针访问对象"><a href="#利用指针访问对象" class="headerlink" title="利用指针访问对象"></a>利用指针访问对象</h3><p>​    如果指针指向了一个对象，则允许使用<strong>解引用符（*）</strong>来访问该对象。</p><hr><p>Note：引用声明符&amp;、指针声明符*、取地址操作符&amp;、解引用符* 所代表的含义各不相同。</p><hr><h3 id="空指针"><a href="#空指针" class="headerlink" title="空指针"></a>空指针</h3><p>​    <strong>空指针</strong>不指向任何对象，在试图使用一个空指针之前代码可以首先检查它是否为空。以下是三种等价的生成空指针的方法：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> *p1 = <span class="literal">nullptr</span>;</span><br><span class="line"><span class="keyword">int</span> *p2 = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">int</span> *p3 = <span class="literal">NULL</span>;</span><br></pre></td></tr></table></figure><h3 id="void-指针"><a href="#void-指针" class="headerlink" title="void* 指针"></a>void* 指针</h3><p>​    <strong>void*</strong>指针可用于存放任意对象的地址。但由于我们并不知道这个对象到底是什么类型，也就无法确定能在这个对象上做哪些操作，故不能直接操作void*指针所指的对象。</p><h2 id="2-3-3-理解复合类型的声明"><a href="#2-3-3-理解复合类型的声明" class="headerlink" title="2.3.3 理解复合类型的声明"></a>2.3.3 理解复合类型的声明</h2><p>​    类型修饰符仅仅只是在声明时修饰了变量，并不能作为类型的一部分，且对与该声明语句中的其他变量不产生任何作用。</p><p>​    声明语句中的修饰符没有个数限制。</p><h1 id="2-4-const-限定符"><a href="#2-4-const-限定符" class="headerlink" title="2.4 const 限定符"></a>2.4 const 限定符</h1><p>​    关键字<strong>const</strong>可以对变量的类型加以限定，使得被限定的变量的值在定义之后不能再改变。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> <span class="keyword">int</span> bufSize = <span class="number">512</span></span><br></pre></td></tr></table></figure><p>因为const对象一旦创建后其值就不能再改变，所以const对象必须被初始化。</p><h3 id="对const的引用可能引用一个并非const的对象"><a href="#对const的引用可能引用一个并非const的对象" class="headerlink" title="对const的引用可能引用一个并非const的对象"></a>对const的引用可能引用一个并非const的对象</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> i = <span class="number">42</span>;</span><br><span class="line"><span class="keyword">int</span> &amp;r1 = i;</span><br><span class="line"><span class="keyword">const</span> <span class="keyword">int</span> &amp;r2 = i;</span><br><span class="line">r1 = <span class="number">0</span>;  <span class="comment">// 可以通过r1修改i的值</span></span><br><span class="line">r2 = <span class="number">0</span>;  <span class="comment">// 错误；不能通过r2修改i的值</span></span><br></pre></td></tr></table></figure><h2 id="2-4-3-顶层const"><a href="#2-4-3-顶层const" class="headerlink" title="2.4.3 顶层const"></a>2.4.3 顶层const</h2><p>​    用名词<strong>顶层const</strong>表示指针本身是个常量，而<strong>底层const</strong>表示指针所指的对象是一个常量。当执行对象的拷贝操作时，拷入和拷出的对象必须具有相同的底层const资格，或者两个对象的数据类型必须能够转换。（待考究，p58）</p><h2 id="2-4-4-constexpr-和常量表达式"><a href="#2-4-4-constexpr-和常量表达式" class="headerlink" title="2.4.4 constexpr 和常量表达式"></a>2.4.4 constexpr 和常量表达式</h2><p>​    <strong>常量表达式</strong>是指值不会改变并且在编译过程就能得到计算结果的表达式。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> <span class="keyword">int</span> max_files = <span class="number">20</span>; <span class="comment">// 常量表达式</span></span><br><span class="line"><span class="keyword">int</span> staff_size = <span class="number">28</span>; <span class="comment">// 不是常量表达式</span></span><br><span class="line"><span class="keyword">const</span> <span class="keyword">int</span> sz = get_size(); <span class="comment">// 不是常量表达式，因为要在运行时才能获取到</span></span><br></pre></td></tr></table></figure><h3 id="constexpr-变量"><a href="#constexpr-变量" class="headerlink" title="constexpr 变量"></a>constexpr 变量</h3><p>​    C++11 新标准规定，允许将变量声明为<strong>constexpr</strong>类型以便由编译器来验证变量的值是否是一个常量表达式。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">constexpr</span> <span class="keyword">int</span> sz = size(); <span class="comment">// 只有当size()是一个constexpr函数时才是一条正确的语句</span></span><br></pre></td></tr></table></figure><h3 id="字面值类型"><a href="#字面值类型" class="headerlink" title="字面值类型"></a>字面值类型</h3><h1 id="2-5-处理类型"><a href="#2-5-处理类型" class="headerlink" title="2.5 处理类型"></a>2.5 处理类型</h1><h2 id="2-5-1-类型别名"><a href="#2-5-1-类型别名" class="headerlink" title="2.5.1 类型别名"></a>2.5.1 类型别名</h2><p>​    <strong>类型别名</strong>是一个名字，它是某种类型的同义词。使用类型别名能让复杂的类型名变得简单明了、易于理解和使用。</p><p>​    有两种方法可用于定义类型别名。分别是是使用<strong>关键字 typedef</strong>和<strong>别名声明using</strong>：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="keyword">double</span> wage;</span><br><span class="line"></span><br><span class="line"><span class="keyword">using</span> SI = Sale_item;</span><br></pre></td></tr></table></figure><h2 id="2-5-2-auto-类型说明符"><a href="#2-5-2-auto-类型说明符" class="headerlink" title="2.5.2 auto 类型说明符"></a>2.5.2 auto 类型说明符</h2><p>​    <strong>auto</strong>类型说明符能让编译器替我们去分析表达式所属的类型。</p><h2 id="2-5-3-decltype-类型指示符"><a href="#2-5-3-decltype-类型指示符" class="headerlink" title="2.5.3 decltype 类型指示符"></a>2.5.3 decltype 类型指示符</h2><p>​    类型说明符<strong>decltype</strong>能从表达式的类型推断出要定义的变量的类型，但不使用该表达式的值初始化变量。其作用是选择并返回操作数的数据类型。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">decltype</span>(f()) sum = x; <span class="comment">// 使用f()的返回类型初始化sum变量，而不使用f()的值</span></span><br></pre></td></tr></table></figure><h1 id="2-6-自定义数据结构"><a href="#2-6-自定义数据结构" class="headerlink" title="2.6 自定义数据结构"></a>2.6 自定义数据结构</h1><h2 id="2-6-1-定义-Sales-data-类型"><a href="#2-6-1-定义-Sales-data-类型" class="headerlink" title="2.6.1 定义 Sales_data 类型"></a>2.6.1 定义 Sales_data 类型</h2><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">Sales_data</span> &#123;</span>          <span class="comment">// 关键字struct + 类名</span></span><br><span class="line">    <span class="built_in">std</span>::<span class="built_in">string</span> bookNo;      <span class="comment">// 数据成员</span></span><br><span class="line">    <span class="keyword">unsigned</span> units_sold = <span class="number">0</span>; <span class="comment">// 类内初始值</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="2-6-2-使用-Sales-data-类"><a href="#2-6-2-使用-Sales-data-类" class="headerlink" title="2.6.2 使用 Sales_data 类"></a>2.6.2 使用 Sales_data 类</h2><h3 id="添加-Sales-data-对象"><a href="#添加-Sales-data-对象" class="headerlink" title="添加 Sales_data 对象"></a>添加 Sales_data 对象</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Sales_data data1;</span><br></pre></td></tr></table></figure><h3 id="Sales-data-对象读入数据"><a href="#Sales-data-对象读入数据" class="headerlink" title="Sales_data 对象读入数据"></a>Sales_data 对象读入数据</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">std</span>::<span class="built_in">cin</span> &gt;&gt; data1.bookNO &gt;&gt; data1.units_sold &gt;&gt; price;</span><br></pre></td></tr></table></figure><h2 id="2-6-3-编写自己的头文件"><a href="#2-6-3-编写自己的头文件" class="headerlink" title="2.6.3 编写自己的头文件"></a>2.6.3 编写自己的头文件</h2><p>​    为了确保哥哥文件中类的定义一致，类通常被定义在头文件中，而且类所在头文件的名字应与类的名字一样。头文件通常包含那些被定义一次的实体，如类、const 和 constexpr 变量。</p><h3 id="预处理器概述"><a href="#预处理器概述" class="headerlink" title="预处理器概述"></a>预处理器概述</h3><p>​    <strong>预处理器</strong>是在编译之前执行的一段程序，可以部分地改变我们所写的程序。能确保头文件多次包含仍能安全工作。之前用到的一项预处理器功能是#include。</p><p>​    C++用到的另一项与处理功能是<strong>头文件保护符</strong>，头文件保护符依赖于<strong>预处理变量</strong>。预处理变量有两种状态：已定义和未定义。<strong>#define</strong> 指令把一个名字设定为预处理变量，<strong>#ifdef</strong> 当且仅当变量已经定义是为真，<strong>#ifndef</strong> 仅当变量未定义时为真。检查结果为真时，执行后续操作直至遇到<strong>#endif</strong> 指令为止。</p><p>​    以下代码说明了这些功能如何有效防止重复包含：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">ifndef</span> SALES_DATA_H  <span class="comment">// 如果没有定义SALES_DATA_H预处理变量，则执行以下语句</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> SALES_DATA_H  <span class="comment">// 定义SALES_DATA_H预处理变量</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> Sales_data</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">Sales_data</span> &#123;</span></span><br><span class="line">    <span class="built_in">std</span>::<span class="built_in">string</span> bookNo;</span><br><span class="line">    <span class="keyword">unsigned</span> units_sold = <span class="number">0</span>; </span><br><span class="line">&#125;;</span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br></pre></td></tr></table></figure><p>第一次包含该文件时，SALES_DATA_H 未定义，预处理器顺序执行代码。再次被包含时 SALES_DATA_H 已定义，<code>#ifndef SALES_DATA_H</code> 检查结果为假，编译器将跳过中间语句。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;数据类型决定了程序中数据和操作的意义。&lt;/p&gt;
&lt;h1 id=&quot;2-1-基本内置类型&quot;&gt;&lt;a href=&quot;#2-1-基本内置类型&quot; class=&quot;headerlink&quot; title=&quot;2.1 基本内置类型&quot;&gt;&lt;/a&gt;2.1 基本内置类型&lt;/h1&gt;&lt;h2 id=&quot;2-1-1-
      
    
    </summary>
    
      <category term="C++" scheme="http://a-kali.github.io/categories/C/"/>
    
    
      <category term="C++" scheme="http://a-kali.github.io/tags/C/"/>
    
  </entry>
  
  <entry>
    <title>《C++ Primer》 第1章 开始</title>
    <link href="http://a-kali.github.io/2019/08/19/%E3%80%8AC-Primer%E3%80%8B-%E7%AC%AC1%E7%AB%A0-%E5%BC%80%E5%A7%8B/"/>
    <id>http://a-kali.github.io/2019/08/19/《C-Primer》-第1章-开始/</id>
    <published>2019-08-19T13:36:16.000Z</published>
    <updated>2019-08-19T15:34:41.869Z</updated>
    
    <content type="html"><![CDATA[<h1 id="1-1-编写一个简单的C-程序"><a href="#1-1-编写一个简单的C-程序" class="headerlink" title="1.1 编写一个简单的C++程序"></a>1.1 编写一个简单的C++程序</h1><h2 id="1-1-1-编译、运行程序"><a href="#1-1-1-编译、运行程序" class="headerlink" title="1.1.1 编译、运行程序"></a>1.1.1 编译、运行程序</h2><p>​    术语：<strong>集成开发环境</strong>（Integrated Developed Environment, IDE）</p><h3 id="源程序文件命名约定"><a href="#源程序文件命名约定" class="headerlink" title="源程序文件命名约定"></a>源程序文件命名约定</h3><p>​    大多数编译器要求源码存储在一个或多个文件中，这些程序文件通常被称为<strong>源文件</strong>。常见C++程序源文件后缀有：<strong>cc、cxx、cpp、cp、C</strong>。</p><h3 id="从命令行运行编译器"><a href="#从命令行运行编译器" class="headerlink" title="从命令行运行编译器"></a>从命令行运行编译器</h3><p>​    <code>$ CC prog1.cc</code></p><p>​    其中CC是编译器的名字。编译器生成一个可执行文件。Windows系统将这个可执行文件命名为<strong>prog1.exe</strong>。UNIX系统常命名为<strong>a.out</strong>。</p><h1 id="1-2-初识输入输出"><a href="#1-2-初识输入输出" class="headerlink" title="1.2 初识输入输出"></a>1.2 初识输入输出</h1><p>​    C++语言常用<strong>标准库</strong>来提供IO机制。同时本书中很多示例使用了<strong>iostream库</strong>。该库包含两个<strong>基础类型istream和ostream</strong>，分别表示输入流和输出流。“<strong>流</strong>”（stream）这个术语想表达的是，随着时间的推移，字符是序列生成或消耗的。</p><h3 id="标准输入输出对象"><a href="#标准输入输出对象" class="headerlink" title="标准输入输出对象"></a>标准输入输出对象</h3><p>标准库定义了4个<strong>IO对象：cin、cout、cerr、clog</strong>。</p><h3 id="一个IO库的程序"><a href="#一个IO库的程序" class="headerlink" title="一个IO库的程序"></a>一个IO库的程序</h3><p>​    程序的第一行</p><p>​    <code>#include &lt;iostream&gt;</code></p><p>告诉编译器我们想要使用iostream库。尖括号中的名字指出了一个<strong>头文件</strong>。每个使用标准库设施的程序都必须包含相关的头文件。对于非标准库的头文件，则用双引号包围。</p><h3 id="向流写入数据"><a href="#向流写入数据" class="headerlink" title="向流写入数据"></a>向流写入数据</h3><p>​    表达式</p><p>​    <code>std::cout &lt;&lt; &quot;Enter two numbers: &quot; &lt;&lt; std::endl;</code></p><p>使用了<strong>输出运算符</strong>（<strong>&lt;&lt;</strong>）在标准输出上打印信息。输出运算符接受两个运算对象：右侧的运算对象是要打印的值，左侧的运算对象必须是一个ostream对象。左侧的ostream对象是运算符的运算结果。</p><p>​    该语句使用了两次输出运算符，即第一次运算结果成为了第二个运算符的左侧对象。该语句等同于：</p><p>​    <code>(std::cout &lt;&lt; &quot;Enter two numbers: &quot;) &lt;&lt;# std::endl;</code></p><p>也可以用两条语句表达：</p><p>​    <code>std::cout &lt;&lt; &quot;Enter two numbers: &quot;</code></p><p>​    <code>std::cout &lt;&lt; std::endl;</code></p><h1 id="1-4-控制流"><a href="#1-4-控制流" class="headerlink" title="1.4 控制流"></a>1.4 控制流</h1><h2 id="1-4-3-读取数量不定的输入数据"><a href="#1-4-3-读取数量不定的输入数据" class="headerlink" title="1.4.3 读取数量不定的输入数据"></a>1.4.3 读取数量不定的输入数据</h2><p>​    在预先不知道要对多少个数求和时，就需要<strong>不断读取数据直至没有新的输入为止</strong>：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">while</span> (<span class="built_in">std</span>::<span class="built_in">cin</span> &gt;&gt; value)</span><br><span class="line">    sum += value;</span><br><span class="line"><span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; <span class="string">"Sum is: "</span> &lt;&lt; sum &lt;&lt; <span class="built_in">std</span>::<span class="built_in">endl</span>;</span><br></pre></td></tr></table></figure><p>如果我们输入</p><p>​    <code>3 4 5 6</code></p><p>则程序会输出</p><p>​    <code>Sum is: 18</code></p><p>当我们使用一个istream对象作为条件时，其效果是检测流的状态。如果流时有效的，那么检测成功。当遇到文件结束符或一个无效输入（例如读入值与value定义的类型不相符），istream的状态会变为无效。</p><h3 id="从键盘输入文件结束符"><a href="#从键盘输入文件结束符" class="headerlink" title="从键盘输入文件结束符"></a>从键盘输入文件结束符</h3><p>Windows: Ctrl + Z, Enter</p><p>Unix&amp;MacOS: Ctrl + D</p><h1 id="1-5-类简介"><a href="#1-5-类简介" class="headerlink" title="1.5 类简介"></a>1.5 类简介</h1><p>​    在C++中，我们通过定义一个<strong>类</strong>（class）来定义自己的数据结构。一个类定义了一个类型，以及与其关联的一组操作。每个类实际上都定义了一个新的类型，其类型名就是其类名。</p><p>类/对象可以进行的操作：</p><ul><li>定义该类型的变量。</li><li>用输入、输出运算符读写该类型的对象。</li><li>在同类对象间进行赋值。</li><li>在两个同类对象间进行加法运算。</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;1-1-编写一个简单的C-程序&quot;&gt;&lt;a href=&quot;#1-1-编写一个简单的C-程序&quot; class=&quot;headerlink&quot; title=&quot;1.1 编写一个简单的C++程序&quot;&gt;&lt;/a&gt;1.1 编写一个简单的C++程序&lt;/h1&gt;&lt;h2 id=&quot;1-1-1-编译、运行
      
    
    </summary>
    
      <category term="C++" scheme="http://a-kali.github.io/categories/C/"/>
    
    
      <category term="C++" scheme="http://a-kali.github.io/tags/C/"/>
    
  </entry>
  
  <entry>
    <title>深度学习工程师（吴恩达）——  序列模型</title>
    <link href="http://a-kali.github.io/2019/08/10/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%B7%A5%E7%A8%8B%E5%B8%88%EF%BC%88%E5%90%B4%E6%81%A9%E8%BE%BE%EF%BC%89%E2%80%94%E2%80%94-%E5%BA%8F%E5%88%97%E6%A8%A1%E5%9E%8B/"/>
    <id>http://a-kali.github.io/2019/08/10/深度学习工程师（吴恩达）——-序列模型/</id>
    <published>2019-08-10T06:02:58.000Z</published>
    <updated>2019-08-21T15:50:16.284Z</updated>
    
    <content type="html"><![CDATA[<h1 id="一、循环序列模型"><a href="#一、循环序列模型" class="headerlink" title="一、循环序列模型"></a>一、循环序列模型</h1><h2 id="1-1-为什么选择序列模型"><a href="#1-1-为什么选择序列模型" class="headerlink" title="1.1 为什么选择序列模型"></a>1.1 为什么选择序列模型</h2><p><img src="https://s2.ax1x.com/2019/08/10/eOFH3R.png" alt="序列模型举例"></p><h2 id="1-2-数学符号定义"><a href="#1-2-数学符号定义" class="headerlink" title="1.2 数学符号定义"></a>1.2 数学符号定义</h2><script type="math/tex; mode=display">x^{<n>} \Rightarrow 序列中的第n个符号所对应的向量</script><p><img src="https://s2.ax1x.com/2019/08/10/eOZuwV.png" alt></p><h2 id="1-3-循环神经网络模型（RNN）"><a href="#1-3-循环神经网络模型（RNN）" class="headerlink" title="1.3 循环神经网络模型（RNN）"></a>1.3 循环神经网络模型（RNN）</h2><p>​    由于序列数据每次输入长度相差较大的特性，使其无法适应常规神经网络模型，于是便有了循环神经网络模型。</p><p><img src="https://s2.ax1x.com/2019/08/10/eO1htI.png" alt="eO1htI.png"></p><p>​    循环神经网络每次输入一个词向量，当神经网络读取到x<sup><2></2></sup>的信息时，它也会按照一定权重输入一些来自时间步1的信息，称为a<sup><1></1></sup>；读取x<sup><3></3></sup>时则会输入来自时间步1和2的信息，以此类推。而读取x<sup><1></1></sup>时则需要输入一个自定义的激活值a<sup><0></0></sup>，这个值通常为0。w和b分别表示权重和偏置，为每个时间步所共享。</p><script type="math/tex; mode=display">a^{<t>} = g(w_{aa}a^{<t-1>}+w_{ax}x^{<t>}+b_a)\\\hat y^{<t>} = g(w_{ya}a^{<t>}+b_y)</script><p>​    g(x)为激活函数，通常为tanh，最后得出输出值的激活函数可以为sigmod。</p><p>​    简化方程如下：</p><script type="math/tex; mode=display">a^{<t>} = g(w_{a}[a^{<t-1>},x^{<t>}])\\其中w_a为w_{aa}和w_{ax}的横向拼接，[a^{<t-1>},x^{<t>}]表示a^{<t-1>}和x^{<t>}纵向拼接。</script><p>​    RNN的一个缺点是其只能使用当前输入之前的信息，而没有使用到之后的信息。后续将提到的BRNN将解决这个问题。</p><h2 id="1-4-通过时间的反向传播"><a href="#1-4-通过时间的反向传播" class="headerlink" title="1.4 通过时间的反向传播"></a>1.4 通过时间的反向传播</h2><script type="math/tex; mode=display">损失函数：L^{<t>}(\hat y^{<t>},y^{<t>}) = -y^{<t>}\log \hat y^{<t>}-(1-y^{<t>})\log (1-y^{<t>})\\L^(\hat y^{<t>},y^{<t>}) = \sum_{t=1}^{T_y} L^{<t>}(\hat y^{<t>},y^{<t>})</script><p>即总损失为各时间损失之和。</p><h2 id="1-5-不同类型的循环神经网络"><a href="#1-5-不同类型的循环神经网络" class="headerlink" title="1.5 不同类型的循环神经网络"></a>1.5 不同类型的循环神经网络</h2><ul><li>等长多输入多输出结构，如找出句子中的人名</li><li>多输入单输出结构，如情感分类</li><li>单输入多输出结构，如音乐生成</li><li>非等长多输入多输出结构，如语言翻译</li></ul><p><img src="https://s2.ax1x.com/2019/08/19/mlQIqs.png" alt="mlQIqs.png"></p><h2 id="1-6-语言模型和序列生成"><a href="#1-6-语言模型和序列生成" class="headerlink" title="1.6 语言模型和序列生成"></a>1.6 语言模型和序列生成</h2><p>​    语言模型的训练集由一个巨大的语料库组成，句子中的每个词向量都对应着字典中其所在的位置，句末由\<eos>来表示句子的结束。语料中没有的词向量以\<unk>表示。</unk></eos></p><h2 id="1-7-对新序列采样"><a href="#1-7-对新序列采样" class="headerlink" title="1.7 对新序列采样"></a>1.7 对新序列采样</h2><p>暂时没看懂</p><h2 id="1-8-RNN的梯度消失"><a href="#1-8-RNN的梯度消失" class="headerlink" title="1.8 RNN的梯度消失"></a>1.8 RNN的梯度消失</h2><p>示例：</p><ul><li>The <strong>cat</strong>, which already ate …… <strong>was</strong> full.</li><li>The <strong>cats</strong>, which already ate …… <strong>were</strong> full.</li></ul><p>在这两个句子中，cat的单复数直接决定了后面的谓语使用was还是were。但由于主语和谓语的距离太远，时间的反向传播很难从谓语传播到主语，导致梯度消失，因此网络很难调整前面的计算。</p><h2 id="1-9-Gated-Recurrent-Unit-GRU"><a href="#1-9-Gated-Recurrent-Unit-GRU" class="headerlink" title="1.9 Gated Recurrent Unit (GRU)"></a>1.9 Gated Recurrent Unit (GRU)</h2><p><strong>门控循环单元（GRU）</strong>改变了RNN的隐藏层，使得RNN能更好地捕捉深层次的连接，并改善了梯度消失问题。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;一、循环序列模型&quot;&gt;&lt;a href=&quot;#一、循环序列模型&quot; class=&quot;headerlink&quot; title=&quot;一、循环序列模型&quot;&gt;&lt;/a&gt;一、循环序列模型&lt;/h1&gt;&lt;h2 id=&quot;1-1-为什么选择序列模型&quot;&gt;&lt;a href=&quot;#1-1-为什么选择序列模型&quot; c
      
    
    </summary>
    
      <category term="深度学习" scheme="http://a-kali.github.io/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="深度学习" scheme="http://a-kali.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="吴恩达" scheme="http://a-kali.github.io/tags/%E5%90%B4%E6%81%A9%E8%BE%BE/"/>
    
      <category term="序列模型" scheme="http://a-kali.github.io/tags/%E5%BA%8F%E5%88%97%E6%A8%A1%E5%9E%8B/"/>
    
      <category term="自然语言处理" scheme="http://a-kali.github.io/tags/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/"/>
    
      <category term="笔记" scheme="http://a-kali.github.io/tags/%E7%AC%94%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>使用MMDetection进行语义分割</title>
    <link href="http://a-kali.github.io/2019/08/04/%E4%BD%BF%E7%94%A8MMDetection%E8%BF%9B%E8%A1%8C%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2/"/>
    <id>http://a-kali.github.io/2019/08/04/使用MMDetection进行语义分割/</id>
    <published>2019-08-04T01:53:42.000Z</published>
    <updated>2019-09-01T16:18:08.099Z</updated>
    
    <content type="html"><![CDATA[<p>​    <a href="https://github.com/open-mmlab/mmdetection" target="_blank" rel="noopener">MMDetection</a>是商汤科技开源的用于深度学习目标检测的库，而SIIM-ACR Pneumothorax Segmentation（以下简称SIIM）是发布于Kaggle平台的一个分割气胸所在位置的计算机视觉类竞赛。以下我将以SIIM比赛为例，介绍如何使用MMDetection进行语义分割。</p><h1 id="一、安装MMDetection"><a href="#一、安装MMDetection" class="headerlink" title="一、安装MMDetection"></a>一、安装MMDetection</h1><p>​    安装过程可能会有更新，以官方为准：</p><p>​    <a href="https://github.com/open-mmlab/mmdetection" target="_blank" rel="noopener">https://github.com/open-mmlab/mmdetection</a></p><h2 id="安装准备"><a href="#安装准备" class="headerlink" title="安装准备"></a>安装准备</h2><ul><li>操作系统：Linux</li><li>Python 3.5+</li><li>PyTorch 1.0+ 或 PyTorch-nightly</li><li>CUDA 9.0+</li><li>NCCL 2+</li><li>GCC 4.9+</li></ul><h2 id="安装步骤"><a href="#安装步骤" class="headerlink" title="安装步骤"></a>安装步骤</h2><ol><li><p>创建conda虚拟环境并激活、安装Cython</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">conda create -n open-mmlab python=3.7 -y</span><br><span class="line">conda activate open-mmlab</span><br><span class="line"></span><br><span class="line">conda install cython</span><br></pre></td></tr></table></figure></li><li><p>根据<a href="https://pytorch.org/get-started/locally/" target="_blank" rel="noopener">PyTorch官网</a>中对应的版本在conda的虚拟环境中安装PyTorch stable/nightly和torchvision。<strong>注意需要去掉安装命令中的 -c 参数</strong>（如果有的话），不然下载过程会很慢。</p></li><li><p>在虚拟环境中安装<a href="https://github.com/open-mmlab/mmcv" target="_blank" rel="noopener">mmcv</a>和<a href="https://github.com/philferriere/cocoapi" target="_blank" rel="noopener">cocoapi</a></p></li><li><p>克隆MMDetection并安装</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">git <span class="built_in">clone</span> https://github.com/open-mmlab/mmdetection.git</span><br><span class="line"><span class="built_in">cd</span> mmdetection</span><br><span class="line">python setup.py develop</span><br><span class="line"><span class="comment"># or "pip install -v -e ."</span></span><br></pre></td></tr></table></figure></li></ol><h1 id="二、准备COCO格式数据标注"><a href="#二、准备COCO格式数据标注" class="headerlink" title="二、准备COCO格式数据标注"></a>二、准备COCO格式数据标注</h1><p>   COCO的全称是Common Objects in COntext，是微软团队提供的一个可以用来进行图像识别的数据集。而我们在这次比赛中需要用到的是COCO数据集的标注格式，mmdetection将通过标注来对数据进行训练和测试。</p><p>   COCO数据集现在有5种标注类型：<strong>Object Detection（目标检测）、Keypoint Detection（关键点检测）、 Stuff Segmentation（语义分割）、Panoptic Segmentation（全景分割）和image captions（看图说话）</strong>，使用JSON文件存储。在SIIM比赛中使用的是语义分割。</p><h2 id="基本的JSON结构体类型"><a href="#基本的JSON结构体类型" class="headerlink" title="基本的JSON结构体类型"></a>基本的JSON结构体类型</h2><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">"info"</span>: info,</span><br><span class="line">    <span class="attr">"licenses"</span>: [license],</span><br><span class="line">    <span class="attr">"images"</span>: [image],</span><br><span class="line">    <span class="attr">"annotations"</span>: [annotation],</span><br><span class="line">&#125;</span><br><span class="line">    </span><br><span class="line">info&#123;</span><br><span class="line">    "year": int,</span><br><span class="line">    "version": str,</span><br><span class="line">    "description": str,</span><br><span class="line">    "contributor": str,</span><br><span class="line">    "url": str,</span><br><span class="line">    "date_created": datetime,</span><br><span class="line">&#125;</span><br><span class="line">license&#123;</span><br><span class="line">    "id": int,</span><br><span class="line">    "name": str,</span><br><span class="line">    "url": str,</span><br><span class="line">&#125; </span><br><span class="line">image&#123;</span><br><span class="line">    "id": int,</span><br><span class="line">    "width": int,</span><br><span class="line">    "height": int,</span><br><span class="line">    "file_name": str,</span><br><span class="line">    "license": int,</span><br><span class="line">    "flickr_url": str,</span><br><span class="line">    "coco_url": str,</span><br><span class="line">    "date_captured": datetime,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ol><li>info类型，以下是一个info类型的实例：</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&quot;info&quot;:&#123;</span><br><span class="line">&quot;description&quot;:&quot;This is stable 1.0 version of the 2014 MS COCO dataset.&quot;,</span><br><span class="line">&quot;url&quot;:&quot;http:\/\/mscoco.org&quot;,</span><br><span class="line">&quot;version&quot;:&quot;1.0&quot;,&quot;year&quot;:2014,</span><br><span class="line">&quot;contributor&quot;:&quot;Microsoft COCO group&quot;,</span><br><span class="line">&quot;date_created&quot;:&quot;2015-01-27 09:11:52.357475&quot;</span><br><span class="line">&#125;,</span><br></pre></td></tr></table></figure><ol><li>images是包含多个image实例的数组，以下是一个image类型的实例：</li></ol><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">   <span class="attr">"license"</span>:<span class="number">3</span>,</span><br><span class="line">   <span class="attr">"file_name"</span>:<span class="string">"COCO_val2014_000000391895.jpg"</span>,</span><br><span class="line">   <span class="attr">"coco_url"</span>:<span class="string">"http:\/\/mscoco.org\/images\/391895"</span>,</span><br><span class="line">    <span class="attr">"height"</span>:<span class="number">360</span>,<span class="attr">"width"</span>:<span class="number">640</span>,<span class="attr">"date_captured"</span>:<span class="string">"2013-11-14 11:18:45"</span>,</span><br><span class="line">   <span class="attr">"flickr_url"</span>:<span class="string">"http:\/\/farm9.staticflickr.com\/8186\/8119368305_4e622c8349_z.jpg"</span>,</span><br><span class="line">   <span class="attr">"id"</span>:<span class="number">391895</span></span><br><span class="line">&#125;,</span><br></pre></td></tr></table></figure><ol><li>licenses是包含多个license实例的数组，以下是一个license类型的实例：</li></ol><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line"><span class="attr">"url"</span>:<span class="string">"http:\/\/creativecommons.org\/licenses\/by-nc-sa\/2.0\/"</span>,</span><br><span class="line"><span class="attr">"id"</span>:<span class="number">1</span>,</span><br><span class="line"><span class="attr">"name"</span>:<span class="string">"Attribution-NonCommercial-ShareAlike License"</span></span><br><span class="line">&#125;,</span><br></pre></td></tr></table></figure><p>   info和licenses是不必要的，留空即可。</p><h2 id="Stuff-Segmentation-类型的标注"><a href="#Stuff-Segmentation-类型的标注" class="headerlink" title="Stuff Segmentation 类型的标注"></a>Stuff Segmentation 类型的标注</h2><p>   Stuff Segmentation 的标注格式和 Object Detection 的格式一样，如下：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">"info"</span>: info,</span><br><span class="line">    <span class="attr">"licenses"</span>: [license],</span><br><span class="line">    <span class="attr">"images"</span>: [image],</span><br><span class="line">    <span class="attr">"annotations"</span>: [annotation],</span><br><span class="line">    <span class="attr">"categories"</span>: [category]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>   可以看到segmentation的结构体比通用结构体多了两种类型：annotations和categories。</p><ol><li>annotations字段是包含多个annotation实例的一个数组，annotation类型本身又包含了一系列的字段，如下所示：</li></ol><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">annotation&#123;</span><br><span class="line">    "id": int,    </span><br><span class="line">    "image_id": int,</span><br><span class="line">    "category_id": int,</span><br><span class="line">    "segmentation": RLE or [polygon],</span><br><span class="line">    "area": float,</span><br><span class="line">    "bbox": [x,y,width,height],</span><br><span class="line">    "iscrowd": 0 or 1,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>   在Stuff Segmentation任务中，segmentation的编码为RLE格式，iscrowd为0；area字段为标注覆盖的面积；bbox是一个长度为4的数组，用于表示目标检测的边框，x和y表示边框左上角的坐标，width和height表示边框的宽和高。当编码为RLE格式时，segmentation的格式如下：</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">segmentation : </span><br><span class="line">&#123;</span><br><span class="line">    'counts': [272, 2, 4, 4, 4, 4, 2, 9, 1, 2, 16, 43, 143, 24......], </span><br><span class="line">    'size': [240, 320]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>   size是这张图片的宽高，counts字段的内容为RLE编码。此处举例使用的是uncompressed RLE，做语义分割任务时需编码为compact RLE。可使用pycocotools中的函数生成compact RLE，以下用SIIM中的一个RLE码举例:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> pycocotools.mask <span class="keyword">import</span> encode</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> mask_function <span class="keyword">import</span> rle2mask</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>rle = <span class="string">'407576 2 1021 7 1015 10 1013 12 1011 14 1008 17 1006 19 1005 20 1003 21 1003 22 1001 23 1001 24 999 25 999 25 999 26 997 27 997 27 996 28 996 28 996 29 994 30 994 30 994 30 993 31 993 32 992 32 992 32 992 32 991 33 991 33 991 33 991 33 991 33 990 34 990 34 990 34 990 34 990 34 989 35 989 36 988 36 988 16 1 19 988 15 3 18 988 15 4 16 989 14 8 13 989 14 8 13 989 13 9 13 989 13 9 13 989 12 10 13 989 12 10 13 989 11 11 13 989 11 11 13 989 11 11 13 989 10 11 14 989 10 11 14 990 9 9 16 990 9 7 18 990 9 6 18 991 9 6 18 991 9 5 19 992 8 4 20 992 7 5 20 993 6 4 21 993 6 4 21 994 4 4 22 995 3 5 20 997 2 5 20 1005 19 1006 17 1008 15 1010 12 1015 7'</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>mask = rle2mask(rle, <span class="number">1024</span>, <span class="number">1024</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>mask = mask.T.astype(np.uint8) <span class="comment"># uint8是encode函数参数的指定数值类型</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>segmentation = encode(np.asfortranarray(mask))</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>segmentation</span><br><span class="line">&#123;<span class="string">'size'</span>: [<span class="number">1024</span>, <span class="number">1024</span>], <span class="string">'counts'</span>: <span class="string">b'hP^&lt;2mo05J3N2N2M3N2O1N101N101N10001N100O10001N10000O101O00000O100000000O100000000O101O00\\OUQO3kn0LWQO3in0MXQO1in0N[QOOen01[QOOen00\\QO0dn00\\QO0dn0O]QO1cn0O]QO1cn0N^QO2bn0N^QO2bn0N^QO2bn0M^QO4bn0L^QO4cn0K[QO7en0IYQO9gn0GXQO9in0GWQO9in0GVQO:kn0ETQO&lt;ln0CUQO=ln0BSQO?mn0ASQO?nn0_ORQOb0on0]ORQOa0Po0^OPQOb0Xo0O1N2N2M5KXoYa0'</span>&#125; <span class="comment"># compact RLE</span></span><br></pre></td></tr></table></figure><p>   rle2mask是SIIM比赛官方提供的用于将RLE转化成mask的函数，内容如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">rle2mask</span><span class="params">(rle, width, height)</span>:</span></span><br><span class="line">    mask = np.zeros(width * height)</span><br><span class="line">    array = np.asarray([int(x) <span class="keyword">for</span> x <span class="keyword">in</span> rle.split()])</span><br><span class="line">    starts = array[<span class="number">0</span>::<span class="number">2</span>]</span><br><span class="line">    lengths = array[<span class="number">1</span>::<span class="number">2</span>]</span><br><span class="line"></span><br><span class="line">    current_position = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> index, start <span class="keyword">in</span> enumerate(starts):</span><br><span class="line">        current_position += start</span><br><span class="line">        mask[current_position:current_position+lengths[index]] = <span class="number">255</span></span><br><span class="line">        current_position += lengths[index]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> mask.reshape(width, height)</span><br></pre></td></tr></table></figure><p>   以下是COCO2017的语义分割标注文件中一个完整的annotation:</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">"segmentation"</span>:</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="attr">"counts"</span>:<span class="string">"Q[d04_;3L1O1O2M2O10001O0O10O11O00000000N2N2FkD3\\;Nem[6"</span>,</span><br><span class="line">        <span class="attr">"size"</span>: [<span class="number">371</span>, <span class="number">640</span>]</span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="attr">"area"</span>: <span class="number">257.0</span>,</span><br><span class="line">    <span class="attr">"iscrowd"</span>: <span class="number">0</span>,</span><br><span class="line">    <span class="attr">"image_id"</span>: <span class="number">19042</span>,</span><br><span class="line">    <span class="attr">"bbox"</span>: [<span class="number">56.0</span>, <span class="number">50.0</span>, <span class="number">21.0</span>, <span class="number">16.0</span>],</span><br><span class="line">    <span class="attr">"category_id"</span>: <span class="number">127</span>,</span><br><span class="line">    <span class="attr">"id"</span>: <span class="number">20001212</span></span><br><span class="line">&#125;,</span><br></pre></td></tr></table></figure><ol><li>categories 字段是一个包含多个category实例的数组，表示标注的物体类型，category结构体描述如下：</li></ol><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">"id"</span>: int,</span><br><span class="line">    <span class="attr">"name"</span>: str,</span><br><span class="line">    <span class="attr">"supercategory"</span>: str,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>​    在SIIM的检测目标里只有一种类型，即气胸（Pneumothorax）。于是自定义一种category如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"categories"</span>: [</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="string">'supercategory'</span>: <span class="string">'Pneumothorax'</span>,</span><br><span class="line">        <span class="string">'id'</span>: <span class="number">1</span>,</span><br><span class="line">        <span class="string">'name'</span>: <span class="string">'Pneumothorax'</span></span><br><span class="line">    &#125;</span><br><span class="line">]</span><br></pre></td></tr></table></figure><p>   以上是关于Stuff Segmentation 类型标注的所有内容，接下来就可以自己动手写一个脚本自动生成标注文件了。值得一提的是测试集的标注文件无需annotations字段。</p><p>   准备好的COCO格式数据集按如下形式摆放。官方建议新建一个data文件夹，将数据集放在data文件夹下（建议使用软链接的方式）。生成的标注文件放在annotations文件夹下。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">mmdetection</span><br><span class="line">├── mmdetc</span><br><span class="line">├── tools</span><br><span class="line">├── configs</span><br><span class="line">├── data</span><br><span class="line">│   ├── coco</span><br><span class="line">│   │   ├── annotations</span><br><span class="line">│   │   ├── train2017</span><br><span class="line">│   │   ├── val2017</span><br><span class="line">│   │   ├── test2017</span><br></pre></td></tr></table></figure><p>软连接方式，其中$COCO_ROOT需改为你的coco数据集根目录：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cd mmdetection</span><br><span class="line">mkdir data</span><br><span class="line">ln -s $COCO_ROOT data</span><br></pre></td></tr></table></figure><h1 id="三、训练模型"><a href="#三、训练模型" class="headerlink" title="三、训练模型"></a>三、训练模型</h1><h2 id="修改模型配置文件"><a href="#修改模型配置文件" class="headerlink" title="修改模型配置文件"></a>修改模型配置文件</h2><p>   进入配置文件夹configs，编辑你想使用的模型对应的配置文件。以下以cascade_mask_rcnn_x101_64x4d_fpn_1x.py为例，解释其中几个比较关键的参数：</p>   <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># model settings</span></span><br><span class="line">model = dict(</span><br><span class="line">    type=<span class="string">'CascadeRCNN'</span>,</span><br><span class="line">    num_stages=<span class="number">3</span>,</span><br><span class="line">    pretrained=<span class="string">'open-mmlab://resnext101_64x4d'</span>,</span><br><span class="line">    backbone=dict(</span><br><span class="line">        type=<span class="string">'ResNeXt'</span>,</span><br><span class="line">        depth=<span class="number">101</span>,</span><br><span class="line">        groups=<span class="number">64</span>,</span><br><span class="line">        base_width=<span class="number">4</span>,</span><br><span class="line">        num_stages=<span class="number">4</span>,</span><br><span class="line">        out_indices=(<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>),</span><br><span class="line">        frozen_stages=<span class="number">1</span>,</span><br><span class="line">        style=<span class="string">'pytorch'</span>),</span><br><span class="line">    neck=dict(</span><br><span class="line">        type=<span class="string">'FPN'</span>,</span><br><span class="line">        in_channels=[<span class="number">256</span>, <span class="number">512</span>, <span class="number">1024</span>, <span class="number">2048</span>],</span><br><span class="line">        out_channels=<span class="number">256</span>,</span><br><span class="line">        num_outs=<span class="number">5</span>),</span><br><span class="line">    rpn_head=dict(</span><br><span class="line">        type=<span class="string">'RPNHead'</span>,</span><br><span class="line">        in_channels=<span class="number">256</span>,</span><br><span class="line">        feat_channels=<span class="number">256</span>,</span><br><span class="line">        anchor_scales=[<span class="number">8</span>],</span><br><span class="line">        anchor_ratios=[<span class="number">0.5</span>, <span class="number">1.0</span>, <span class="number">2.0</span>],</span><br><span class="line">        anchor_strides=[<span class="number">4</span>, <span class="number">8</span>, <span class="number">16</span>, <span class="number">32</span>, <span class="number">64</span>],</span><br><span class="line">        target_means=[<span class="number">.0</span>, <span class="number">.0</span>, <span class="number">.0</span>, <span class="number">.0</span>],</span><br><span class="line">        target_stds=[<span class="number">1.0</span>, <span class="number">1.0</span>, <span class="number">1.0</span>, <span class="number">1.0</span>],</span><br><span class="line">        loss_cls=dict(</span><br><span class="line">            type=<span class="string">'CrossEntropyLoss'</span>, use_sigmoid=<span class="literal">True</span>, loss_weight=<span class="number">1.0</span>),</span><br><span class="line">        loss_bbox=dict(type=<span class="string">'SmoothL1Loss'</span>, beta=<span class="number">1.0</span> / <span class="number">9.0</span>, loss_weight=<span class="number">1.0</span>)),</span><br><span class="line">    bbox_roi_extractor=dict(</span><br><span class="line">        type=<span class="string">'SingleRoIExtractor'</span>,</span><br><span class="line">        roi_layer=dict(type=<span class="string">'RoIAlign'</span>, out_size=<span class="number">7</span>, sample_num=<span class="number">2</span>),</span><br><span class="line">        out_channels=<span class="number">256</span>,</span><br><span class="line">        featmap_strides=[<span class="number">4</span>, <span class="number">8</span>, <span class="number">16</span>, <span class="number">32</span>]),</span><br><span class="line">    bbox_head=[</span><br><span class="line">        dict(</span><br><span class="line">            type=<span class="string">'SharedFCBBoxHead'</span>,</span><br><span class="line">            num_fcs=<span class="number">2</span>,</span><br><span class="line">            in_channels=<span class="number">256</span>,</span><br><span class="line">            fc_out_channels=<span class="number">1024</span>,</span><br><span class="line">            roi_feat_size=<span class="number">7</span>,</span><br><span class="line">            num_classes=<span class="number">2</span>,  <span class="comment">#种类的数目+1，+1为背景类。</span></span><br><span class="line">                            <span class="comment">#SIIM比赛中只有一种类即气胸类，所以此处为1+1=2。</span></span><br><span class="line">                            <span class="comment">#下面的num_classes一样</span></span><br><span class="line">            target_means=[<span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>],</span><br><span class="line">            target_stds=[<span class="number">0.1</span>, <span class="number">0.1</span>, <span class="number">0.2</span>, <span class="number">0.2</span>],</span><br><span class="line">            reg_class_agnostic=<span class="literal">True</span>,</span><br><span class="line">            loss_cls=dict(</span><br><span class="line">                type=<span class="string">'CrossEntropyLoss'</span>,</span><br><span class="line">                use_sigmoid=<span class="literal">False</span>,</span><br><span class="line">                loss_weight=<span class="number">1.0</span>),</span><br><span class="line">            loss_bbox=dict(</span><br><span class="line">                type=<span class="string">'SmoothL1Loss'</span>,</span><br><span class="line">                beta=<span class="number">1.0</span>,</span><br><span class="line">                loss_weight=<span class="number">1.0</span>)),</span><br><span class="line">        dict(</span><br><span class="line">            type=<span class="string">'SharedFCBBoxHead'</span>,</span><br><span class="line">            num_fcs=<span class="number">2</span>,</span><br><span class="line">            in_channels=<span class="number">256</span>,</span><br><span class="line">            fc_out_channels=<span class="number">1024</span>,</span><br><span class="line">            roi_feat_size=<span class="number">7</span>,</span><br><span class="line">            num_classes=<span class="number">2</span>,</span><br><span class="line">            target_means=[<span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>],</span><br><span class="line">            target_stds=[<span class="number">0.05</span>, <span class="number">0.05</span>, <span class="number">0.1</span>, <span class="number">0.1</span>],</span><br><span class="line">            reg_class_agnostic=<span class="literal">True</span>,</span><br><span class="line">            loss_cls=dict(</span><br><span class="line">                type=<span class="string">'CrossEntropyLoss'</span>,</span><br><span class="line">                use_sigmoid=<span class="literal">False</span>,</span><br><span class="line">                loss_weight=<span class="number">1.0</span>),</span><br><span class="line">            loss_bbox=dict(</span><br><span class="line">                type=<span class="string">'SmoothL1Loss'</span>,</span><br><span class="line">                beta=<span class="number">1.0</span>,</span><br><span class="line">                loss_weight=<span class="number">1.0</span>)),</span><br><span class="line">        dict(</span><br><span class="line">            type=<span class="string">'SharedFCBBoxHead'</span>,</span><br><span class="line">            num_fcs=<span class="number">2</span>,</span><br><span class="line">            in_channels=<span class="number">256</span>,</span><br><span class="line">            fc_out_channels=<span class="number">1024</span>,</span><br><span class="line">            roi_feat_size=<span class="number">7</span>,</span><br><span class="line">            num_classes=<span class="number">2</span>,</span><br><span class="line">            target_means=[<span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>],</span><br><span class="line">            target_stds=[<span class="number">0.033</span>, <span class="number">0.033</span>, <span class="number">0.067</span>, <span class="number">0.067</span>],</span><br><span class="line">            reg_class_agnostic=<span class="literal">True</span>,</span><br><span class="line">            loss_cls=dict(</span><br><span class="line">                type=<span class="string">'CrossEntropyLoss'</span>,</span><br><span class="line">                use_sigmoid=<span class="literal">False</span>,</span><br><span class="line">                loss_weight=<span class="number">1.0</span>),</span><br><span class="line">            loss_bbox=dict(</span><br><span class="line">                type=<span class="string">'SmoothL1Loss'</span>,</span><br><span class="line">                beta=<span class="number">1.0</span>,</span><br><span class="line">                loss_weight=<span class="number">1.0</span>))</span><br><span class="line">    ],</span><br><span class="line">    mask_roi_extractor=dict(</span><br><span class="line">        type=<span class="string">'SingleRoIExtractor'</span>,</span><br><span class="line">        roi_layer=dict(type=<span class="string">'RoIAlign'</span>, out_size=<span class="number">14</span>, sample_num=<span class="number">2</span>),</span><br><span class="line">        out_channels=<span class="number">256</span>,</span><br><span class="line">        featmap_strides=[<span class="number">4</span>, <span class="number">8</span>, <span class="number">16</span>, <span class="number">32</span>]),</span><br><span class="line">    mask_head=dict(</span><br><span class="line">        type=<span class="string">'FCNMaskHead'</span>,</span><br><span class="line">        num_convs=<span class="number">4</span>,</span><br><span class="line">        in_channels=<span class="number">256</span>,</span><br><span class="line">        conv_out_channels=<span class="number">256</span>,</span><br><span class="line">        num_classes=<span class="number">2</span>,</span><br><span class="line">        loss_mask=dict(</span><br><span class="line">            type=<span class="string">'CrossEntropyLoss'</span>, use_mask=<span class="literal">True</span>, loss_weight=<span class="number">1.0</span>)))</span><br><span class="line"><span class="comment"># model training and testing settings</span></span><br><span class="line">train_cfg = dict(</span><br><span class="line">    rpn=dict(</span><br><span class="line">        assigner=dict(</span><br><span class="line">            type=<span class="string">'MaxIoUAssigner'</span>,</span><br><span class="line">            pos_iou_thr=<span class="number">0.7</span>,</span><br><span class="line">            neg_iou_thr=<span class="number">0.3</span>,</span><br><span class="line">            min_pos_iou=<span class="number">0.3</span>,</span><br><span class="line">            ignore_iof_thr=<span class="number">-1</span>),</span><br><span class="line">        sampler=dict(</span><br><span class="line">            type=<span class="string">'RandomSampler'</span>,</span><br><span class="line">            num=<span class="number">256</span>,</span><br><span class="line">            pos_fraction=<span class="number">0.5</span>,</span><br><span class="line">            neg_pos_ub=<span class="number">-1</span>,</span><br><span class="line">            add_gt_as_proposals=<span class="literal">False</span>),</span><br><span class="line">        allowed_border=<span class="number">0</span>,</span><br><span class="line">        pos_weight=<span class="number">-1</span>,</span><br><span class="line">        debug=<span class="literal">False</span>),</span><br><span class="line">    rpn_proposal=dict(</span><br><span class="line">        nms_across_levels=<span class="literal">False</span>,</span><br><span class="line">        nms_pre=<span class="number">2000</span>,</span><br><span class="line">        nms_post=<span class="number">2000</span>,</span><br><span class="line">        max_num=<span class="number">2000</span>,</span><br><span class="line">        nms_thr=<span class="number">0.7</span>,</span><br><span class="line">        min_bbox_size=<span class="number">0</span>),</span><br><span class="line">    rcnn=[</span><br><span class="line">        dict(</span><br><span class="line">            assigner=dict(</span><br><span class="line">                type=<span class="string">'MaxIoUAssigner'</span>,</span><br><span class="line">                pos_iou_thr=<span class="number">0.5</span>,</span><br><span class="line">                neg_iou_thr=<span class="number">0.5</span>,</span><br><span class="line">                min_pos_iou=<span class="number">0.5</span>,</span><br><span class="line">                ignore_iof_thr=<span class="number">-1</span>),</span><br><span class="line">            sampler=dict(</span><br><span class="line">                type=<span class="string">'RandomSampler'</span>,</span><br><span class="line">                num=<span class="number">512</span>,</span><br><span class="line">                pos_fraction=<span class="number">0.25</span>,</span><br><span class="line">                neg_pos_ub=<span class="number">-1</span>,</span><br><span class="line">                add_gt_as_proposals=<span class="literal">True</span>),</span><br><span class="line">            mask_size=<span class="number">28</span>,</span><br><span class="line">            pos_weight=<span class="number">-1</span>,</span><br><span class="line">            debug=<span class="literal">False</span>),</span><br><span class="line">        dict(</span><br><span class="line">            assigner=dict(</span><br><span class="line">                type=<span class="string">'MaxIoUAssigner'</span>,</span><br><span class="line">                pos_iou_thr=<span class="number">0.6</span>,</span><br><span class="line">                neg_iou_thr=<span class="number">0.6</span>,</span><br><span class="line">                min_pos_iou=<span class="number">0.6</span>,</span><br><span class="line">                ignore_iof_thr=<span class="number">-1</span>),</span><br><span class="line">            sampler=dict(</span><br><span class="line">                type=<span class="string">'RandomSampler'</span>,</span><br><span class="line">                num=<span class="number">512</span>,</span><br><span class="line">                pos_fraction=<span class="number">0.25</span>,</span><br><span class="line">                neg_pos_ub=<span class="number">-1</span>,</span><br><span class="line">                add_gt_as_proposals=<span class="literal">True</span>),</span><br><span class="line">            mask_size=<span class="number">28</span>,</span><br><span class="line">            pos_weight=<span class="number">-1</span>,</span><br><span class="line">            debug=<span class="literal">False</span>),</span><br><span class="line">        dict(</span><br><span class="line">            assigner=dict(</span><br><span class="line">                type=<span class="string">'MaxIoUAssigner'</span>,</span><br><span class="line">                pos_iou_thr=<span class="number">0.7</span>,</span><br><span class="line">                neg_iou_thr=<span class="number">0.7</span>,</span><br><span class="line">                min_pos_iou=<span class="number">0.7</span>,</span><br><span class="line">                ignore_iof_thr=<span class="number">-1</span>),</span><br><span class="line">            sampler=dict(</span><br><span class="line">                type=<span class="string">'RandomSampler'</span>,</span><br><span class="line">                num=<span class="number">512</span>,</span><br><span class="line">                pos_fraction=<span class="number">0.25</span>,</span><br><span class="line">                neg_pos_ub=<span class="number">-1</span>,</span><br><span class="line">                add_gt_as_proposals=<span class="literal">True</span>),</span><br><span class="line">            mask_size=<span class="number">28</span>,</span><br><span class="line">            pos_weight=<span class="number">-1</span>,</span><br><span class="line">            debug=<span class="literal">False</span>)</span><br><span class="line">    ],</span><br><span class="line">    stage_loss_weights=[<span class="number">1</span>, <span class="number">0.5</span>, <span class="number">0.25</span>])</span><br><span class="line">test_cfg = dict(</span><br><span class="line">    rpn=dict(</span><br><span class="line">        nms_across_levels=<span class="literal">False</span>,</span><br><span class="line">        nms_pre=<span class="number">1000</span>,</span><br><span class="line">        nms_post=<span class="number">1000</span>,</span><br><span class="line">        max_num=<span class="number">1000</span>,</span><br><span class="line">        nms_thr=<span class="number">0.7</span>,</span><br><span class="line">        min_bbox_size=<span class="number">0</span>),</span><br><span class="line">    rcnn=dict(</span><br><span class="line">        score_thr=<span class="number">0.05</span>,</span><br><span class="line">        nms=dict(type=<span class="string">'nms'</span>, iou_thr=<span class="number">0.5</span>),</span><br><span class="line">        max_per_img=<span class="number">100</span>,</span><br><span class="line">        mask_thr_binary=<span class="number">0.5</span>),</span><br><span class="line">    keep_all_stages=<span class="literal">False</span>)</span><br><span class="line"><span class="comment"># dataset settings</span></span><br><span class="line">dataset_type = <span class="string">'CocoDataset'</span>  <span class="comment">#数据类型</span></span><br><span class="line">data_root = <span class="string">'data/coco/'</span>  <span class="comment">#数据所在目录</span></span><br><span class="line">img_norm_cfg = dict(</span><br><span class="line">    mean=[<span class="number">123.675</span>, <span class="number">116.28</span>, <span class="number">103.53</span>], std=[<span class="number">58.395</span>, <span class="number">57.12</span>, <span class="number">57.375</span>], to_rgb=<span class="literal">True</span>)</span><br><span class="line">data = dict(</span><br><span class="line">    imgs_per_gpu=<span class="number">2</span>,  <span class="comment">#每块GPU每次所载入的图片</span></span><br><span class="line">    workers_per_gpu=<span class="number">2</span>,</span><br><span class="line">    train=dict(</span><br><span class="line">        type=dataset_type,</span><br><span class="line">        ann_file=data_root + <span class="string">'annotations/instances_train2017.json'</span>, <span class="comment">#标注文件</span></span><br><span class="line">        img_prefix=data_root + <span class="string">'train2017/'</span>, <span class="comment">#训练集所在目录</span></span><br><span class="line">        img_scale=(<span class="number">1024</span>, <span class="number">1024</span>), <span class="comment">#图片宽高</span></span><br><span class="line">        img_norm_cfg=img_norm_cfg,</span><br><span class="line">        size_divisor=<span class="number">32</span>,</span><br><span class="line">        flip_ratio=<span class="number">0</span>,</span><br><span class="line">        with_mask=<span class="literal">True</span>,</span><br><span class="line">        with_crowd=<span class="literal">True</span>,</span><br><span class="line">        with_label=<span class="literal">True</span>),</span><br><span class="line">    val=dict(</span><br><span class="line">        type=dataset_type,</span><br><span class="line">        ann_file=data_root + <span class="string">'annotations/instances_val2017.json'</span>,</span><br><span class="line">        img_prefix=data_root + <span class="string">'train2017/'</span>,</span><br><span class="line">        img_scale=(<span class="number">1024</span>, <span class="number">1024</span>),</span><br><span class="line">        img_norm_cfg=img_norm_cfg,</span><br><span class="line">        size_divisor=<span class="number">32</span>,</span><br><span class="line">        flip_ratio=<span class="number">0</span>,</span><br><span class="line">        with_mask=<span class="literal">True</span>,</span><br><span class="line">        with_crowd=<span class="literal">True</span>,</span><br><span class="line">        with_label=<span class="literal">True</span>),</span><br><span class="line">    test=dict(</span><br><span class="line">        type=dataset_type,</span><br><span class="line">        ann_file=data_root + <span class="string">'annotations/instances_test2017.json'</span>,</span><br><span class="line">        img_prefix=data_root + <span class="string">'test2017/'</span>,</span><br><span class="line">        img_scale=(<span class="number">1024</span>, <span class="number">1024</span>),</span><br><span class="line">        img_norm_cfg=img_norm_cfg,</span><br><span class="line">        size_divisor=<span class="number">32</span>,</span><br><span class="line">        flip_ratio=<span class="number">0</span>,</span><br><span class="line">        with_mask=<span class="literal">True</span>,</span><br><span class="line">        with_label=<span class="literal">False</span>,</span><br><span class="line">        test_mode=<span class="literal">True</span>))</span><br><span class="line"><span class="comment"># optimizer</span></span><br><span class="line">optimizer = dict(type=<span class="string">'SGD'</span>, lr=<span class="number">0.0002</span>, momentum=<span class="number">0.9</span>, weight_decay=<span class="number">0.0001</span>)</span><br><span class="line">optimizer_config = dict(grad_clip=dict(max_norm=<span class="number">35</span>, norm_type=<span class="number">2</span>))</span><br><span class="line"><span class="comment"># learning policy</span></span><br><span class="line">lr_config = dict(</span><br><span class="line">    policy=<span class="string">'step'</span>,</span><br><span class="line">    warmup=<span class="string">'linear'</span>,</span><br><span class="line">    warmup_iters=<span class="number">300</span>, <span class="comment">#预训练迭代次数</span></span><br><span class="line">    warmup_ratio=<span class="number">0.00015</span>,</span><br><span class="line">    step=[<span class="number">8</span>, <span class="number">11</span>])</span><br><span class="line">checkpoint_config = dict(interval=<span class="number">1</span>)</span><br><span class="line"><span class="comment"># yapf:disable</span></span><br><span class="line">log_config = dict(</span><br><span class="line">    interval=<span class="number">50</span>,</span><br><span class="line">    hooks=[</span><br><span class="line">        dict(type=<span class="string">'TextLoggerHook'</span>),</span><br><span class="line">        <span class="comment"># dict(type='TensorboardLoggerHook')</span></span><br><span class="line">    ])</span><br><span class="line"><span class="comment"># yapf:enable</span></span><br><span class="line"><span class="comment"># runtime settings</span></span><br><span class="line">total_epochs = <span class="number">50</span>   <span class="comment">#训练的epoch数，SIIM的训练集较小，故需要多训练几轮</span></span><br><span class="line">dist_params = dict(backend=<span class="string">'nccl'</span>)</span><br><span class="line">log_level = <span class="string">'INFO'</span></span><br><span class="line">work_dir = <span class="string">'./work_dirs/cascade_mask_rcnn_x101_64x4d_fpn_1x'</span> <span class="comment">#模型和日志的存放位置</span></span><br><span class="line">load_from = <span class="literal">None</span>   </span><br><span class="line">resume_from = <span class="literal">None</span>   <span class="comment">#加载checkpoint</span></span><br><span class="line">workflow = [(<span class="string">'train'</span>, <span class="number">1</span>)]</span><br></pre></td></tr></table></figure><h2 id="修改coco数据配置文件"><a href="#修改coco数据配置文件" class="headerlink" title="修改coco数据配置文件"></a>修改coco数据配置文件</h2><p>   编辑mmdet/datasets/coco.py，修改CLASSES。例如SIIM比赛中只有一个Pneumothorax类，则改成如下形式：</p>   <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CLASSES = (<span class="string">'Pneumothorax'</span>,)</span><br></pre></td></tr></table></figure><h2 id="训练模型"><a href="#训练模型" class="headerlink" title="训练模型"></a>训练模型</h2><p>   注意：配置文件中的默认学习率是8个gpu和2个img/gpu(batch size= 8<em>2 = 16)。根据线性缩放规则，如果您使用不同的GPU数目或img/gpu，您需要设置与batch size成比例的学习率。例如，如果4GPUs </em> 2 img/gpu的lr=0.01，那么16GPUs * 4 img/gpu的lr=0.08。</p><h3 id="单GPU训练"><a href="#单GPU训练" class="headerlink" title="单GPU训练"></a>单GPU训练</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python tools/train.py $&#123;CONFIG_FILE&#125;</span><br></pre></td></tr></table></figure><p>可选参数：</p><ul><li>—work_dir ${YOUR_WORK_DIR} ：指定work_dir</li></ul><h3 id="多GPU训练"><a href="#多GPU训练" class="headerlink" title="多GPU训练"></a>多GPU训练</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./tools/dist_train.sh $&#123;CONFIG_FILE&#125; $&#123;GPU_NUM&#125; [optional arguments]</span><br></pre></td></tr></table></figure><p>可选参数：</p><ul><li><code>--validate [k]</code>：训练时每k epochs（默认为1）执行一次验证</li><li><code>--work_dir ${YOUR_WORK_DIR}</code>：指定work_dir</li><li><code>--resume_from ${CHECKPOINT_FILE}</code>：从指定的checkpoint文件开始训练</li></ul><p>对于刚刚配置的环境，我们只需输入如下命令就可以训练啦：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./tools/dist_train.sh configs/cascade_mask_rcnn_x101_64x4d_fpn_1x.py 4 --validate</span><br></pre></td></tr></table></figure><p>训练log</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br></pre></td><td class="code"><pre><span class="line">2019-07-19 11:47:51,271 - INFO - Distributed training: True</span><br><span class="line">2019-07-19 11:47:57,025 - INFO - load model from: open-mmlab://resnext101_64x4d</span><br><span class="line">2019-07-19 11:48:04,712 - WARNING - missing keys in source state_dict: layer3.15.bn1.num_batches_tracked, layer3.4.bn3.num_batches_tracked, layer2.0.bn2.num_batches_tracked, layer3.8.bn3.num_batches_tracked, layer3.12.bn2.num_batches_tracked, layer3.0.downsample.1.num_batches_tracked, layer3.7.bn1.num_batches_tracked, layer1.1.bn2.num_batches_tracked, layer3.2.bn3.num_batches_tracked, layer4.0.downsample.1.num_batches_tracked, layer3.20.bn1.num_batches_tracked, layer3.7.bn3.num_batches_tracked, layer3.15.bn3.num_batches_tracked, layer3.19.bn1.num_batches_tracked, layer3.22.bn3.num_batches_tracked, layer4.2.bn1.num_batches_tracked, layer4.2.bn2.num_batches_tracked, layer4.0.bn3.num_batches_tracked, layer2.1.bn2.num_batches_tracked, layer3.1.bn2.num_batches_tracked, layer3.9.bn2.num_batches_tracked, layer3.3.bn2.num_batches_tracked, layer1.2.bn1.num_batches_tracked, layer1.0.bn2.num_batches_tracked, layer3.11.bn1.num_batches_tracked, layer1.0.bn1.num_batches_tracked, layer2.3.bn1.num_batches_tracked, layer3.16.bn2.num_batches_tracked, layer3.3.bn3.num_batches_tracked, layer3.14.bn1.num_batches_tracked, layer3.12.bn3.num_batches_tracked, layer3.13.bn1.num_batches_tracked, layer3.6.bn2.num_batches_tracked, layer3.18.bn1.num_batches_tracked, layer2.3.bn3.num_batches_tracked, layer3.21.bn2.num_batches_tracked, layer2.2.bn3.num_batches_tracked, layer1.1.bn3.num_batches_tracked, layer3.9.bn1.num_batches_tracked, layer3.20.bn3.num_batches_tracked, layer3.3.bn1.num_batches_tracked, layer3.8.bn1.num_batches_tracked, layer3.0.bn2.num_batches_tracked, layer3.17.bn3.num_batches_tracked, layer3.0.bn3.num_batches_tracked, layer3.18.bn2.num_batches_tracked, layer3.16.bn1.num_batches_tracked, layer3.14.bn2.num_batches_tracked, layer3.16.bn3.num_batches_tracked, layer3.17.bn2.num_batches_tracked, layer4.1.bn2.num_batches_tracked, layer3.22.bn2.num_batches_tracked, layer3.2.bn2.num_batches_tracked, layer3.19.bn3.num_batches_tracked, layer3.0.bn1.num_batches_tracked, layer1.2.bn2.num_batches_tracked, layer4.1.bn3.num_batches_tracked, layer3.12.bn1.num_batches_tracked, layer3.5.bn2.num_batches_tracked, layer2.3.bn2.num_batches_tracked, layer3.11.bn2.num_batches_tracked, layer3.18.bn3.num_batches_tracked, layer3.8.bn2.num_batches_tracked, layer3.17.bn1.num_batches_tracked, layer3.22.bn1.num_batches_tracked, layer3.20.bn2.num_batches_tracked, layer3.11.bn3.num_batches_tracked, layer3.4.bn1.num_batches_tracked, layer2.0.bn1.num_batches_tracked, layer3.1.bn1.num_batches_tracked, layer3.6.bn1.num_batches_tracked, layer2.0.downsample.1.num_batches_tracked, layer4.0.bn2.num_batches_tracked, layer1.2.bn3.num_batches_tracked, layer3.13.bn3.num_batches_tracked, layer3.13.bn2.num_batches_tracked, layer4.1.bn1.num_batches_tracked, bn1.num_batches_tracked, layer3.10.bn3.num_batches_tracked, layer2.1.bn1.num_batches_tracked, layer3.5.bn1.num_batches_tracked, layer3.6.bn3.num_batches_tracked, layer3.19.bn2.num_batches_tracked, layer3.7.bn2.num_batches_tracked, layer2.0.bn3.num_batches_tracked, layer3.15.bn2.num_batches_tracked, layer3.9.bn3.num_batches_tracked, layer3.10.bn2.num_batches_tracked, layer1.1.bn1.num_batches_tracked, layer2.2.bn2.num_batches_tracked, layer2.2.bn1.num_batches_tracked, layer3.5.bn3.num_batches_tracked, layer3.2.bn1.num_batches_tracked, layer3.1.bn3.num_batches_tracked, layer4.2.bn3.num_batches_tracked, layer3.10.bn1.num_batches_tracked, layer3.21.bn1.num_batches_tracked, layer3.21.bn3.num_batches_tracked, layer3.4.bn2.num_batches_tracked, layer2.1.bn3.num_batches_tracked, layer1.0.downsample.1.num_batches_tracked, layer1.0.bn3.num_batches_tracked, layer4.0.bn1.num_batches_tracked, layer3.14.bn3.num_batches_tracked</span><br><span class="line"></span><br><span class="line">loading annotations into memory...</span><br><span class="line">Done (t=0.04s)</span><br><span class="line">creating index...</span><br><span class="line">index created!</span><br><span class="line">loading annotations into memory...</span><br><span class="line">Done (t=0.03s)</span><br><span class="line">creating index...</span><br><span class="line">index created!</span><br><span class="line">loading annotations into memory...</span><br><span class="line">loading annotations into memory...</span><br><span class="line">Done (t=0.05s)</span><br><span class="line">creating index...</span><br><span class="line">index created!Done (t=0.06s)</span><br><span class="line"></span><br><span class="line">creating index...</span><br><span class="line">index created!</span><br><span class="line">loading annotations into memory...</span><br><span class="line">Done (t=0.00s)</span><br><span class="line">creating index...</span><br><span class="line">index created!</span><br><span class="line">loading annotations into memory...</span><br><span class="line">Done (t=0.00s)</span><br><span class="line">creating index...</span><br><span class="line">index created!</span><br><span class="line">2019-07-19 11:48:08,173 - INFO - Start running, host: root@dl-All-Series, work_dir: /home/dl/d/12siim/0715hk/mmdetection/work_dirs/cascade_mask_rcnn_x101_64x4d_fpn_1x</span><br><span class="line">2019-07-19 11:48:08,174 - INFO - workflow: [(&apos;train&apos;, 1)], max: 50 epochs</span><br><span class="line">loading annotations into memory...</span><br><span class="line">Done (t=0.00s)</span><br><span class="line">creating index...</span><br><span class="line">index created!</span><br><span class="line">loading annotations into memory...</span><br><span class="line">Done (t=0.00s)</span><br><span class="line">creating index...</span><br><span class="line">index created!</span><br><span class="line">2019-07-19 11:50:30,248 - INFO - Epoch [1][50/375]      lr: 0.00003, eta: 14:45:23, time: 2.841, data_time: 0.199, memory: 10024, loss_rpn_cls: 0.7045, loss_rpn_bbox: 0.0066, s0.loss_cls: 0.5725, s0.acc: 88.9043, s0.loss_bbox: 0.0005, s0.loss_mask: 2.8232, s1.loss_cls: 0.3224, s1.acc: 74.6172, s1.loss_bbox: 0.0002, s1.loss_mask: 1.6205, s2.loss_cls: 0.1525, s2.acc: 90.1211, s2.loss_bbox: 0.0000, s2.loss_mask: 0.5753, loss: 6.7784</span><br><span class="line">2019-07-19 11:52:41,648 - INFO - Epoch [1][100/375]     lr: 0.00007, eta: 14:09:53, time: 2.628, data_time: 0.045, memory: 10024, loss_rpn_cls: 0.6970, loss_rpn_bbox: 0.0089, s0.loss_cls: 0.2083, s0.acc: 99.7930, s0.loss_bbox: 0.0003, s0.loss_mask: 0.7883, s1.loss_cls: 0.1744, s1.acc: 99.7988, s1.loss_bbox: 0.0001, s1.loss_mask: 0.4091, s2.loss_cls: 0.1105, s2.acc: 99.7949, s2.loss_bbox: 0.0000, s2.loss_mask: 0.2313, loss: 2.6281</span><br><span class="line">2019-07-19 11:54:53,230 - INFO - Epoch [1][150/375]     lr: 0.00010, eta: 13:57:00, time: 2.632, data_time: 0.041, memory: 10024, loss_rpn_cls: 0.6769, loss_rpn_bbox: 0.0073, s0.loss_cls: 0.0545, s0.acc: 99.7344, s0.loss_bbox: 0.0020, s0.loss_mask: 0.6995, s1.loss_cls: 0.0519, s1.acc: 99.7871, s1.loss_bbox: 0.0004, s1.loss_mask: 0.3705, s2.loss_cls: 0.0455, s2.acc: 99.8027, s2.loss_bbox: 0.0000, s2.loss_mask: 0.1762, loss: 2.0847</span><br><span class="line">2019-07-19 11:57:06,704 - INFO - Epoch [1][200/375]     lr: 0.00013, eta: 13:52:23, time: 2.669, data_time: 0.042, memory: 10024, loss_rpn_cls: 0.5973, loss_rpn_bbox: 0.0074, s0.loss_cls: 0.0639, s0.acc: 99.4219, s0.loss_bbox: 0.0106, s0.loss_mask: 0.6261, s1.loss_cls: 0.0481, s1.acc: 99.6797, s1.loss_bbox: 0.0028, s1.loss_mask: 0.3498, s2.loss_cls: 0.0360, s2.acc: 99.7715, s2.loss_bbox: 0.0004, s2.loss_mask: 0.1757, loss: 1.9182</span><br><span class="line">2019-07-19 11:59:20,874 - INFO - Epoch [1][250/375]     lr: 0.00017, eta: 13:49:37, time: 2.684, data_time: 0.039, memory: 10024, loss_rpn_cls: 0.3471, loss_rpn_bbox: 0.0087, s0.loss_cls: 0.0609, s0.acc: 98.8672, s0.loss_bbox: 0.0256, s0.loss_mask: 0.5709, s1.loss_cls: 0.0274, s1.acc: 99.5234, s1.loss_bbox: 0.0066, s1.loss_mask: 0.3234, s2.loss_cls: 0.0211, s2.acc: 99.7559, s2.loss_bbox: 0.0006, s2.loss_mask: 0.1756, loss: 1.5679</span><br><span class="line">2019-07-19 12:01:35,584 - INFO - Epoch [1][300/375]     lr: 0.00020, eta: 13:47:30, time: 2.693, data_time: 0.040, memory: 10024, loss_rpn_cls: 0.1487, loss_rpn_bbox: 0.0081, s0.loss_cls: 0.0710, s0.acc: 98.5605, s0.loss_bbox: 0.0343, s0.loss_mask: 0.5988, s1.loss_cls: 0.0186, s1.acc: 99.4336, s1.loss_bbox: 0.0084, s1.loss_mask: 0.3309, s2.loss_cls: 0.0099, s2.acc: 99.6973, s2.loss_bbox: 0.0013, s2.loss_mask: 0.1713, loss: 1.4013</span><br><span class="line">2019-07-19 12:03:48,274 - INFO - Epoch [1][350/375]     lr: 0.00020, eta: 13:43:39, time: 2.654, data_time: 0.044, memory: 10024, loss_rpn_cls: 0.0949, loss_rpn_bbox: 0.0086, s0.loss_cls: 0.0763, s0.acc: 98.4336, s0.loss_bbox: 0.0383, s0.loss_mask: 0.4798, s1.loss_cls: 0.0180, s1.acc: 99.4102, s1.loss_bbox: 0.0088, s1.loss_mask: 0.2716, s2.loss_cls: 0.0072, s2.acc: 99.6953, s2.loss_bbox: 0.0014, s2.loss_mask: 0.1467, loss: 1.1517</span><br><span class="line">[&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;] 288/286, 7.3 task/s, elapsed: 39s, ETA:     0s</span><br><span class="line"></span><br><span class="line">Loading and preparing results...</span><br><span class="line">DONE (t=0.00s)</span><br><span class="line">creating index...</span><br><span class="line">index created!</span><br><span class="line">Running per image evaluation...</span><br><span class="line">Evaluate annotation type *bbox*</span><br><span class="line">DONE (t=0.18s).</span><br><span class="line">Accumulating evaluation results...</span><br><span class="line">DONE (t=0.04s).</span><br><span class="line"> Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000</span><br><span class="line"> Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.002</span><br><span class="line"> Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000</span><br><span class="line"> Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000</span><br><span class="line"> Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000</span><br><span class="line"> Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000</span><br><span class="line"> Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.002</span><br><span class="line"> Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.005</span><br><span class="line"> Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.005</span><br><span class="line"> Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000</span><br><span class="line"> Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000</span><br><span class="line"> Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.005</span><br><span class="line">Loading and preparing results...</span><br><span class="line">DONE (t=0.01s)</span><br><span class="line">creating index...</span><br><span class="line">index created!</span><br><span class="line">Running per image evaluation...</span><br><span class="line">Evaluate annotation type *segm*</span><br><span class="line">DONE (t=0.19s).</span><br><span class="line">Accumulating evaluation results...</span><br><span class="line">DONE (t=0.04s).</span><br><span class="line"> Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000</span><br><span class="line"> Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000</span><br><span class="line"> Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000</span><br><span class="line"> Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000</span><br><span class="line"> Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000</span><br><span class="line"> Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000</span><br><span class="line"> Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000</span><br><span class="line"> Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.001</span><br><span class="line"> Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.001</span><br><span class="line"> Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000</span><br><span class="line"> Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000</span><br><span class="line"> Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.001</span><br></pre></td></tr></table></figure><h2 id="测试模型"><a href="#测试模型" class="headerlink" title="测试模型"></a>测试模型</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># single-gpu testing</span></span><br><span class="line">python tools/test.py <span class="variable">$&#123;CONFIG_FILE&#125;</span> <span class="variable">$&#123;CHECKPOINT_FILE&#125;</span> [--out <span class="variable">$&#123;RESULT_FILE&#125;</span>] [--<span class="built_in">eval</span> <span class="variable">$&#123;EVAL_METRICS&#125;</span>] [--show]</span><br><span class="line"></span><br><span class="line"><span class="comment"># multi-gpu testing</span></span><br><span class="line">./tools/dist_test.sh <span class="variable">$&#123;CONFIG_FILE&#125;</span> <span class="variable">$&#123;CHECKPOINT_FILE&#125;</span> <span class="variable">$&#123;GPU_NUM&#125;</span> [--out <span class="variable">$&#123;RESULT_FILE&#125;</span>] [--<span class="built_in">eval</span> <span class="variable">$&#123;EVAL_METRICS&#125;</span>]</span><br></pre></td></tr></table></figure><p>可选参数：</p><ul><li><code>RESULT_FILE</code>： 用于存放测试结果的pickle格式的文件名，若没有指定这个参数，最终结果将不会输出到文件里。</li><li><code>EVAL_METRICS</code>：需要评估的类型，可选选项有： <code>proposal_fast</code>, <code>proposal</code>, <code>bbox</code>, <code>segm</code>, <code>keypoints</code>.</li><li><code>--show</code>：若指定了该参数，检测结果将在新窗口中以图片形式显示出来。（只能用于单GPU测试。）</li></ul><p>对于测试数据集，我们输入了如下命令：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./tools/dist_test.sh configs/cascade_mask_rcnn_x101_64x4d_fpn_1x.py work_dirs/cascade_mask_rcnn_x101_64x4d_fpn_1x/epoch_50.pth 4 --<span class="built_in">eval</span> segm</span><br></pre></td></tr></table></figure><p>由于指定了 —eval 为 segm，最终的预测结果会输出到result.pkl.segm.json文件里。</p><p>参考文献：</p><ul><li>MMDetection官方文档：<a href="https://github.com/open-mmlab/mmdetection" target="_blank" rel="noopener">https://github.com/open-mmlab/mmdetection</a></li><li>COCO官方：<a href="http://cocodataset.org/#format-data" target="_blank" rel="noopener">http://cocodataset.org/#format-data</a></li><li>COCO数据集的标注格式：<a href="https://zhuanlan.zhihu.com/p/29393415" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/29393415</a></li><li>mmdetection训练自己的数据：<a href="https://blog.csdn.net/qq_36302589/article/details/86149293" target="_blank" rel="noopener">https://blog.csdn.net/qq_36302589/article/details/86149293</a></li><li>mmdetection的configs中的各项参数具体解释：<a href="https://blog.csdn.net/hajlyx/article/details/85991400" target="_blank" rel="noopener">https://blog.csdn.net/hajlyx/article/details/85991400</a></li><li>以及各路大佬的答疑解惑</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;​    &lt;a href=&quot;https://github.com/open-mmlab/mmdetection&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;MMDetection&lt;/a&gt;是商汤科技开源的用于深度学习目标检测的库，而SIIM-ACR Pne
      
    
    </summary>
    
      <category term="计算机视觉" scheme="http://a-kali.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/"/>
    
    
      <category term="计算机视觉" scheme="http://a-kali.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/"/>
    
      <category term="语义分割" scheme="http://a-kali.github.io/tags/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2/"/>
    
      <category term="Kaggle" scheme="http://a-kali.github.io/tags/Kaggle/"/>
    
      <category term="深度学习" scheme="http://a-kali.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="PyTorch" scheme="http://a-kali.github.io/tags/PyTorch/"/>
    
      <category term="MMDetection" scheme="http://a-kali.github.io/tags/MMDetection/"/>
    
      <category term="COCO" scheme="http://a-kali.github.io/tags/COCO/"/>
    
  </entry>
  
</feed>
