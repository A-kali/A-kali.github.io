<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>某科学のBLOG</title>
  
  <subtitle>与其感慨路难行，不如马上出发</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://a-kali.github.io/"/>
  <updated>2019-11-06T10:38:36.281Z</updated>
  <id>http://a-kali.github.io/</id>
  
  <author>
    <name>Hsaki</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>基于CNN对轻度认知障碍到阿兹海默症转化的预测</title>
    <link href="http://a-kali.github.io/2019/11/06/%E5%9F%BA%E4%BA%8ECNN%E5%AF%B9%E8%BD%BB%E5%BA%A6%E8%AE%A4%E7%9F%A5%E9%9A%9C%E7%A2%8D%E5%88%B0%E9%98%BF%E5%85%B9%E6%B5%B7%E9%BB%98%E7%97%87%E8%BD%AC%E5%8C%96%E7%9A%84%E9%A2%84%E6%B5%8B/"/>
    <id>http://a-kali.github.io/2019/11/06/基于CNN对轻度认知障碍到阿兹海默症转化的预测/</id>
    <published>2019-11-06T06:56:51.000Z</published>
    <updated>2019-11-06T10:38:36.281Z</updated>
    
    <content type="html"><![CDATA[<h1 id="项目介绍"><a href="#项目介绍" class="headerlink" title="项目介绍"></a>项目介绍</h1><p>阿尔茨海默症(Alzheimer disease, AD)是多发于中老年人的一种疾病，轻度认知障碍(Mild cognitive impairment, MCI)是介于正常衰老和痴呆之间的一种中间状态，对可能向AD转化的MCI进行早期诊断和干预可以有效延缓AD病程的发展。本项目试图使用卷积神经网络技术对一定时间内转化为AD的MCI(converted MCI, cMCI)和未转化为AD的MCI(stable MCI, sMCI)进行分类。</p><h1 id="MedicalNet"><a href="#MedicalNet" class="headerlink" title="MedicalNet"></a>MedicalNet</h1><p>项目地址：<a href="https://github.com/Tencent/MedicalNet" target="_blank" rel="noopener">https://github.com/Tencent/MedicalNet</a></p><h1 id="Siamese-Network"><a href="#Siamese-Network" class="headerlink" title="Siamese Network"></a>Siamese Network</h1><h2 id="Face-Alignment"><a href="#Face-Alignment" class="headerlink" title="Face Alignment"></a>Face Alignment</h2><h2 id="Data-Augmentation"><a href="#Data-Augmentation" class="headerlink" title="Data Augmentation"></a>Data Augmentation</h2><p><a href="https://www.leiphone.com/news/201903/nX5goc6wyF8CdoAR.html" target="_blank" rel="noopener">https://www.leiphone.com/news/201903/nX5goc6wyF8CdoAR.html</a></p><h2 id="图像配准"><a href="#图像配准" class="headerlink" title="图像配准"></a>图像配准</h2><h2 id="半监督学习"><a href="#半监督学习" class="headerlink" title="半监督学习"></a>半监督学习</h2>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;项目介绍&quot;&gt;&lt;a href=&quot;#项目介绍&quot; class=&quot;headerlink&quot; title=&quot;项目介绍&quot;&gt;&lt;/a&gt;项目介绍&lt;/h1&gt;&lt;p&gt;阿尔茨海默症(Alzheimer disease, AD)是多发于中老年人的一种疾病，轻度认知障碍(Mild cogniti
      
    
    </summary>
    
      <category term="计算机视觉" scheme="http://a-kali.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/"/>
    
    
      <category term="计算机视觉" scheme="http://a-kali.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/"/>
    
      <category term="CNN" scheme="http://a-kali.github.io/tags/CNN/"/>
    
      <category term="3D 卷积" scheme="http://a-kali.github.io/tags/3D-%E5%8D%B7%E7%A7%AF/"/>
    
      <category term="医疗影像" scheme="http://a-kali.github.io/tags/%E5%8C%BB%E7%96%97%E5%BD%B1%E5%83%8F/"/>
    
      <category term="MedicalNet" scheme="http://a-kali.github.io/tags/MedicalNet/"/>
    
      <category term="孪生网络" scheme="http://a-kali.github.io/tags/%E5%AD%AA%E7%94%9F%E7%BD%91%E7%BB%9C/"/>
    
      <category term="Face Alignment" scheme="http://a-kali.github.io/tags/Face-Alignment/"/>
    
      <category term="PyTorch" scheme="http://a-kali.github.io/tags/PyTorch/"/>
    
  </entry>
  
  <entry>
    <title>深度学习自动驾驶概述</title>
    <link href="http://a-kali.github.io/2019/11/05/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E5%8A%A8%E9%A9%BE%E9%A9%B6%E6%A6%82%E8%BF%B0/"/>
    <id>http://a-kali.github.io/2019/11/05/深度学习自动驾驶概述/</id>
    <published>2019-11-05T09:45:08.000Z</published>
    <updated>2019-11-05T09:46:18.720Z</updated>
    
    <content type="html"><![CDATA[<p><strong>目标：</strong>使用端到端的深度学习方法，根据车载摄像头的画面来判断如何<strong>打方向盘和踩油门</strong>。</p><p><img src="https://s2.ax1x.com/2019/11/05/MprAb9.png" alt="MprAb9.png"></p><p>参考论文：End to End Learning for Self-Driving Cars</p><p><strong>收集数据：</strong></p><p><img src="https://s2.ax1x.com/2019/11/05/MpBqT1.png" alt="MpBqT1.png"></p><p>汽车人为行驶时，其左中右三个摄像头、方向盘转向、油门、转向灯等数据都会通过其 CAN bus 传入处理器。而如今的汽车中基本都带有上述传感器帮忙训练神经网络；当汽车自动驾驶时，汽车根据中间摄像头传入的数据来操控方向盘等设备。</p><p><img src="https://s2.ax1x.com/2019/11/05/Mpye1K.png" alt="Mpye1K.png"></p><p><strong>自动驾驶模拟器：</strong></p><p><a href="https://imgchr.com/i/Mp6LR0" target="_blank" rel="noopener"><img src="https://s2.ax1x.com/2019/11/05/Mp6LR0.md.png" alt="Mp6LR0.md.png"></a></p><p>看起来很好玩的样子，有空看看源码了解下神经网络输出如何操控这些游戏。</p><p><strong>图像处理：</strong></p><ul><li>亮度调整（适应白天、晚上、阴天、晴天等情景）</li><li>归一化</li><li>图像切割（去除地平线以上和车头部分的无关紧要的数据）</li><li>水平翻转（左转右转）</li><li>数据平衡（欠采样、过采样、给样本少的数据更大权重、合成新数据）</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;strong&gt;目标：&lt;/strong&gt;使用端到端的深度学习方法，根据车载摄像头的画面来判断如何&lt;strong&gt;打方向盘和踩油门&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://s2.ax1x.com/2019/11/05/MprAb9.png&quot; al
      
    
    </summary>
    
    
      <category term="计算机视觉" scheme="http://a-kali.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/"/>
    
      <category term="自动驾驶" scheme="http://a-kali.github.io/tags/%E8%87%AA%E5%8A%A8%E9%A9%BE%E9%A9%B6/"/>
    
      <category term="深度学习" scheme="http://a-kali.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="概述" scheme="http://a-kali.github.io/tags/%E6%A6%82%E8%BF%B0/"/>
    
  </entry>
  
  <entry>
    <title>Kaggle days China, Oct 2019</title>
    <link href="http://a-kali.github.io/2019/10/30/Kaggle-days-China-Oct-2019/"/>
    <id>http://a-kali.github.io/2019/10/30/Kaggle-days-China-Oct-2019/</id>
    <published>2019-10-30T12:17:30.000Z</published>
    <updated>2019-11-09T15:52:47.745Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Winning-competitions-with-deep-learning-skills-—-SeuTao"><a href="#Winning-competitions-with-deep-learning-skills-—-SeuTao" class="headerlink" title="Winning competitions with deep learning skills — SeuTao"></a>Winning competitions with deep learning skills — SeuTao</h1><p><img src="https://s2.ax1x.com/2019/11/09/Mnu7rQ.png" alt="Mnu7rQ.png"></p><h2 id="Prepare-for-a-DL-competition"><a href="#Prepare-for-a-DL-competition" class="headerlink" title="Prepare for a DL competition"></a>Prepare for a DL competition</h2><ul><li>GPUs 是基础&amp;必要条件，但不是获得金牌的决定性条件。有着9块金牌的涛神在2019年也才只有2块1080ti而已。</li><li>多读 paper 是获得 idea 的关键，在很多 paper 中能找到相似问题的解决方案。</li><li>多读别人的代码。</li></ul><h2 id="Five-steps-to-Win-a-DL-competition"><a href="#Five-steps-to-Win-a-DL-competition" class="headerlink" title="Five steps to Win a DL competition"></a>Five steps to Win a DL competition</h2><ul><li>Understand the data</li><li>Build a strong baseline</li><li>Find the tricks</li><li>Ensemble</li><li>Pseudo-labels</li></ul><h3 id="Build-a-strong-baseline"><a href="#Build-a-strong-baseline" class="headerlink" title="Build a strong baseline"></a>Build a strong baseline</h3><ul><li>据涛神的看法，建立一个 <strong>strong baseline</strong> 是整个比赛中最重要的一环。一个高质量的 baseline 可以直接让你拿到<strong>银牌</strong>甚至 top15。可以建立一个高质量的 pipeline 并重复利用。</li><li>不要使用花里胡哨的神经网络架构和损失函数。这里大概可以理解为，baseline应使用简单轻量的神经网络，便于快速训练、调参、尝试 tricks。</li><li><strong>优化器</strong>：动量梯度下降或者 lr(3e-4) Adam优化器。优化器的改变对网络性能提升不大。</li><li><strong>学习率</strong>：可以尝试 warm up 和 余弦退火/cyclic lr</li><li>找到对数据合适的<strong>数据增强</strong>。</li><li>可靠的<strong>本地验证</strong>。在kaggle上提交验证相对麻烦而且有次数限制，而有一个可靠的本地验证就能快速地尝试验证各种 tricks。</li><li><strong>BatchNorm</strong>问题，基线很难高分的一个原因，涉及到神经网络细节。这里没看懂先挂张图：<img src="https://s2.ax1x.com/2019/11/09/Mn3W5j.png" alt="Mn3W5j.png"></li></ul><h3 id="Find-the-tricks"><a href="#Find-the-tricks" class="headerlink" title="Find the tricks"></a>Find the tricks</h3><ul><li>任务型 trick：图片分类trick、目标检测trick等。这些trick需要大量相关论文的积累。</li><li>数据型 trick：这需要你对数据敏锐的分析。数据相关的trick往往是制胜的关键。</li></ul><h3 id="Ensemble"><a href="#Ensemble" class="headerlink" title="Ensemble"></a>Ensemble</h3><p>融合技巧很重要，比如stacking、blending等</p><p><img src="https://s2.ax1x.com/2019/11/09/Mn82y6.png" alt="Mn82y6.png"></p><h3 id="Pseudo-labels"><a href="#Pseudo-labels" class="headerlink" title="Pseudo labels"></a>Pseudo labels</h3><ul><li>易于使用而且几乎在所有的深度学习竞赛中都奏效。</li><li>可以通过测试集或者外部数据来生成伪标签。</li><li>在比赛的最后stage使用——Overfit the LB then create pseudo labels（这个有点难理解）</li><li>注意不要 overfit 伪标签</li></ul><h2 id="Others"><a href="#Others" class="headerlink" title="Others"></a>Others</h2><ul><li>实验效率很重要，总结每一次实验经验，不管是成功还是失败。</li><li>在 kernel only 这种限制测试时间的比赛上，可以使用模型蒸馏、加速。</li><li>找到任务实质相关的论文。</li><li>熟读计算机视觉各个分支的论文，很可能会在之前读过的相关的论文上找到thick。</li></ul><h1 id="Tricks-of-image-classification-—-Jun-Lan"><a href="#Tricks-of-image-classification-—-Jun-Lan" class="headerlink" title="Tricks of image classification — Jun Lan"></a>Tricks of image classification — Jun Lan</h1><ul><li><p>图像分类大致可以分为两种：多类别分类（一个样本属于一个类别） vs 多标签分类（一个样本属于多个类别）</p></li><li><p>找到之前相似的比赛，观察高分solution</p></li><li><p>将数据增强后的图片可视化查看效果，根据任务选择增强方法</p></li><li><p>医疗影像预训练数据：MedicalNet。目前没开源2d数据</p></li><li><p>cycle learning rate：减少调参，更快收敛</p></li><li><p>多类别：交叉熵损失；多标签：二值交叉熵损失</p></li><li><p>mixup：一种数据增强的方法。将两张图片及其标签按一定比例进行融合</p></li><li><p>apex：基于pytorch的低精度运算（32位或16位）。减少显存占用，增加训练速度。pure float可能会导致精度损失和溢出。解决方案：混合精度训练。（设成O1就行了）</p></li><li><p>梯度累加（batch accumulation）：增大batch的方法，（多累积几步再更新梯度？）</p></li><li><p>伪标签：数据少或有大量额外数据且没有标签的情况下</p><ol><li>训练集训练模型</li><li>测试数据</li><li>将置信度较高的数据放入训练集（0.95、0，98）</li><li>再训练</li></ol></li><li><p>数据蒸馏（knowledge distillation）：使用小模型（student）来获取大模型（teacher）中的核心知识</p><ol><li>将数据集分为k折</li><li>k折交叉验证训练teacher model</li><li>预测out-of-fold的标签</li><li>在out-of-fold训练student model</li></ol></li></ul><hr><h1 id="半年5战5金：Kaggle史上最快GrandMaster是如何炼成的"><a href="#半年5战5金：Kaggle史上最快GrandMaster是如何炼成的" class="headerlink" title="半年5战5金：Kaggle史上最快GrandMaster是如何炼成的"></a>半年5战5金：Kaggle史上最快GrandMaster是如何炼成的</h1><p>下面内容跟 kaggle days 没什么关系，是一些很有用的 tricks。整理自网络，有删改，原文地址：<a href="https://zhuanlan.zhihu.com/p/89476481" target="_blank" rel="noopener">Kaggle你问我答【1】——SeuTao</a></p><p>这是 Kaggle 你问我答 (AMA) 的第一期活动，本期请到的嘉宾是 SueTao，他研究生毕业于东南大学，目前是腾讯的一名算法工程师。SueTao 擅长计算机视觉（Computer Vision），半年 5 战 5 金，也许是史上最快的 GrandMaster。截至目前共斩获 9 金 3 银，kaggle 最高排名全球第 10。</p><p>以下是本期活动的问答集锦：</p><p><strong>Q1：如何搭建kaggle data pipeline?</strong></p><p>A1：我目前的比赛还是集中在cv，也做过语音，还有前段时候的PMP，都是DL相关的竞赛。 数据的pipeline其实是可以积累并且优化的。我觉得可以参考一些前人的代码，尤其是蛙神的code。 可以在蛙神的code基础上，慢慢优化跟积累出自己的数据pipeline。 DL数据pipeline中还有个很重要的部分就是数据增强，这块针对不同比赛可能有不同的做法。</p><p><strong>Q2：自己曾经努力拿过银牌，但是觉得金牌好难，特别是solo的情况，请问金牌和银牌的差距在哪里，如何突破？</strong></p><p>A2：我还是从我参与比较多的cv竞赛角度出发哈。首先，如果你是cv新人，在kaggle竞赛上觉得拿金牌很困难，其实是很正常的。目前cv赛基本被cv高手霸榜了。 如果你是已经比较熟悉cv各个方向的模型，那你可能需要一个竞赛好手来给你带路。毕竟竞赛还是有很多套路的。 如果是新人，我的建议是坚持，通过几个cv竞赛来积累对这个方向的认识。了解不同模型不同任务。 我觉得可以参考padue，大家如果看他竞赛的成绩的话，开始他也只是银牌水平，但是从前段时间的protein开始，他现在在cv赛的水平基本就是solo gold了。 deep learning实践的积累还是很重要，一口吃不成胖子。</p><p><strong>Q4：新出的3d object比赛是不是一种趋势，请问涛神对computer vision的发展有什么观察和展望？</strong></p><p>A4：cv的话3d绝对是一个趋势，包括学术界和工业界； sensor的成本越来越低，性能也越来越好；就人脸识别来说，用3d来说安全性和可靠性就更高了。 其实我目前也算是退坑computer vision了，也谈不上对cv有深入的认识。大家从kaggle上cv赛的数量上可以发现，cv对企业的价值还是非常高的。前景是非常好，例如工业检测之类的。</p><p><strong>Q5：怎么判断该改进网络结构还是调学习率？</strong></p><p>A5：学习率和学习策略可能是搭建baseline里面最重要的部分。这块需要在比赛的前期优化到最好，建议使用简单的网络作为baseline，然后仔细优化学习策略。没有提升空间之后再考虑别的方向的优化。</p><p><strong>Q6：是否应该从分类错误的sample中提取灵感继续改进？如果是该怎么做？</strong></p><p>A6：cv最好的一点是可以看图，非常直观。举个例子：比如之前的鲸鱼竞赛，baseline模型的bad case大多是一些姿态较大，分辨率较差的图像。那么我们就可以考虑增加对应的数据增强。效果也很显著。 再举个反面例子：刚刚结束的nips的cellsignal竞赛，是细胞的荧光成像。整个比赛我完全没有看bad case。 因为没有domain知识，图像非自然，很难观察。 但是也不妨碍比赛能拿名次，只看log来调参。</p><p><strong>Q7：请评价cv 各项任务中 state of the art 模型的实用性，有何推荐？</strong></p><p>A7：“试过才有发言权”，这是我做kaggle之后的一个经验。没做kaggle之前，我工作集中在轻量级的模型，对于sota的大模型几乎没有尝试。所以我在竞赛中会尽量去尝试各种sota，最终会有很多有意思的结论。 会发现kaiming的resnet为什么强，unet为什么就是好用。 有些很fancy的模型真的只是过拟合特定的数据集。 我也没有尝试过所有的sota，但是我觉得paper里的内容看看就好，去伪存真，实践出真知。</p><p><strong>Q8：作为一个新人从头开始拿到金牌的最佳策略？比如选择比赛的类型？</strong></p><p>A8：哈哈 因为我cv一把梭，只能给到cv的经验。如果新人想拿金牌的话，最好就是找一个蛙神all in的比赛，step by step follow蛙神！只要比所有人都肝，有足够计算资源，对齐discussion report出来的模型精度，solo gold就有希望！ 其实我第一个比赛TGS就是这么做的。</p><p><strong>Q9：在kaggle学到的东西是否有应用到别的地方？能否举例说明？</strong></p><p>A9：非常多。举个例子：模型集成（ensemble）。可能有些人说模型集成在实际工作中用不了；工作中的场景有效率的要求；在计算资源受限的情况下，3个小模型集成的效果可能远好于1个大模型的效果。 我之前的参与的人脸项目，其实就用了这样的策略，很好用。但是如何去集成，怎么增大模型间diversity，这些技巧大家可以从kaggle上学习。</p><p><strong>Q10：回头看自己的经历，对刚入坑的新人，有什么想提醒的经验和教训？</strong></p><p>A10：教训到没有，做比赛一年感触还是蛮多的，投入越多收获越大吧。希望大家坚持。 真的只有投入去做了，才会有收获。</p><p><strong>Q11：CV比赛假如遇到瓶颈会往哪些方向尝试？</strong></p><p>A11：数据层面绝对是提分收益最大的方向；还是要多看数据，多分析bad case；不看数据就调网络结构是不可取的。 数据层面有些线索之后，可以指导你对模型结构本身做一些改进。另外最重要的：多看paper，paper是idea的来源。</p><p><strong>Q12：一般会用哪种方式平时积累知识？</strong></p><p>A12：过去很长一段时间内，我积累的方式还是来自比赛 通过一个比赛，我可以验证很多paper的方法，实践在工作中无法使用的模型；帮助我深入理解一些数据上和模型上的问题 感觉从我个人而言，比赛和工作相辅相成，给我工作提供了非常好的积累和储备。</p><p><strong>Q13：想知道打比赛的节奏是什么， 比如比赛结束前一个月， 一周， 几天主要干什么？</strong></p><p>A13：基本上最后一周前，最终方案就要定了。考虑最终的集成。</p><p><strong>Q14：有复现比赛top solution的习惯吗？ 有的话是一种怎样的方式呢？</strong></p><p>A14：会看，但是很少会跑。因为一直忙着做新的比赛。其实应该仔细去研究下的。</p><p><strong>Q15：分类比赛中的最后的sub的阈值应该根据什么来选取呢，有什么选取技巧呢？</strong></p><p>A15：我只能说可靠的local validation是最重要的，所有涉及模型选择，调参；其实都需要一个依据，local validation就是这个依据。这样问题就变成如何建立可靠的local validation了。</p><p><strong>Q16：分类比赛中最后的两个sub一般会怎么样选择呢，不同的方案的模型，还是其他？</strong></p><p>A16：这个问题比较好。前期几个比赛的sub一般都是我选的，有幸抽中过金牌。我个人的建议是，差异一定要大，一个激进一个保守。 就dl比赛来说，集成最稳的是weight ave，简单有效，一般来说我会选一个这个； 然后一些存在过拟合风险的方法，但是lb和cv都很可观的方案，我也会选择一个。</p><p><strong>Q17：请问经常看到各位大佬同时参加好几个比赛，还能拿到很好的名次，这是怎么做到的？</strong></p><p>A17：其实kaggle上的top CVer都会有自己积累下来的pipeline。竞赛任务无非是这几种，迅速搭建一个可靠的baseline，对top选手很容易； 看似在做多个竞赛，可能跑的是一套代码。真的要最终比赛冲刺了，会有针对性地去理解数据和优化。</p><p><strong>Q18：图像比赛有什么通用的技巧吗？厉害的选手一次提交就可以进到绿圈，细节处理上有什么独到之处？</strong></p><p>A18：DL调参的细节太多了，需要很长时间的积累。同样的数据+网络，不同人的训练结果可能相差巨大。这是top CVer的核心竞争力 通用技巧的话，paper上带着“bag of tricks”的都需要仔细阅读 bag of tricks for image classification， bag of tricks for object detection。</p><p><strong>Q19：想问下之前说没法做bad case的时候通过log调参是怎么调的， 另外一般bad case怎么样比较好的分析？</strong></p><p>A19：其实很简单: bias-variance trade off，只看log的话，拿捏好这个。 比如nips cellsignal比赛，baseline效果是，training拟合的非常好，test却非常差。其实是一种train test consistency。从1）数据层面；2）网络层面，去分析可能的情况。1）数据层面:数据分布的问题，2）网络层面：batchnorm。针对性地去做实验，确定问题所在，继续观察bias-variance，要得出可靠结论，再进行下一步。</p><p><strong>Q20：我这边自己写了个基于 pytorch 的轮子, 每次基本上能跟上 public kernel 的步伐, 但是就是很难超越. 我估计是训练资源和调参问题. 那么: 调参大部分用已经训练好的模型来调, 还是每次改变参数都重新训练个几天, 哪种方法对 top CVer 比较实际?</strong></p><p>A20：建议解决计算资源问题，保证快速学习，训练资源很重要，其实最优的实验周期我个人感觉在半天。 半天能出一个实验结果最好，中间可以干别的。 结果出得太快也不好，要及时总结和记录实验。</p><p><strong>Q21：之前看到有新闻说模型会用贴纸识别面包机，用肤色识别罪犯的这种过拟合的情况，还有aptos存在模型通过图片尺寸leak发现lable，有没有什么好办法避免这种情况？</strong></p><p>A21：我感觉过拟合问题其实比大家想象的更严重，之前做活体检测基本就是这么个情况，难以范化。 目前的DL还比较‘蠢’，要说办法的话，加数据算不算？</p><p><strong>Q22：问一个技术性问题，碰到一些受阈值影响的metrics时，训练的时候取最好的模型应该依据val-metrics还是val-loss呢？valid的时候如果遍历阈值，可能会极大的影响效率。不同模型/不同epoch，用不同阈值取得的metrics比较，会不会‘不公平’？</strong></p><p>A22：其实我也没有很好的答案。是我的话，最优的val-metrics和val-loss模型我都会存。其实最担心的是优化的loss和metrics不一致。</p><p><strong>Q23：还想问下对warmRestart这类的循环式的scheduler有什么看法？和传统的ReduceLROnPlateau相比有什么优劣？</strong></p><p>A23：最近发现这个真的很好用。如果用step LR的话，很可能下降的位置就不够好。循环的学习策略，我的感受是既不会有太多过拟合，也不需要很仔细调参，基本会有个不错的结果。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Winning-competitions-with-deep-learning-skills-—-SeuTao&quot;&gt;&lt;a href=&quot;#Winning-competitions-with-deep-learning-skills-—-SeuTao&quot; class=&quot;h
      
    
    </summary>
    
    
      <category term="计算机视觉" scheme="http://a-kali.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/"/>
    
      <category term="深度学习" scheme="http://a-kali.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="kaggle days" scheme="http://a-kali.github.io/tags/kaggle-days/"/>
    
      <category term="kaggle" scheme="http://a-kali.github.io/tags/kaggle/"/>
    
      <category term="图像分类" scheme="http://a-kali.github.io/tags/%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB/"/>
    
      <category term="比赛技巧" scheme="http://a-kali.github.io/tags/%E6%AF%94%E8%B5%9B%E6%8A%80%E5%B7%A7/"/>
    
      <category term="优化器" scheme="http://a-kali.github.io/tags/%E4%BC%98%E5%8C%96%E5%99%A8/"/>
    
      <category term="学习率" scheme="http://a-kali.github.io/tags/%E5%AD%A6%E4%B9%A0%E7%8E%87/"/>
    
      <category term="数据蒸馏" scheme="http://a-kali.github.io/tags/%E6%95%B0%E6%8D%AE%E8%92%B8%E9%A6%8F/"/>
    
      <category term="伪标签" scheme="http://a-kali.github.io/tags/%E4%BC%AA%E6%A0%87%E7%AD%BE/"/>
    
  </entry>
  
  <entry>
    <title>FCN 论文解读</title>
    <link href="http://a-kali.github.io/2019/10/26/FCN%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB/"/>
    <id>http://a-kali.github.io/2019/10/26/FCN论文解读/</id>
    <published>2019-10-26T02:06:38.000Z</published>
    <updated>2019-11-14T18:15:21.034Z</updated>
    
    <content type="html"><![CDATA[<p>论文地址：<a href="https://arxiv.org/abs/1411.4038" target="_blank" rel="noopener">Fully Convolutional Networks for Semantic Segmentation</a></p><h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><p>原始的 CNN 在图像的分类和定位任务中都获得了不错的成绩，但在分割任务中表现不佳。本文提出了一种<strong>全卷积网络(Fully Convolution Network, FCN)</strong>，通过进行像素级的预测(pixelwise prediction)来实现<strong>语义分割(semantic segmentaion)</strong>。</p><p><a href="https://imgchr.com/i/MUdneI" target="_blank" rel="noopener"><img src="https://s2.ax1x.com/2019/11/15/MUdneI.md.png" alt="MUdneI.md.png"></a></p><p>实现全卷积网络主要基于三种技术：</p><ul><li>全卷积化（Fully Convolutional）</li><li>反卷积（Deconvolution）</li><li>跃层结构（Skip Layer）</li></ul><h1 id="全卷积化"><a href="#全卷积化" class="headerlink" title="全卷积化"></a>全卷积化</h1><p><img src="https://s2.ax1x.com/2019/11/15/MUB4hV.png" alt="MUB4hV.png"></p><p>简单来说就是把传统CNN最后的全连接层换成了卷积层。全卷积在多篇目标检测的论文中都有提到，其能提取出样本的特征图，样本目标区域对应特征图的感兴趣区域所在位置（如上图中的猫对应heatmap中的彩色像素）。</p><h1 id="上采样（Upsampling）"><a href="#上采样（Upsampling）" class="headerlink" title="上采样（Upsampling）"></a>上采样（Upsampling）</h1><p><img src="https://s2.ax1x.com/2019/11/15/MUBJ6e.png" alt="MUBJ6e.png"></p><p>图像(图a)在经过卷积、池化等一系列处理后，得到的特征图(图b)分辨率远小于原图像。这样一来特征图中的像素无法与原图中一一对应，无法对每个像素进行预测。于是需要对特征图进行<strong>上采样</strong>以提高特征图的分辨率。文中对比了三种上采样的方法：</p><h2 id="Shift-and-stitch"><a href="#Shift-and-stitch" class="headerlink" title="Shift-and-stitch"></a>Shift-and-stitch</h2><p>关于该方法可以参考博客：<a href="https://www.jianshu.com/p/e534e2be5d7d" target="_blank" rel="noopener">关于FCN 论文中的 Shift-and-stitch 的详尽解释</a>。作者认为该方法“不能感受到更精细的信息”。</p><h2 id="Patchwise-training"><a href="#Patchwise-training" class="headerlink" title="Patchwise training"></a>Patchwise training</h2><p>与其字面意思一样，patchwise是介于pixelwise和imagewise之间的级别。对每一个感兴趣的像素，以它为中心取一个patch，然后输入网络，输出则为该像素的标签，训练时就将一个个patch组成一个batch作为网络输入。这种方法可能会因为patch的太大或太小造成精度的损失。</p><h2 id="Deconvolution"><a href="#Deconvolution" class="headerlink" title="Deconvolution"></a>Deconvolution</h2><p>反卷积文章作者最终采用的方法，下面是两种反卷积的示例，图解起来十分直观：</p><p><img src="https://s2.ax1x.com/2019/11/15/MUBwkt.gif" alt="MUBwkt.gif"></p><p><img src="https://s2.ax1x.com/2019/11/15/MUBBff.gif" alt="MUBBff.gif"></p><p>下面是另一种解释，这样一看好像确实是把卷积的操作反过来了：</p><p><img src="https://s2.ax1x.com/2019/11/15/MUB20s.png" alt="MUB20s.png"></p><h1 id="跃层结构-Skip-Layer"><a href="#跃层结构-Skip-Layer" class="headerlink" title="跃层结构(Skip Layer)"></a>跃层结构(Skip Layer)</h1><p>FCN 通过卷积和反卷积我们基本能定位到目标区域，但是，我们会发现模型前期是通过卷积、池化、非线性激活函数等作用输出了特征权重图像，我们经过反卷积等操作输出的图像实际是很粗糙的，毕竟丢了很多细节。因此我们需要找到一种方式填补丢失的细节数据，所以就有了<strong>跃层结构</strong>。</p><p>跃层结构将浅层的位置信息和深层的语义信息结合起来，得到更佳鲁棒的结果，其过程如图：</p><p><img src="https://s2.ax1x.com/2019/11/15/MUBz9K.png" alt="MUBz9K.png"></p><h1 id="网络结构"><a href="#网络结构" class="headerlink" title="网络结构"></a>网络结构</h1><p><img src="https://s2.ax1x.com/2019/11/15/MUDAAI.png" alt="MUDAAI.png"></p><h1 id="FCN-的缺点"><a href="#FCN-的缺点" class="headerlink" title="FCN 的缺点"></a>FCN 的缺点</h1><ol><li>分割的结果不够精细。图像过于模糊或平滑，没有分割出目标图像的细节</li><li>因为模型是基于CNN改进而来，即便是用卷积替换了全连接，但是依然是独立像素进行分类，没有充分考虑像素与像素之间的关系</li></ol><h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><p>[1]<a href="https://blog.csdn.net/fate_fjh/article/details/52882134" target="_blank" rel="noopener">卷积神经网络CNN（1）——图像卷积与反卷积（后卷积，转置卷积）</a></p><p>[2]<a href="https://blog.csdn.net/qq_31347869/article/details/89429211" target="_blank" rel="noopener">【论文笔记】FCN</a></p><p>[3]<a href="http://www.sohu.com/a/270896638_633698" target="_blank" rel="noopener">10分钟看懂全卷积神经网络（ FCN ）：语义分割深度模型先驱 </a></p><p>[4]<a href="https://blog.csdn.net/qq_36269513/article/details/80420363" target="_blank" rel="noopener">FCN的学习及理解（Fully Convolutional Networks for Semantic Segmentation）</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;论文地址：&lt;a href=&quot;https://arxiv.org/abs/1411.4038&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Fully Convolutional Networks for Semantic Segmentation&lt;/a&gt;&lt;
      
    
    </summary>
    
    
      <category term="论文解读" scheme="http://a-kali.github.io/tags/%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB/"/>
    
      <category term="计算机视觉" scheme="http://a-kali.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/"/>
    
      <category term="语义分割" scheme="http://a-kali.github.io/tags/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2/"/>
    
      <category term="CNN" scheme="http://a-kali.github.io/tags/CNN/"/>
    
      <category term="FCN" scheme="http://a-kali.github.io/tags/FCN/"/>
    
      <category term="反卷积" scheme="http://a-kali.github.io/tags/%E5%8F%8D%E5%8D%B7%E7%A7%AF/"/>
    
  </entry>
  
  <entry>
    <title>RSNA Intracranial Hemorrhage Detection 比赛记录</title>
    <link href="http://a-kali.github.io/2019/10/16/RSNA-Intracranial-Hemorrhage-Detection-%E6%AF%94%E8%B5%9B%E8%AE%B0%E5%BD%95/"/>
    <id>http://a-kali.github.io/2019/10/16/RSNA-Intracranial-Hemorrhage-Detection-比赛记录/</id>
    <published>2019-10-16T07:24:54.000Z</published>
    <updated>2019-10-30T12:13:00.459Z</updated>
    
    <content type="html"><![CDATA[<div id="hbe-security">  <div class="hbe-input-container">  <input type="password" class="hbe-form-control" id="pass" placeholder="Please enter the password to read the blog." />    <label for="pass">Please enter the password to read the blog.</label>    <div class="bottom-line"></div>  </div></div><div id="decryptionError" style="display: none;">Incorrect Password!</div><div id="noContentError" style="display: none;">No content to display!</div><div id="encrypt-blog" style="display:none">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</div><script src="/lib/crypto-js.js"></script><script src="/lib/blog-encrypt.js"></script><link href="/css/blog-encrypt.css" rel="stylesheet" type="text/css">]]></content>
    
    <summary type="html">
    
      The article has been encrypted, please enter your password to view.&lt;br&gt;
    
    </summary>
    
    
      <category term="计算机视觉" scheme="http://a-kali.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/"/>
    
      <category term="Kaggle" scheme="http://a-kali.github.io/tags/Kaggle/"/>
    
      <category term="深度学习" scheme="http://a-kali.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="图片分类" scheme="http://a-kali.github.io/tags/%E5%9B%BE%E7%89%87%E5%88%86%E7%B1%BB/"/>
    
  </entry>
  
  <entry>
    <title>R-CNN, Fast R-CNN, Faster R-CNN, Mask R-CNN 系列论文解读</title>
    <link href="http://a-kali.github.io/2019/10/10/R-CNN-Fast-R-CNN-Faster-R-CNN-Mask-R-CNN-%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB/"/>
    <id>http://a-kali.github.io/2019/10/10/R-CNN-Fast-R-CNN-Faster-R-CNN-Mask-R-CNN-论文解读/</id>
    <published>2019-10-10T09:21:36.000Z</published>
    <updated>2019-11-05T09:43:19.831Z</updated>
    
    <content type="html"><![CDATA[<h1 id="R-CNN"><a href="#R-CNN" class="headerlink" title="R-CNN"></a>R-CNN</h1><p>论文地址：<a href="https://arxiv.org/pdf/1311.2524.pdf" target="_blank" rel="noopener">Rich feature hierarchies for accurate object detection and semantic segmentation</a></p><p>发布时间：2014.10.22</p><h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>伴随着AlexNet的横空出世，卷积神经网络开始进入人们的视线，R-CNN便是将卷积神经网络运用于目标检测和语义分割的一个成功典范，其在 VOC 2012 将最佳mAP提高了30%。其成绩对卷积神经网络在目标检测的运用产生了深远的影响。</p><p>但在这之前，需要解决两个主要的问题：</p><ol><li>与图片分类不同，目标检测需要在图片上定位目标的位置。那么如何利用深度的神经网络去做目标的定位？</li><li>如何在一个小规模的数据集上训练能力强劲的网络模型？</li></ol><p>R-CNN全称为Regions with CNN features，其名字来源于其主要使用的两项技术：卷积神经网络（CNN）和<strong>区域推荐</strong>（Region Proposals），而区域推荐正是第一个问题的解决方法。当时已有许多现成的区域推荐算法，本文作者使用的是<strong>选择性搜索(selective search)算法</strong>。</p><h2 id="选择性搜索"><a href="#选择性搜索" class="headerlink" title="选择性搜索"></a>选择性搜索</h2><p><img src="https://s2.ax1x.com/2019/10/25/KwZVHS.png" alt="KwZVHS.png"></p><p>大概就是根据临近颜色的相似度将左边的原图变成像右边由色块组成的图片，然后根据色块选出候选框。这样可以减少对一些不必要的区域进行卷积运算，比如左图左上角那个框。该算法被后续几代网络沿用，直到 Faster R-CNN 使用神经网络进行区域推荐。</p><h2 id="整体架构"><a href="#整体架构" class="headerlink" title="整体架构"></a>整体架构</h2><p>R-CNN整体过程如下：</p><ol><li>给定一张输入图片，使用selective search从图片中提取 2000 个类别独立的候选区域。</li><li>将每个候选区域缩放到227×227，输入到 CNN中抽取一个固定长度的特征向量。</li><li>使用<strong>各个类别对应的SVM对特征向量进行二分类</strong>，判断该候选区域是否包含该类别，之后对每个类别的窗口进行极大值抑制。</li></ol><p><img src="https://img-blog.csdnimg.cn/20181210155342586.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2JyaWJsdWU=,size_16,color_FFFFFF,t_70" alt></p><p>对于第二个问题，作者给出的解决方法是：在大型图片分类数据集ILSVRC上预训练卷积神经网络，并微调（fine-tuning）到小型目标检测数据集PASCAL上，这使得mAP上升了8个百分点。</p><p>R-CNN高效的原因：</p><ol><li>所有类别共享CNN参数</li><li>特征维度相对较小</li></ol><h1 id="SPP-Net"><a href="#SPP-Net" class="headerlink" title="SPP-Net"></a>SPP-Net</h1><p>论文地址：<a href="https://arxiv.org/abs/1406.4729" target="_blank" rel="noopener">Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition</a></p><p>发布时间：2015.4.23</p><h2 id="背景-1"><a href="#背景-1" class="headerlink" title="背景"></a>背景</h2><p>由于 CNN 需要固定大小的输入，在将图片输入到神经网络之前需要对图片进行缩放(warp)或裁剪(crop)。缩放会造成图片几何失真，而裁剪则可能损失部分目标物像素，这将会对图片识别精确度有所影响。</p><p><img src="https://s2.ax1x.com/2019/10/22/K8nKrd.png" alt="K8nKrd.png"></p><p>CNN 只能接收固定尺寸图片的原因是其全连接层节点数目固定，而其卷积层是可以接收不同尺寸的图片的。于是作者设计了用于神经网络中的 <strong>SPP</strong> (spatial pytamid pooling, 空间金字塔池化) 模块，位于卷积层和全连接层之间，用于<strong>接收任意尺寸的图片、提取其特征并产生固定大小的输出</strong>。而且实验表明，训练时使用不同尺寸的输入，可以提高测试精度。</p><h2 id="空间金字塔池化层"><a href="#空间金字塔池化层" class="headerlink" title="空间金字塔池化层"></a>空间金字塔池化层</h2><p><img src="https://s2.ax1x.com/2019/10/22/KGQ98P.png" alt="KGQ98P.png"></p><p>作者将 CNN 中的最后一个池化层用 SPP 替代。如图所示，<strong>SPP 将最后一层卷积层输出的特征图分割成不同尺寸的网格，分别为4×4、2×2、1×1，然后对每个小格进行max pooling，再将池化后的结果连接起来，就能得到（16+4+1）× 256 的固定长度的输出</strong>（这里的256为256个channel）。</p><h2 id="SPP-在目标检测中的应用"><a href="#SPP-在目标检测中的应用" class="headerlink" title="SPP 在目标检测中的应用"></a>SPP 在目标检测中的应用</h2><p>前面提到，R-CNN 在图像中选出2000个候选窗口，并将每个窗口缩放后输入到神经网络中，这样对一张图片反复使用深度卷积网络十分耗时。测试时，特征提取是其主要的时间瓶颈。</p><p>论文中提到，特征图的ROI与原图中的目标物的位置存在一定的映射关系，如下图：</p><p><img src="https://s2.ax1x.com/2019/10/22/KG6IIA.png" alt="KG6IIA.png"></p><p>于是<strong>对于一张图片，只需要提取一次特征，然后将特征图的2000个候选区域输入 SPP 模块就能得到固定长度的表示。由于只需要进行一次卷积操作，节省了大量候选区域通过神经网络的时间。</strong></p><h1 id="Fast-R-CNN"><a href="#Fast-R-CNN" class="headerlink" title="Fast R-CNN"></a>Fast R-CNN</h1><p>论文地址：<a href="https://arxiv.org/abs/1504.08083" target="_blank" rel="noopener">Fast R-CNN</a></p><p>发布时间：2015.9.27</p><h2 id="背景-2"><a href="#背景-2" class="headerlink" title="背景"></a>背景</h2><p>SPPnet 虽然对R-CNN进行了一些改进，但仍然存在许多问题：</p><ul><li>需要大量产生候选框</li><li>对目标的定位只能靠候选框来粗略定位</li><li>多阶段pipeline，特征提取、模型训练、SVM分类器训练、边框回归要分别进行</li><li>特征图要存在本地磁盘，影响速度</li></ul><p>于是 Fast R-CNN 改进了在目标检测任务中的性能，其优势如下：</p><ul><li>相比 R-CNN、SPPnet 有着更高的 mAP</li><li>单阶段(single-stage)训练，使用多任务损失(multi-task loss)</li><li>训练可以更新网络每一层的参数</li><li>无需使用磁盘缓存特征</li></ul><h2 id="架构细节和模型训练"><a href="#架构细节和模型训练" class="headerlink" title="架构细节和模型训练"></a>架构细节和模型训练</h2><p><img src="https://s2.ax1x.com/2019/10/23/KtoCi6.png" alt="KtoCi6.png"></p><p>从上图直观上来看，Fast R-CNN 与 SPPnet 的结构有两个区别：</p><ol><li>SPP模块被换成了RoI池化层</li><li>网络末端有两个输出，分别用于图像分类和边框回归。分类器被换成了softmax。使用softmax的好处在于不用单独训练一个SVM分类器；缺点在于对于一个候选框最多只能分出一类物体，即使一个候选框包含了多个类别的目标（大概）。</li></ol><p>另外值得一提的是，Fast R-CNN 采用的是固定大小的输入，而不像SPPnet使用任意大小的输入。</p><h3 id="RoI-池化层"><a href="#RoI-池化层" class="headerlink" title="RoI 池化层"></a>RoI 池化层</h3><p>RoI 池化层实质上就是单层的 SPP 模块。其将一个候选窗口划分为 H×W 的网格，对每个网格内进行最大池化，最后输出一个长度为 H×W 的特征。超参数 H 和 W 视具体网络结构而定。</p><h3 id="多任务损失"><a href="#多任务损失" class="headerlink" title="多任务损失"></a>多任务损失</h3><p>多任务损失由分类任务损失和边框回归任务损失线性组合而成：</p><script type="math/tex; mode=display">L=L_{cls}(p,u)+\lambda [u\geq 1]L_{loc}(t^u,v)\\</script><p>其中：</p><script type="math/tex; mode=display">L_{cls}(p,u)=-\log p_u\\L_{loc}(t^u,v)=\sum smooth_{L_1}(t^u_i-v_i)</script><h3 id="Mini-batch-sampling"><a href="#Mini-batch-sampling" class="headerlink" title="Mini-batch sampling"></a>Mini-batch sampling</h3><p>（其实这一段我没看太懂，以下仅作参考）</p><p>在调优(fine tuning)训练时，每个mini-batch中首先加入 N 张完整图片，从 N 张图片中选出一共 R 个 IoU&gt;0.5 的候选区域，然后将这 R 个候选区域作为训练样本放入网络训练。</p><h1 id="Faster-R-CNN"><a href="#Faster-R-CNN" class="headerlink" title="Faster R-CNN"></a>Faster R-CNN</h1><p>论文地址：<a href="https://arxiv.org/abs/1506.01497" target="_blank" rel="noopener">Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks</a></p><p>发布时间：2016.1.6</p><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>性能优越的目标检测网络都依赖区域推荐(region proposal)算法来假定目标位置，比如R-CNN中的选择搜索(search selective)算法，而这些区域推荐的计算消耗正是整个网络性能的瓶颈。本文作者引入了<strong>区域推荐网络(Region Proposal Network, RPN)</strong>，尝试使用神经网络来进行区域提取。并将 RPN 和 Fast R-CNN 融合在一起，共享卷积特征，成为一个端到端的神经网络。</p><h2 id="架构概览"><a href="#架构概览" class="headerlink" title="架构概览"></a>架构概览</h2><p><img src="https://s2.ax1x.com/2019/10/25/KdqldS.png" alt="KdqldS.png"></p><p>Fast R-CNN 大致结构如图。可以看出，网络由四步组成：</p><ol><li>输入的图片经过卷积层输出一张特征图</li><li>将特征图输入 RPN，得到候选区域</li><li>将特征图上候选区域的对应位置输入到 RoI 池化层</li><li>输入到分类器得出分类结果</li></ol><p>那么 RPN 具体是怎样的呢？</p><h2 id="RPN"><a href="#RPN" class="headerlink" title="RPN"></a>RPN</h2><p><img src="https://s2.ax1x.com/2019/10/25/KdIwZQ.png" alt="KdIwZQ.png"></p><p>从上图中Faster R-CNN更具体的结构，包括左下方的RPN模块。RPN具体流程如下：</p><ol><li><p>使用<strong>滑动窗口(slide window)</strong>遍历整个特征图(feature map)，遍历过程中以每个window中心产生9个预设<strong>锚框(anchor)</strong>，9个锚框分别对应3种尺寸和3种长宽比。</p><p><img src="https://s2.ax1x.com/2019/10/25/KwJZQS.png" alt="KwJZQS.png"></p></li><li><p>将锚框分别输入到<strong>线性分类层(cls layer)</strong>和<strong>边框回归层(reg layer)</strong>中。分类层通过softmax对锚框进行二分类，初步判断该锚框是前景还是背景（锚框里是否包含目标物）；回归层通过边框回归进一步修正锚框，使锚框定位更精确。</p><p><img src="https://s2.ax1x.com/2019/10/26/K0RaZ9.png" alt="K0RaZ9.png"></p></li><li><p>将筛选、修正后的锚框映射到特征图上，输入到ROI池化层。后续操作和Fast R-CNN一样。</p></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;R-CNN&quot;&gt;&lt;a href=&quot;#R-CNN&quot; class=&quot;headerlink&quot; title=&quot;R-CNN&quot;&gt;&lt;/a&gt;R-CNN&lt;/h1&gt;&lt;p&gt;论文地址：&lt;a href=&quot;https://arxiv.org/pdf/1311.2524.pdf&quot; target=
      
    
    </summary>
    
      <category term="计算机视觉" scheme="http://a-kali.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/"/>
    
    
      <category term="论文解读" scheme="http://a-kali.github.io/tags/%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB/"/>
    
      <category term="计算机视觉" scheme="http://a-kali.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/"/>
    
      <category term="语义分割" scheme="http://a-kali.github.io/tags/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2/"/>
    
      <category term="深度学习" scheme="http://a-kali.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="R-CNN" scheme="http://a-kali.github.io/tags/R-CNN/"/>
    
      <category term="目标检测" scheme="http://a-kali.github.io/tags/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/"/>
    
  </entry>
  
  <entry>
    <title>计算机视觉算法岗面试归纳</title>
    <link href="http://a-kali.github.io/2019/10/05/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E7%AE%97%E6%B3%95%E5%B2%97%E9%9D%A2%E8%AF%95%E5%BD%92%E7%BA%B3/"/>
    <id>http://a-kali.github.io/2019/10/05/计算机视觉算法岗面试归纳/</id>
    <published>2019-10-05T01:32:59.000Z</published>
    <updated>2019-10-28T14:12:55.835Z</updated>
    
    <content type="html"><![CDATA[<h1 id="ML"><a href="#ML" class="headerlink" title="ML"></a>ML</h1><ul><li>介绍一下调参的经验</li><li>Softmax的公式和伪代码</li><li>分类常见的指标有什么，如何理解AUC？</li><li>介绍决策树、RF、XGBoost、GBDT和 LightGBM</li><li>XGboost的loss函数的推导（mse以及非mse形式），以及求解推导。</li><li>使用O(N)复杂度完成GBDT分裂</li><li>介绍 F1-score，AUC，交叉熵，ROC</li><li>介绍 Adboost，GBDT，XGBoost</li><li>介绍不同的聚类算法：K-Means、GMM、DBSCAN等</li><li>CCA和PCA的区别</li><li>牛顿法能用于非凸函数吗？</li><li>XGBoost里处理缺失值的方法</li><li>样本不平衡对 SVM 的影响</li><li>KNN和Kmeans的算法中K的含义，K对算法的影响，怎么选择K</li><li>LR的全过程，从train到inference，损失函数</li><li>介绍常见的集成方法</li><li>LR + softmax做多分类和LR + multiLoss 做多分类区别在哪里</li><li>LR为什么用交叉熵作为loss函数</li><li>Kmeans的缺点？如何改善？</li><li>讲一下K-means算法的过程以及原理</li><li>为什么Bagging降方差，Boosting降偏差？</li><li>介绍XGBoost对GBDT的提升，LightGBM对XGBoost的提升</li><li>为什么要对连续型数值进行离散化，这样做有什么优势</li><li>LR 为什么用sigmoid函数？</li><li>怎么解决样本不均衡（重点考核损失函数优化）</li><li>HMM 和 CRF的区别</li><li>XGBoost 如何处理缺失数据？</li><li>写一下 LR 和 SVM 的损失函数</li><li>正负样本不均衡时的解决方案</li><li>知道哪些降维的方法，具体讲讲</li><li>线性模型和非线性模型都有哪些？</li><li>手写AUC的计算（小矩形积分得到总面积即可）</li><li>决策树分支的原理</li><li>offerpolicy 和 onpolicy 的区别</li><li>为什么随机森林的树比 GBDT 的深一点？</li><li>逻辑回归的目标函数(损失函数)是凸函数吗？</li><li>完全二叉树的概念</li><li>朴素贝叶斯与贝叶斯有什么区别？</li><li>SVM 为什么变成对偶问题来求解？</li><li>缺失值如何处理，什么情况下均值、众数，什么情况下丢弃特征。</li><li>诸如ID类的特征如何处理，编码方式one-hot还是其他的，高维时？什么样才算高维，有没有界定？</li><li>聚类的算法有哪些？评价方法？优化算法？</li><li>解释几何间隔和函数间隔</li><li>描述决策树，如何选特征，怎么划分，怎么剪枝，介绍信息增益</li><li>K-Means 聚类这种方法一定会收敛嘛？如果不收敛，怎么办？</li><li>SVM 的目标函数，为什么能用拉格朗日乘子法讲原始最优化问题转化为极大极小问题，数学原理是什么</li><li>介绍SVM，其中的软间隔是什么意思？</li><li>使用线性回归的时候什么时候会需要用L2？</li><li>如果F1已经趋于平稳，如何在保持F1稳定的前提下提高precision，降低recall；</li><li>LR 为什么不用 MSE，SVM 为什么用hinge不用logloss</li><li>XGBoost 怎么解决过拟合？怎么剪枝？怎么选择特征？怎么处理缺失值？</li><li>XGBoost 的默认深度</li><li>各种决策树模型的优劣（从最简单的ID3到最后的LGB）</li><li>SVM 核函数哪些是高维空间维度已知，哪些是未知的？</li><li>LR介绍、LR对特征需要做什么特殊处理吗？类别特征、连续特征</li><li>损失函数正则项的本质是什么? </li><li>SVM 有哪些核函数？</li><li>L1 正则化为什么能使特征稀疏？</li><li>Stacking原理，还有怎么调优？</li><li>XGBoost怎么调参？用了多少棵树？</li><li>各种决策树模型的优劣（从最简单的ID3到最后的LGB）</li><li>ID3 C4.5 CART的区别</li><li>手推 SVM, GBDT, XGBoost</li><li>CRF 怎么训练的（传统+深度学习）</li><li>得到AUC的两种计算方法</li><li>树的分裂方式（id3,gini,gdbt,xgboost）</li><li>监督学习的概念？什么是随机森林，随机森林的优点？</li><li>LR和SVM区别（计算复杂度）</li><li>Adam优化器的迭代公式</li><li>SGD每步做什么，为什么能online learning</li><li>L1 L2正则化区别</li><li>PCA原理和执行步骤</li><li>特征工程知道吗？举几个特征归一化的例子</li><li>SVM为什么可以处理非线性问题</li><li>L1正则化的先验分布？</li><li>L1的不知道，L2的先验分布知道吧？</li><li>多标签分类问题怎么解决，从损失函数角度考虑</li></ul><h1 id="NN"><a href="#NN" class="headerlink" title="NN"></a>NN</h1><ul><li>激活函数 除了 Sigmoid tanh ReLU 还有什么介绍一下？</li><li>BFE 和 Dropout的关系</li><li>Dropout是失活神经元还是失活连接</li><li>手推梯度反向传播</li><li>介绍 Leaky Relu 并写公式</li><li>分类网络样本不均衡怎么办？</li><li>dropout层作用，如何实现有什么作用？</li><li>Dropout 前向和反向的处理</li><li>神经网络如果没有激活函数还能解决线性不可分问题吗？</li><li>Tensorflow的动态图和静态图有什么区别</li><li>GN，BN，LN，IN 它们的共性和特性</li><li>为什么BN有泛化能力的改善. 什么场景用什么normalization方法，效果如何.</li><li>Dropout为什么能防止过拟合？具体实现</li><li>dropout在训练和测试时不同，怎么保证测试结果稳定</li><li>如何计算神经网络的 FLOPS？</li><li>梯度下降陷入局部最优有什么解决办法</li></ul><h1 id="图像处理"><a href="#图像处理" class="headerlink" title="图像处理"></a>图像处理</h1><ul><li>手写灰度直方图代码</li><li>介绍一下开运算和闭运算</li><li>介绍双目相机识别目标深度的原理</li><li>单目视觉如何测量深度？</li><li>介绍常见的边缘检测算法</li><li>SIFT 特征是如何保持旋转不变性的？</li><li>如何快速判断图中有环？</li><li>介绍常见的边缘检测算子</li><li>Hough 变换原理（直线和圆检测）</li><li>为什么 Sobel 算子中间是2，两边是1</li><li>算法题：实现 OpenCV中的图像缩放，包括实现双线性插值</li><li>输入图像灰度值对模型的影响，为什么要把0-255转化成0-1？</li><li>介绍 RANSAC</li><li>介绍一阶二阶边缘检测算子一阶二阶边缘检测算子</li><li>OpenCV里面findcontour函数的原理是什么？</li><li>相机里面的标定参数有哪些？是怎么计算这些参数的？</li><li>如何求边缘，45°边缘，高斯滤波和双边滤波</li><li>代码题：手撕实现图像的resize和rotate90度</li><li>手写中值滤波</li><li>介绍一下高斯滤波，均值滤波，中值滤波</li><li>SIFT特征提取怎么做的，具备什么性质，为什么</li><li>讲一下CTC的原理</li><li>夜间拍照的多图对齐和融合</li></ul><h1 id="CV"><a href="#CV" class="headerlink" title="CV"></a>CV</h1><ul><li>介绍你读到的19年 Anchor-free 目标检测论文</li><li>简单介绍Fast RCNN -&gt; Faster RCNN -&gt; mask RCNN (这个真的好高频)</li><li>256×256×3 -&gt; 128×128×64的卷积，stride，padding和待优化的参数有多少</li><li>手撕 SoftNMS代码</li><li>CNN反向传播公式推导；参数共享指的是？</li><li>介绍熟悉的NAS网络</li><li>介绍目标检测中的多尺度训练/测试？</li><li>为什么 DenseNet 比 ResNet 更耗显存？</li><li>为什么深度学习中的图像分割要先编码再解码？</li><li>1*1 卷积有什么作用？</li><li>如何计算语义分割的 mIoU（写伪代码）</li><li>原始图片中的 RoI 如何映射到 feature map ?</li><li>PyTorch的高效convolution实现</li><li>PyTorch 不用库函数如何实现多机多卡</li><li>哪些情况用 MaxPool比AveragePool效果好？原因</li><li>介绍Anchor based 和Anchor free目标检测网络的优缺点</li><li>YOLOv3在小缺陷检测上也很好，RPN上和two-stage的有什么区别</li><li>MobileNetV2 module的参数量和FLOPs计算</li><li>CNN 的感受野受什么影响</li><li>CNN 如何保持平移方向不变性</li><li>如果分类的数据图像每一类只有几张，你会用什么方法？</li><li>RPN怎么计算 box 的实际坐标</li><li>介绍常见的 Anchor free 目标检测算法</li><li>算法题：编程实现目标检测中的 IoU 计算</li><li>公式及讲解soft attention，hard attention，multi head attention</li><li>卷积操作是线性的吗？CNN是线性的吗？为什么？（激活函数）常用的激活函数？</li><li>3×3 卷积核 与 5×5 卷积核相比的优点</li><li>CNN Maxpooling 怎么反向传播？</li><li>Inception（V1-V4）网络结构以及优缺点</li><li>写出 YOLOv3 的损失函数</li><li>YOLOV1~V3系列介绍，以及每一版的改进，优缺点介绍</li><li>介绍金字塔池化，ASPP，深度可分，带孔卷积</li><li>VGG网络什么特点，用到了哪几种卷积核？</li><li>介绍 anchor-based和anchor-free两者的优缺点</li><li>PyTorch 多gpu训练机制的原理，优化器以及网络参数保存机制</li><li>讲下faster-rcnn？Faster-rcnn里面的NMS的算法原理是什么？</li><li>Mask R-CNN 如何提高mask的分辨率？</li><li>普通卷积、DW+PW卷积计算量推导</li><li>MobileNet V2中的Residual结构最先是哪个网络提出来的</li><li>CornerNet介绍，CornerPooling是怎么做的，怎么解决cornernet检测物体合并为一个框的问题</li><li>GoogLeNet中为什么采用小的卷积核？</li><li>说一下UNet的结构</li><li>熟悉deeplab吗，aspp是怎样的，与其他的state-of-art的模型对比，deeplab还可以做哪些改进？</li><li>retinanet的focal loss是解决的什么问题</li><li>CRF后处理的目的</li><li>介绍deeplabv3，画出backbone（串联和并联），论文中认为这两种哪种方式更好？如何避免friding efect、deeplabv3的损失函数</li></ul><h1 id="SLAM"><a href="#SLAM" class="headerlink" title="SLAM"></a>SLAM</h1><ul><li>PnP求解最少需要几个点？</li><li>ORBSLAM的哪个部分最耗时？</li><li>ORBSLAM怎么克服尺度漂移问题？</li><li>回环原理讲一下，要估计哪些量？</li><li>后端BA中，如何存在outlier一般怎么解决？</li><li>BA中，海塞矩阵的求逆有哪些可以加速的方法？</li><li>单应矩阵(homography)为什么只有8个自由度？</li><li>如何设计一个视觉+IMU+RTK+Lidar的定位系统？</li><li>对于光照明暗变化、动态场景，视觉SLAM如何去解决？</li><li>ROS中，node属于多进程，如何把两个node放在一个进程中？</li><li>ORBSLAM 后端H矩阵求解的算法复杂度是多少？如何去加速后端求解？</li><li>ORB-SLAM的初始化步骤</li><li>介绍 Bundle Adjustment</li><li>机器人学中表示旋转的方式有哪些？区别是什么？</li><li>检测圆的方法有哪些？</li><li>霍夫圆变换的原理是什么？</li><li>你知道哪些点云匹配的算法？原理是什么？</li><li>ROS里面的一些基本操作怎么实现？</li><li>怎么估计3D姿态？用什么表示姿态？</li><li>相机标定方法与流程，内外参矩阵求解</li><li>什么是闭环检测？常用的方法有哪些？你用的哪种方法？有没有创新？</li><li>解释一下Gauss-Netwon和LM算法。</li><li>熟悉Ceres优化库吗？说一下。</li><li>描述（扩展）卡尔曼滤波与粒子滤波，你自己在用卡尔曼滤波时遇到什么问题没有？</li><li>除了视觉传感，还用过其他传感吗？比如GPS，激光雷达。。。</li></ul><h1 id="反向面试"><a href="#反向面试" class="headerlink" title="反向面试"></a>反向面试</h1><p>再也不用担心面试官灵魂拷问：你有什么要问我的么？</p><p>下面列表里的问题对于参加技术面试的人来说很有用：</p><ul><li>我的日常工作是什么？</li><li>入职培训会是什么样的？</li><li>你们怎么使用源码控制系统？</li><li>团队内/团队间的交流通常是怎样的？</li><li>有标准的开发环境吗？是强制的吗？</li><li>我可以为开源项目做贡献吗？是否需要审批？</li><li>团队里面初级和高级工程师的比例是多少？</li><li>晋升流程是怎样的？要求/预期是怎样沟通的？</li><li>我入职的岗位是新增还是接替之前离职的同事？</li><li>入职之后在哪个项目组，项目是新成立还是已有的？b公司是否有技术分享交流活动？有的话，多久一次呢？</li><li>更多提问可以在 <a href="https://github.com/yifeikong/reverse-interview-zh" target="_blank" rel="noopener">https://github.com/yifeikong/reverse-interview-zh</a> 找到</li></ul><p>出了以上几种类型的题目，还常见编程算法题、C++语言细节、Python语言细节、英语题、数学题、项目、计算机网络和操作系统</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;ML&quot;&gt;&lt;a href=&quot;#ML&quot; class=&quot;headerlink&quot; title=&quot;ML&quot;&gt;&lt;/a&gt;ML&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;介绍一下调参的经验&lt;/li&gt;
&lt;li&gt;Softmax的公式和伪代码&lt;/li&gt;
&lt;li&gt;分类常见的指标有什么，如何理解AUC？&lt;/
      
    
    </summary>
    
    
      <category term="机器学习" scheme="http://a-kali.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="计算机视觉" scheme="http://a-kali.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/"/>
    
      <category term="神经网络" scheme="http://a-kali.github.io/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
      <category term="语义分割" scheme="http://a-kali.github.io/tags/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2/"/>
    
      <category term="目标检测" scheme="http://a-kali.github.io/tags/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/"/>
    
      <category term="面试" scheme="http://a-kali.github.io/tags/%E9%9D%A2%E8%AF%95/"/>
    
      <category term="SLAM" scheme="http://a-kali.github.io/tags/SLAM/"/>
    
      <category term="图像处理" scheme="http://a-kali.github.io/tags/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/"/>
    
  </entry>
  
  <entry>
    <title>周志华《机器学习》</title>
    <link href="http://a-kali.github.io/2019/09/16/%E5%91%A8%E5%BF%97%E5%8D%8E%E3%80%8A%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E3%80%8B/"/>
    <id>http://a-kali.github.io/2019/09/16/周志华《机器学习》/</id>
    <published>2019-09-16T11:28:39.000Z</published>
    <updated>2019-09-18T12:36:28.450Z</updated>
    
    <content type="html"><![CDATA[<h1 id="第-1-章-绪论"><a href="#第-1-章-绪论" class="headerlink" title="第 1 章    绪论"></a>第 1 章    绪论</h1><h2 id="1-2-基本术语"><a href="#1-2-基本术语" class="headerlink" title="1.2 基本术语"></a>1.2 基本术语</h2><p>假设（hypothesis）：根据数据的潜在规律学习而得的模型。亦称为学习器。</p><p>簇（cluster）：聚类学习中的一个组。</p><p>泛化（generalization）：学得模型适用于新样本的能力。</p><h2 id="1-3-假设空间"><a href="#1-3-假设空间" class="headerlink" title="1.3 假设空间"></a>1.3 假设空间</h2><p>假设空间：机器学习中可能的函数构成的空间。学习的过程即是在假设空间中进行搜索的过程。</p><h1 id="第-2-章-模型评估与选择"><a href="#第-2-章-模型评估与选择" class="headerlink" title="第 2 章    模型评估与选择"></a>第 2 章    模型评估与选择</h1><h2 id="2-2-评估方法"><a href="#2-2-评估方法" class="headerlink" title="2.2 评估方法"></a>2.2 评估方法</h2><h3 id="2-2-1-留出法"><a href="#2-2-1-留出法" class="headerlink" title="2.2.1 留出法"></a>2.2.1 留出法</h3><p><strong>留出法</strong>（hold-out）将数据集划分为两个互斥的集合，分别作为训练集和测试集。</p><h3 id="2-2-2-交叉验证法"><a href="#2-2-2-交叉验证法" class="headerlink" title="2.2.2 交叉验证法"></a>2.2.2 交叉验证法</h3><h3 id="2-2-3-自助法"><a href="#2-2-3-自助法" class="headerlink" title="2.2.3 自助法"></a>2.2.3 自助法</h3><p><strong>自助采样法</strong>（bootstrap sampling）对大小为 m 的数据集进行 m 次放回采样，采样得到的数据作为训练集，初始数据集中大约有 36.8% 的数据未被采样过，这部分数据作为测试集。</p><p>自助法在数据集较小、难以划分测试集和训练集时比较有用。但会改变原有数据集的分布，引入估计偏差。</p><h3 id="2-2-4-调参与最佳模型"><a href="#2-2-4-调参与最佳模型" class="headerlink" title="2.2.4 调参与最佳模型"></a>2.2.4 调参与最佳模型</h3><p>模型评估与选择中，用于评估模型的数据集常称为<strong>验证集</strong>。</p><h2 id="2-3-性能度量"><a href="#2-3-性能度量" class="headerlink" title="2.3 性能度量"></a>2.3 性能度量</h2><p>性能度量：对模型泛化能力的评价标准。</p><p>均方误差（mean squared error）：$E(f;D)=\frac{1}{m} \sum^m_{i=1}(f(x_i)-y_i)^2.$ 常用于回归任务中。</p><h3 id="2-3-1-错误率与精度"><a href="#2-3-1-错误率与精度" class="headerlink" title="2.3.1 错误率与精度"></a>2.3.1 错误率与精度</h3><ul><li><strong>错误率</strong>（error rate）：分类错误的样本数占样本总数的比例</li><li><strong>精度</strong>（accuracy）：分类正确的样本数占样本总数的比例</li></ul><p>此处的评估标准仅仅是根据样本分类的正误个数进行评估，没有表现出单个样本的错误程度。</p><h3 id="2-3-2-查准率、查全率与-F1"><a href="#2-3-2-查准率、查全率与-F1" class="headerlink" title="2.3.2 查准率、查全率与 F1"></a>2.3.2 查准率、查全率与 F1</h3><p>在信息检索等应用场景中经常出现如下的需求，比如想知道“检索出的信息中有多少比例是用户感兴趣的”“用户感兴趣的信息中有多少被检索出来了”。此时用<strong>查准率</strong>（precision）和<strong>查全率</strong>（recall，也被称为召回率）更为适合此类需求。</p><p>混淆矩阵：</p><p><a href="https://imgchr.com/i/nfoRB9" target="_blank" rel="noopener"><img src="https://s2.ax1x.com/2019/09/16/nfoRB9.png" alt="nfoRB9.png"></a></p><p>查准率 P 和查全率 R 分别被定义为</p><script type="math/tex; mode=display">P=\frac{TP}{TP+FP}\\R=\frac{TP}{TP+FN}</script><p>查全率和查准率是一对矛盾的度量。一般来说，查全率高时查准率低，查准率高时查全率低。</p><p>P-R曲线、ROC和AUC可参考<a href="https://a-kali.github.io/2019/09/03/机器学习中的评价指标/">机器学习中的评价指标</a>。</p><h3 id="2-3-4-代价敏感错误率与代价曲线"><a href="#2-3-4-代价敏感错误率与代价曲线" class="headerlink" title="2.3.4 代价敏感错误率与代价曲线"></a>2.3.4 代价敏感错误率与代价曲线</h3><p>不同类型的错误所造成的后果不同，为权衡不同类型错误所造成的不同损失，可以为错误赋予<strong>非均等代价</strong>。</p><p>在非均等代价下，我们所希望的不再是简单地最小化错误次数，而是希望最小化<strong>总体代价</strong>。以二分类为例，其代价敏感错误率为：</p><script type="math/tex; mode=display">E = \frac{1}{m}(\sum_{x_i\in D^+}I(f(x_i)\not=y_i)\times cost_{01}+\sum_{x_i\in D^-}I(f(x_i)\not=y_i)\times cost_{10})</script><p>其中$I(·)$为指示函数，$cost$为错误的权重（即代价）。</p><p><strong>代价曲线</strong>可以直接反映非均等代价下学习器的期望总体代价。代价曲线的绘制很简单：ROC曲线上的每一点对应了代价平面上的一条线段，根据ROC曲线上的每一点的状态绘制一条从(0,FPR) 到 (1, FNR) 的线段，线段下的面积即表示了该条件下的期望总体代价。</p><p><img src="https://s2.ax1x.com/2019/09/18/n7Ri7j.png" alt="n7Ri7j.png"></p><h1 id="第-3-章-线性模型"><a href="#第-3-章-线性模型" class="headerlink" title="第 3 章    线性模型"></a>第 3 章    线性模型</h1>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;第-1-章-绪论&quot;&gt;&lt;a href=&quot;#第-1-章-绪论&quot; class=&quot;headerlink&quot; title=&quot;第 1 章    绪论&quot;&gt;&lt;/a&gt;第 1 章    绪论&lt;/h1&gt;&lt;h2 id=&quot;1-2-基本术语&quot;&gt;&lt;a href=&quot;#1-2-基本术语&quot; class
      
    
    </summary>
    
      <category term="机器学习" scheme="http://a-kali.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="机器学习" scheme="http://a-kali.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>Inception v1-v4 论文解读</title>
    <link href="http://a-kali.github.io/2019/09/04/Inception-v1-v4/"/>
    <id>http://a-kali.github.io/2019/09/04/Inception-v1-v4/</id>
    <published>2019-09-04T09:57:36.000Z</published>
    <updated>2019-11-14T16:07:10.736Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Inception-V1"><a href="#Inception-V1" class="headerlink" title="Inception V1"></a>Inception V1</h1><p>论文地址：<a href="https://arxiv.org/pdf/1409.4842v1.pdf" target="_blank" rel="noopener">Going deeper with convolutions</a></p><h2 id="动机与深层思考"><a href="#动机与深层思考" class="headerlink" title="动机与深层思考"></a>动机与深层思考</h2><p>直接提升神经网络性能的方法是提升网络的深度和宽度。然而，更深的网络意味着其参数的大幅增加，从而导致计算量爆炸。因此，作者希望能在计算资源消耗恒定不变的条件下，提升网络性能。</p><p>降低计算资源消耗的一个方法是使用<a href="https://baike.baidu.com/item/稀疏连接/22764619?fr=aladdin" target="_blank" rel="noopener">稀疏连接</a>结构，但不均匀的稀疏数值运算在当前适合密集运算的硬件条件下运行十分低效。作者希望将稀疏连接结构运用于卷积层，并以此解决稀疏连接在密集运算条件下效率低下的问题。于是Inception便应运而生。</p><h2 id="架构细节"><a href="#架构细节" class="headerlink" title="架构细节"></a>架构细节</h2><p> <img src="https://s2.ax1x.com/2019/10/04/uDtGDI.png" alt="uDtGDI.png"></p><p>作者希望“找到最优的局部结构，并在空间上重复它”，如上的Inception模块便是作者找到的最优局部结构。该结构有四个通道，同时使用了1×1、3×3、5×5的卷积核。作者表示“卷积核的大小并没有什么特殊含义，其便利性大于必要性”，在padding=0，1，2的时候特征图大小相同，方便对齐。</p><p>随着网路层数的加深，其特征图的抽象程度变高，空间集中程度下降。这意味着5×5卷积核占比应逐渐增加。然而在具有大量滤波器的卷积层，5×5卷积核运算量太大。这催生了对Inception的第二个改进：在计算量要求较多的地方使用1×1卷积核进行降维。于是便诞生了完整版的Inception V1模块：</p><p><img src="https://s2.ax1x.com/2019/10/04/uDB4kn.png" alt="uDB4kn.png"></p><h2 id="GoogLeNet"><a href="#GoogLeNet" class="headerlink" title="GoogLeNet"></a>GoogLeNet</h2><p>GoogLeNet是一个大量使用了Inception模块堆叠的一个神经网络，其结构如下（图太大了，这里就不放完整图片了）：</p><p><img src="https://s2.ax1x.com/2019/10/04/uDrWin.png" alt="#uDrWin.png"></p><p>值得一提的是，考虑到深层网络的梯度消失问题（当时还没出现批归一化和残差结构），GoogLeNet使用了在网络的中间隐藏层使用了<strong>辅助分类器</strong>（auxiliary classifiers），其训练时给出的分类结果的损失的以0.3的权重加到总损失上，以在一定程度上解决梯度消失问题。</p><h2 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h2><ul><li><p>很多文章中都有提到，Inception结构使用不同大小的卷积核能够适应不同尺度的特征。虽然并没有在原论文中看见相关阐述，但我觉得有点道理。论文中提到Inception在目标检测任务中有更出色的效果，这很可能与其能适应不同尺度特征有关。</p><p><img src="https://s2.ax1x.com/2019/10/04/uDo1Ds.png" alt="如图，图中三只狗狗所占图片区域大小不同"></p></li><li><p>作者并没有在原论文中提到Inception结构起作用的原因，但我认为Inception结构和ResNet的残差结构有异曲同工之妙（虽然ResNet的诞生在GoogLeNet之后）。残差结构能让神经网络自己通过调整参数来选择是否趋近于恒等映射，而Inception能让神经网络自己选择卷积核大小（3×3、5×5 convolutions），或是将这层作为全连接（1×1 convolutions，Inception结构最左边的那个1×1卷积核作用相当于全连接），抑或是池化（3×3 Max Pooling）。</p></li></ul><h1 id="Inception-V2-amp-V3"><a href="#Inception-V2-amp-V3" class="headerlink" title="Inception V2&amp;V3"></a>Inception V2&amp;V3</h1><p>论文链接：<a href="https://arxiv.org/abs/1512.00567" target="_blank" rel="noopener">Rethinking the Inception Architecture for Computer Vision</a></p><h2 id="通用设计准则"><a href="#通用设计准则" class="headerlink" title="通用设计准则"></a>通用设计准则</h2><p>该论文提出了4个神经网络的设计准则，并根据这些准则改进Inception。以下列出关键的两条：</p><ul><li>避免一次性大幅压缩（大尺寸卷积、池化等）特征图的尺寸，否则会造成<strong>表征性瓶颈</strong>，特征图中的信息会大量损失。</li><li>高维度的特征更容易局部处理，解耦更多的特征，加速网络训练。</li></ul><h2 id="分解（Factorization）大尺寸卷积"><a href="#分解（Factorization）大尺寸卷积" class="headerlink" title="分解（Factorization）大尺寸卷积"></a>分解（Factorization）大尺寸卷积</h2><p>作者提出，大尺寸卷积的计算量和它的尺寸是不成比例的。于是将原来的5×5卷积改成了两个3×3卷积：</p><p><img src="https://s2.ax1x.com/2019/10/07/uRSdMD.png" alt="uRSdMD.png"></p><p>然后减少了28%的计算量。</p><h2 id="分解为不对称的卷积"><a href="#分解为不对称的卷积" class="headerlink" title="分解为不对称的卷积"></a>分解为不对称的卷积</h2><p>然后作者想把3×3分解成更小的卷积……尝试了分解成两个2×2，节省了11%的计算量。然后尝试了分解成1×3和3×1，节省了33%计算量。于是便多出了如下两类不对称分解的Inception模块：</p><p><img src="https://s2.ax1x.com/2019/10/07/uRCVIA.png" alt="uRCVIA.png"></p><p>左图模块特性：</p><ul><li>在网络的浅层表现不佳，但在网络的中层有较好的效果。</li><li>由于比原版模块增加了一层非线性层，提高了模型的表达能力。</li></ul><p>右图模块特性：</p><ul><li>能够维持特征的高维度，符合上述通用设计准则的第二条。</li></ul><h2 id="减少特征图尺寸"><a href="#减少特征图尺寸" class="headerlink" title="减少特征图尺寸"></a>减少特征图尺寸</h2><p>当网络需要将一个尺寸为 2d×2d、维度为 k 的特征图转换为一个尺寸为 d×d、维度为 2k 的特征图时，问题就来了：如果先减小尺寸，那么将会损失大量信息，造成准则第一条中的表征性瓶颈；如果先增大维度，那么计算量将翻3倍。如何高效地减小特征图尺寸呢？作者提出了以下结构：</p><p><img src="https://s2.ax1x.com/2019/10/07/uRkv3n.png" alt="uRkv3n.png"></p><p>该结构在增加特征维度、减少特征图尺寸的同时避免了表征性瓶颈和计算量过大的问题。</p><h2 id="Inception-v2"><a href="#Inception-v2" class="headerlink" title="Inception-v2"></a>Inception-v2</h2><p><img src="https://s2.ax1x.com/2019/10/07/uRVxgA.png" alt="uRVxgA.png"></p><p>其中使用了三种Inception模块（图中红框处），包括3个普通分解模块和5个不对称分解堆叠模块以及2个不对称分解扩展模块。值得一提的是原网络中的7×7卷积被分解成了3个3×3卷积。</p><h2 id="Inception-v3"><a href="#Inception-v3" class="headerlink" title="Inception-v3"></a>Inception-v3</h2><p>在论文的后续中，作者对Inception v2进行了如下改进：</p><ul><li>使用RMSProp优化器</li><li>辅助分类器使用了BatchNorm</li><li>标签平滑（正则化）</li></ul><h1 id="Inception-V4-amp-Inception-Resnet"><a href="#Inception-V4-amp-Inception-Resnet" class="headerlink" title="Inception V4 &amp; Inception-Resnet"></a>Inception V4 &amp; Inception-Resnet</h1><p>论文地址：<a href="https://arxiv.org/pdf/1602.07261.pdf" target="_blank" rel="noopener">Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning</a></p><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>随着 ResNet 网络的出现及其在主流数据集上的良好表现，作者想将残差结构引入到 Inception 网络中，看看网络是否会有更好的表现；同时注意到Inception-v3的部分结构有不必要的复杂性，于是尝试在不引入残差结构的情况下改进原本的Inception结构，并将改进后的Inception结构命名为Inception-v4。</p><p>我感觉这篇论文的知识量不大，整篇论文一半都是图，看看了解下就行。</p><h2 id="Inception-v4"><a href="#Inception-v4" class="headerlink" title="Inception-v4"></a>Inception-v4</h2><p><img src="https://s2.ax1x.com/2019/10/08/uhaJjs.png" alt="uhaJjs.png"></p><p>图中是v4使用的三个Inception模块。分别命名为Inception-A、Inception-B、Inception-C。除了所有的池化层都使用了<strong>Avg Pooling</strong>以外，没有什么特别的变动。另外网络整体结构也发生了一些改变，这里直接用网图了：</p><p><img src="https://img-blog.csdnimg.cn/2018102913400312.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3p6YzE1ODA2,size_27,color_FFFFFF,t_70" alt></p><h2 id="Inception-Resnet"><a href="#Inception-Resnet" class="headerlink" title="Inception-Resnet"></a>Inception-Resnet</h2><p><a href="https://imgchr.com/i/uhwGmn" target="_blank" rel="noopener"><img src="https://s2.ax1x.com/2019/10/08/uhwGmn.md.png" alt="uhwGmn.md.png"></a></p><p><img src="https://img-blog.csdnimg.cn/20181029135504384.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3p6YzE1ODA2,size_27,color_FFFFFF,t_70" alt></p><p>上图是 Inception-Resnet-v1 的模块和结构， Inception-Resnet-v2只是在v1的基础上使用了Inception-v4的stem结构。</p><h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><p>[1]<a href="http://baijiahao.baidu.com/s?id=1601882944953788623&wfr=spider&for=pc" target="_blank" rel="noopener">一文概览Inception家族的「奋斗史」</a></p><p>[2]<a href="https://blog.csdn.net/zzc15806/article/details/83504130" target="_blank" rel="noopener">【深度学习】GoogLeNet系列解读 —— Inception v4</a></p><p>[3]<a href="https://blog.csdn.net/weixin_39953502/article/details/80966046" target="_blank" rel="noopener">inception-v1,v2,v3,v4—-论文笔记</a></p><p>以及文中所述的论文链接。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Inception-V1&quot;&gt;&lt;a href=&quot;#Inception-V1&quot; class=&quot;headerlink&quot; title=&quot;Inception V1&quot;&gt;&lt;/a&gt;Inception V1&lt;/h1&gt;&lt;p&gt;论文地址：&lt;a href=&quot;https://arxiv.or
      
    
    </summary>
    
      <category term="计算机视觉" scheme="http://a-kali.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/"/>
    
    
      <category term="论文解读" scheme="http://a-kali.github.io/tags/%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB/"/>
    
      <category term="Inception" scheme="http://a-kali.github.io/tags/Inception/"/>
    
      <category term="计算机视觉" scheme="http://a-kali.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/"/>
    
      <category term="神经网络" scheme="http://a-kali.github.io/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>线性回归与逻辑回归</title>
    <link href="http://a-kali.github.io/2019/09/03/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E4%B8%8E%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/"/>
    <id>http://a-kali.github.io/2019/09/03/线性回归与逻辑回归/</id>
    <published>2019-09-03T13:21:16.000Z</published>
    <updated>2019-09-04T09:56:45.073Z</updated>
    
    <content type="html"><![CDATA[<h1 id="线性回归"><a href="#线性回归" class="headerlink" title="线性回归"></a>线性回归</h1><p>​    <strong>线性回归</strong>通常是解决连续数值预测问题, 利用数理统计的回归分析, 来确定变量之间的相互依赖关系. 其公式通常表示如下:</p><script type="math/tex; mode=display">h_\theta(x)=\theta_0 +\theta_1x_1+\theta_2x_2+……+\theta_nx_n=θ^Tx</script><h1 id="逻辑回归"><a href="#逻辑回归" class="headerlink" title="逻辑回归"></a>逻辑回归</h1><p>​    <strong>逻辑（Logistic，又称 Sigmoid）回归</strong>常用于解决二分类问题，用于估算某种事物的可能性。Sigmoid 函数公式如下：</p><script type="math/tex; mode=display">g(z)=\frac{1}{1+e^{-z}}</script><p>该函数的值域为 (0, 1)，其值的意义为输入特征被分到 1 类的概率。逻辑回归的本质是在线性回归之后加了一层函数映射。将线性回归方程带入到逻辑回归方程中，得到逻辑回归表达式：</p><script type="math/tex; mode=display">h_\theta(x) = g(\theta^Tx)=\frac{1}{1+e^{-\theta^Tx}}</script>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;线性回归&quot;&gt;&lt;a href=&quot;#线性回归&quot; class=&quot;headerlink&quot; title=&quot;线性回归&quot;&gt;&lt;/a&gt;线性回归&lt;/h1&gt;&lt;p&gt;​    &lt;strong&gt;线性回归&lt;/strong&gt;通常是解决连续数值预测问题, 利用数理统计的回归分析, 来确定变量之间的
      
    
    </summary>
    
      <category term="机器学习" scheme="http://a-kali.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="机器学习" scheme="http://a-kali.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="线性回归" scheme="http://a-kali.github.io/tags/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/"/>
    
      <category term="逻辑回归" scheme="http://a-kali.github.io/tags/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/"/>
    
  </entry>
  
  <entry>
    <title>机器学习中的评价指标</title>
    <link href="http://a-kali.github.io/2019/09/03/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E8%AF%84%E4%BB%B7%E6%8C%87%E6%A0%87/"/>
    <id>http://a-kali.github.io/2019/09/03/机器学习中的评价指标/</id>
    <published>2019-09-03T08:52:16.000Z</published>
    <updated>2019-09-18T07:01:26.902Z</updated>
    
    <content type="html"><![CDATA[<h1 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h1><h2 id="混淆矩阵"><a href="#混淆矩阵" class="headerlink" title="混淆矩阵"></a>混淆矩阵</h2><div class="table-container"><table><thead><tr><th style="text-align:center">-</th><th style="text-align:center">Positive Predictions</th><th style="text-align:center">Negative Predictions</th></tr></thead><tbody><tr><td style="text-align:center">Positive Label</td><td style="text-align:center">TP (True Positive)</td><td style="text-align:center">FN</td></tr><tr><td style="text-align:center">Negative Label</td><td style="text-align:center">FP</td><td style="text-align:center">TN</td></tr></tbody></table></div><h2 id="Accuracy（ACC，准确率）"><a href="#Accuracy（ACC，准确率）" class="headerlink" title="Accuracy（ACC，准确率）"></a>Accuracy（ACC，准确率）</h2><script type="math/tex; mode=display">ACC= \frac{TP+TN}{FP+FN+TP+TN}=\frac{预测正确的样本数}{总样本数}</script><h2 id="Precision（PRE，精度、查准率）"><a href="#Precision（PRE，精度、查准率）" class="headerlink" title="Precision（PRE，精度、查准率）"></a>Precision（PRE，精度、查准率）</h2><script type="math/tex; mode=display">PRE=\frac{TP}{TP+FP}=\frac{预测正确的正样本数}{所有预测为正的样本数}</script><h2 id="True-Positive-Rate（TPR，召回率、查全率）"><a href="#True-Positive-Rate（TPR，召回率、查全率）" class="headerlink" title="True Positive Rate（TPR，召回率、查全率）"></a>True Positive Rate（TPR，召回率、查全率）</h2><script type="math/tex; mode=display">TPR=\frac{TP}{TP+FN}= \frac{预测正确的正样本数}{总正样本数}</script><h2 id="False-Positive-Rate（FPR，误报率）"><a href="#False-Positive-Rate（FPR，误报率）" class="headerlink" title="False Positive Rate（FPR，误报率）"></a>False Positive Rate（FPR，误报率）</h2><script type="math/tex; mode=display">FPR=\frac{FP}{TN+FP}=\frac{预测为正的负样本数}{总负样本数}</script><h2 id="False-Negative-Rate（FNR，漏报率）"><a href="#False-Negative-Rate（FNR，漏报率）" class="headerlink" title="False Negative Rate（FNR，漏报率）"></a>False Negative Rate（FNR，漏报率）</h2><script type="math/tex; mode=display">FNR=\frac{FN}{TN+FN}=\frac{预测为负的正样本数}{预测成负样本的总数量}</script><h1 id="评估曲线"><a href="#评估曲线" class="headerlink" title="评估曲线"></a>评估曲线</h1><h2 id="PR-曲线"><a href="#PR-曲线" class="headerlink" title="PR 曲线"></a>PR 曲线</h2><p>精度又名查准率, 关心的是 “查出的所有正例中, 哪些正例是查对的”<br>召回率又名查全率, 关心的是 “对于所有的正例, 正确查出了多少个”</p><p>这二者是一对矛盾的度量, 因为我们很容易知道:</p><ul><li>如果我们希望查准率高, 那么可以认为是 “只有当十成把握认为其是正例时, 才将其挑出”。</li><li>而如果我们希望召回率高, 那么可以认为是 “宁错杀一百, 不放过一个”. 查准率和查全率的曲线又叫 PR 曲线, 如下图所示：</li></ul><p><img src="https://s2.ax1x.com/2019/09/03/nkRp6J.jpg" alt="nkRp6J.jpg"></p><p>通常情况下, 如果一个学习器的 PR 曲线被另一个学习器 <strong>完全包住</strong>. 那么我们就认为后者的性能优于前者. 当二者存在交叉时, 我们可以通过四种方式来确定学习器的优劣：</p><ol><li><p>计算 PR 曲线与横纵坐标轴围成的面积, 面积越大越好；</p></li><li><p>利用平衡点 (BEP, 查准率=查全率), BEP 越大越好；</p></li><li><p>利用$F<em>\beta$度量, 当 $\beta<1$ 时， 查准率(精度)权重更大, 当$\beta>1$时， 查全率(召回率)权重更大。$F</1$></em>\beta$的计算公式来自于加权调和平均数：</p><script type="math/tex; mode=display">\frac{1}{F_\beta}=\frac{1}{1+β^2}(\frac{1}{P}+\frac{β^2}{R})</script><script type="math/tex; mode=display">F_β=\frac{(1+β^2)×P×R}{β^2×P+R}</script></li></ol><h2 id="ROC-曲线"><a href="#ROC-曲线" class="headerlink" title="ROC 曲线"></a>ROC 曲线</h2><p>​    很多学习器是为测试样本产生一个实值或概率预测，然后将这个预测值与一个分类阈值进行比较，若大于阈值分为正例，否则分为负例，因此<strong>分类过程可以看做是选取一个合适的截断点</strong>。那么到底什么样的截断点更合适呢？ ROC 正是从这个角度来研究学习器好坏的工具。</p><p>​    ROC 曲线的纵坐标和横坐标分别是召回率和误诊率，下图为 ROC 曲线图，实际任务中会利用有限个测试样本来绘制 ROC 图，所以产生的大多不是平滑的曲线。</p><p><img src="https://s2.ax1x.com/2019/09/03/nk7o59.jpg" alt="nk7o59.jpg"></p><h3 id="绘制-ROC-曲线"><a href="#绘制-ROC-曲线" class="headerlink" title="绘制 ROC 曲线"></a>绘制 ROC 曲线</h3><p>​    假设已经得出一系列样本被划分为正类的概率，然后按照大小排序，下图是一个示例，图中共有20个测试样本，”Class” 一栏表示每个测试样本真正的标签（p表示正样本，n表示负样本），”Score” 表示每个测试样本属于正样本的概率。</p><p><img src="https://s2.ax1x.com/2019/09/03/nkLzOP.jpg" alt="nkLzOP.jpg"></p><p>​    接下来，我们从高到低，依次将“Score”值作为阈值threshold，当测试样本属于正样本的概率大于或等于这个threshold时，我们认为它为正样本，否则为负样本。举例来说，对于图中的第4个样本，其“Score”值为0.6，那么样本1，2，3，4都被认为是正样本，因为它们的“Score”值都大于等于0.6，而其他样本则都认为是负样本。每次选取一个不同的threshold，我们就可以得到一组FPR和TPR，即ROC曲线上的一点。这样一来，我们一共得到了20组FPR和TPR的值，将它们画在ROC曲线的结果如下图：</p><p><img src="https://s2.ax1x.com/2019/09/03/nkOQkF.jpg" alt="nkOQkF.jpg"></p><h3 id="ROC-曲线的意义"><a href="#ROC-曲线的意义" class="headerlink" title="ROC 曲线的意义"></a>ROC 曲线的意义</h3><p>​    有助于选择最佳的阈值。ROC曲线越靠近左上角，模型的准确性就越高。最靠近左上角的ROC曲线上的点是分类错误最少的最好阈值，其假正例和假反例总数最少。</p><h2 id="AUC-的含义及计算"><a href="#AUC-的含义及计算" class="headerlink" title="AUC 的含义及计算"></a>AUC 的含义及计算</h2><p>​    <strong>AUC</strong>（Area Under Curve）被定义为ROC曲线下与坐标轴围成的面积，显然这个面积的数值不会大于1。又由于ROC曲线一般都处于y=x这条直线的上方，所以AUC的取值范围在0.5和1之间。</p><p>​    在进行学习器的比较时，若一个学习器的ROC曲线被另一个学习器的曲线完全“包住”，则可断言后者的性能优于前者；若两个学习器的ROC曲线发生交叉，则难以一般性的断言两者孰优孰劣。此时如果一定要进行比较，则比较合理的判断依据是比较AUC，AUC大的学习器通常性能更好。</p><h1 id="参考文献："><a href="#参考文献：" class="headerlink" title="参考文献："></a>参考文献：</h1><p><a href="https://hellozhaozheng.github.io/z_post/计算机视觉-计算机视觉知识点总结/" target="_blank" rel="noopener">计算机视觉知识总结</a></p><p><a href="https://baike.baidu.com/item/AUC/19282953?fr=aladdin" target="_blank" rel="noopener">AUC 百度百科</a></p><p><a href="https://zdkswd.github.io/2018/11/20/精确率、召回率、真正类率（TPR）、假正类率（FPR）ROC曲线/" target="_blank" rel="noopener">精确率、召回率、真正类率（TPR）、假正类率（FPR）ROC曲线</a></p><p><a href="https://blog.csdn.net/Libo_Learner/article/details/83615715" target="_blank" rel="noopener">机器学习笔记~F-score beta衡量precision和recall之间重要性</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;基本概念&quot;&gt;&lt;a href=&quot;#基本概念&quot; class=&quot;headerlink&quot; title=&quot;基本概念&quot;&gt;&lt;/a&gt;基本概念&lt;/h1&gt;&lt;h2 id=&quot;混淆矩阵&quot;&gt;&lt;a href=&quot;#混淆矩阵&quot; class=&quot;headerlink&quot; title=&quot;混淆矩阵&quot;&gt;&lt;/a
      
    
    </summary>
    
      <category term="机器学习" scheme="http://a-kali.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="机器学习" scheme="http://a-kali.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="评价指标" scheme="http://a-kali.github.io/tags/%E8%AF%84%E4%BB%B7%E6%8C%87%E6%A0%87/"/>
    
  </entry>
  
  <entry>
    <title>Kaggle 比赛记录之 Severstal: Steel Defect Detection</title>
    <link href="http://a-kali.github.io/2019/09/02/Severstal-Steel-Defect-Detection-%E6%AF%94%E8%B5%9B%E8%AE%B0%E5%BD%95/"/>
    <id>http://a-kali.github.io/2019/09/02/Severstal-Steel-Defect-Detection-比赛记录/</id>
    <published>2019-09-02T02:18:54.000Z</published>
    <updated>2019-10-16T15:08:55.522Z</updated>
    
    <content type="html"><![CDATA[<p>​    看论文看腻了，正好抽空看看隔壁的 Severstal 比赛。希望能吸取一点之前的教训，在这场比赛上好好发挥。</p><h1 id="比赛概览"><a href="#比赛概览" class="headerlink" title="比赛概览"></a>比赛概览</h1><h2 id="描述"><a href="#描述" class="headerlink" title="描述"></a>描述</h2><p>​    大概就是一家中国企业为了提高扁钢的生产质量而希望使用计算机视觉来检测扁钢损坏而发布的一场比赛。</p><h2 id="成绩评价指标"><a href="#成绩评价指标" class="headerlink" title="成绩评价指标"></a>成绩评价指标</h2><p>​    <strong>Dice系数：</strong></p><script type="math/tex; mode=display">Dice(s_1, s_2)=2*\frac{s_1\cap s_2}{s_1+ s_2}</script><p>用于比较两字符串的相似度，大概就是两字符串相同字符的个数乘2比上长度之和。这里应该是用来比较 RLE 编码的相似度。</p><p>​    提交的数据的三分之一用于公榜展示，剩下的三分之二作为最终成绩。这意味着可能比赛结束成绩就出来了。</p><h2 id="比赛时间"><a href="#比赛时间" class="headerlink" title="比赛时间"></a>比赛时间</h2><ul><li><p>2019.10.17 加入比赛、数据公开和组队的截止日期。</p></li><li><p>2019.10.24 提交最终成绩。</p></li><li>2019.11.10 高效奖争夺最终提交。（该比赛的前 50 可以进入高效奖的争夺）</li></ul><h2 id="这是一个-Kernels-only-比赛"><a href="#这是一个-Kernels-only-比赛" class="headerlink" title="这是一个 Kernels-only 比赛"></a>这是一个 Kernels-only 比赛</h2><p>​    最终的提交文件必须在 kernel 上生成，比赛者需要上传模型并在 kernel 上进行最后的测试。并需要满足以下条件：</p><ul><li>单 GPU 情况下运行时间不超过<strong>一小时</strong>。</li><li>断网。</li></ul><h1 id="比赛数据"><a href="#比赛数据" class="headerlink" title="比赛数据"></a>比赛数据</h1><p>​    训练图集、测试图集、训练样本数据和提交样本。每张图占4行csv，分别表示其4种损坏的RLE码。</p><h1 id="EDA"><a href="#EDA" class="headerlink" title="EDA"></a>EDA</h1><p>在做EDA之前先说说自己对数据的想法：</p><ul><li>既然每个样本有 4 种损坏类型，那是不是每种损坏可以单独用一个模型来训练。</li><li>扁钢损坏率似乎不大，这意味着大多数扁钢或许只有1-2种损坏。</li></ul><p>以上有待EDA考究。</p><p>让我们来找一篇<a href="https://www.kaggle.com/go1dfish/clear-mask-visualization-and-simple-eda" target="_blank" rel="noopener">点赞数最多的 EDA</a> 瞅一瞅，得出以下信息：</p><ul><li>训练样本数为 12568，其中有损坏的样本数为 5902，接近一半</li><li>测试样本数为1801</li><li>图片长宽为 (1600, 256)</li><li>四类损坏的数量：{1: 897, 2: 247, 3: 5150, 4: 801}，可见绝大部分损坏都包含第三类损坏</li><li>每个样本具有损坏的种类：{0: 5902, 1: 6239, 2: 425, 3: 2}</li><li>第一类损坏呈密集斑点（猜想）和小矩形状</li><li>第二类损坏呈长条矩形状，似乎是刮损裂纹。竖直长度通常大于横向长度，一张图只有少数损坏。常伴生第一类损坏。</li><li>第三类损坏常呈现大块状，边缘较直，出现概率很高</li><li>第四类损坏扁钢有明显不规则突起，形状十分不规则，常伴生第三类损坏</li></ul><h1 id="疑问"><a href="#疑问" class="headerlink" title="疑问"></a>疑问</h1><ul><li>那个网状的钢是什么？有没有其他形状的？</li><li>有没有哪些易于被混淆的损坏和普通纹路？如果有可以进行可视化来找出原因。</li><li>根据类型比例来设定阈值</li><li>统计各类损坏的密集程度、长宽最大值和最小值以及比例、mask size</li><li>统计两类损坏之间有没有伴生现象</li><li>不同的类型可以使用不同的minsize和阈值</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;​    看论文看腻了，正好抽空看看隔壁的 Severstal 比赛。希望能吸取一点之前的教训，在这场比赛上好好发挥。&lt;/p&gt;
&lt;h1 id=&quot;比赛概览&quot;&gt;&lt;a href=&quot;#比赛概览&quot; class=&quot;headerlink&quot; title=&quot;比赛概览&quot;&gt;&lt;/a&gt;比赛概览&lt;/h
      
    
    </summary>
    
      <category term="计算机视觉" scheme="http://a-kali.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/"/>
    
    
      <category term="计算机视觉" scheme="http://a-kali.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/"/>
    
      <category term="语义分割" scheme="http://a-kali.github.io/tags/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2/"/>
    
      <category term="Kaggle" scheme="http://a-kali.github.io/tags/Kaggle/"/>
    
  </entry>
  
  <entry>
    <title>ResNet (CVPR, 2016)</title>
    <link href="http://a-kali.github.io/2019/09/01/ResNet-CVPR-2016/"/>
    <id>http://a-kali.github.io/2019/09/01/ResNet-CVPR-2016/</id>
    <published>2019-09-01T15:48:36.000Z</published>
    <updated>2019-11-14T16:04:43.452Z</updated>
    
    <content type="html"><![CDATA[<p><strong>论文地址：</strong><a href="https://arxiv.org/abs/1512.03385" target="_blank" rel="noopener">Deep Residual Learning for Image Recognition</a></p><h1 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h1><p>​    众所周知，深度的网络使各层特征和分类器在一个端到端多层网络中融为一个整体，最近的研究也表明网络的深度非常重要。但网络的学习是否像堆积更深层的网络那么简单呢？一个阻碍深层网络学习的阻碍就是臭名昭著的梯度消失和梯度爆炸问题，严重妨碍到神经网络的收敛。这个问题由于归一初始化和中间层归一化的诞生得到了一定的解决，这使得十层以上的神经网络在随机梯度下降的反向传播时也能得到很好的收敛。</p><p>​    然而，实验告诉我们，更深层的神经网络容易表现出<strong>退化</strong>问题（随着层数的加深，准确率达到饱和然后迅速下降），而模型退化的根本原因很大程度上不是因为过拟合，而是因为梯度消失问题。</p><p>​    退化问题表明不是所有的网络结构都能轻易得到优化。假设我们有一个浅层网络和一个深层网络，深层网络的一部分是浅层网络的拷贝，其余部分为恒等映射。在这种情况下深层网络不应该会比浅层网络有更大的误差。<strong>而导致深层网络比浅层网络准确率低的原因是深层网络更难以优化</strong>。</p><p>​    这篇论文将介绍一个深度残差学习框架如何解决退化问题。深度残差框架没有使用直接堆叠网络层来拟合期望的映射函数，而是选择<strong>让这些网络层来拟合一个残差映射</strong>。比如说，我们所期望得到的映射函数射函数为 H(x), 那么我们通过残差函数 F(x) := H(x) - x。那么原始的映射函数就可以通过 F(x) + x 得到。如图所示：</p><p><img src="https://s2.ax1x.com/2019/09/01/nS6Rc8.png" alt="nS6Rc8.png"></p><h1 id="深度残差学习"><a href="#深度残差学习" class="headerlink" title="深度残差学习"></a>深度残差学习</h1><h2 id="残差学习"><a href="#残差学习" class="headerlink" title="残差学习"></a>残差学习</h2><p>​    假设 H(x) 由几个堆叠层组成，其输入为 x，并且其最终能被训练为残差函数 F(x)，即 H(x) = F(x) + x。其也能起到所要求的函数的效果，但是使堆叠层训练成残差函数的难度和使用残差结构训练的难度是不一样的。</p><p>​    引言中所提到的反直觉现象促成了这种重构。如同我们在引言中所讨论的，额外增加的层次如果都是恒等映射，深层模型的不会比浅层模型有更大的误差。退化问题则表明，由多个非线性层的叠加而成的额外层很难近似于恒等映射。<strong>而在残差学习的结构下，如果恒等映射是可选择的，额外层可能会简单地将权重降低至接近0来实现恒等映射。</strong></p><h2 id="快捷恒等映射"><a href="#快捷恒等映射" class="headerlink" title="快捷恒等映射"></a>快捷恒等映射</h2><p>​    我们在每几层之间使用残差学习，如上图的结构。在这篇论文中我们将残差块定义为：<br>$$<br>y = F(x,{W_i})+x<br>$$<br>x 和 y 分别表示残差块的输入和输出，函数 F 表示残差映射所需要学习的函数。上图中的 F(x) 为：<br>$$<br>F=W_2 \sigma(W_1x)<br>$$<br>其中 σ 表示 ReLU，为了简化写法忽略偏置项。之后 F + x 通过快捷连接来完成，之后再进行一段ReLU。</p><p>​    第一条方程式中的 F 和 x 的维度必须是相等的。如果不是这种情况（比如当改变输入输出通道时），<strong>我们可以添加系数矩阵 $W_s$ 来使得 F 和 x 维度相等</strong>。<br>$$<br>y=F(x,W_i)+W_sx<br>$$<br>​    <strong>残差函数 F 的形式时可变的。本文的实验中包含了两层和三层的结构，当然更多层也是可以的，甚至可以用于卷积层。</strong></p><h1 id="ResNet-的意义"><a href="#ResNet-的意义" class="headerlink" title="ResNet 的意义"></a>ResNet 的意义</h1><ul><li><p>从关联性的角度来看，残差结构使得深层网络和浅层网络的关联性更强，输出端的损失能更加有效地调整到浅层网络的参数。当网络层数过深时，优化器会调低网络权重，使得反向传播“选择性地”使用捷径。</p></li><li><p>从函数角度来看，残差结构直接构建了一个更接近“绝对不比浅层网络差”的结构。</p></li></ul><h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><p>[1]<a href="https://hellozhaozheng.github.io/z_post/计算机视觉-ResNet-CVPR2016" target="_blank" rel="noopener">从零开始的BLOG</a></p><p>[2]<a href="https://blog.csdn.net/Quincuntial/article/details/77263562?locationNum=6" target="_blank" rel="noopener">ResNet 论文翻译</a></p><p>[3]<a href="https://arxiv.org/abs/1512.03385" target="_blank" rel="noopener">Deep Residual Learning for Image Recognition</a></p><p>恺明大佬牛逼！</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;strong&gt;论文地址：&lt;/strong&gt;&lt;a href=&quot;https://arxiv.org/abs/1512.03385&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Deep Residual Learning for Image Recognit
      
    
    </summary>
    
    
      <category term="论文解读" scheme="http://a-kali.github.io/tags/%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB/"/>
    
      <category term="计算机视觉" scheme="http://a-kali.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/"/>
    
      <category term="神经网络" scheme="http://a-kali.github.io/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
      <category term="ResNet" scheme="http://a-kali.github.io/tags/ResNet/"/>
    
  </entry>
  
  <entry>
    <title>Aiming to 谷歌机器学习冬令营</title>
    <link href="http://a-kali.github.io/2019/08/29/Aiming-to-%E8%B0%B7%E6%AD%8C%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%86%AC%E4%BB%A4%E8%90%A5/"/>
    <id>http://a-kali.github.io/2019/08/29/Aiming-to-谷歌机器学习冬令营/</id>
    <published>2019-08-29T15:02:43.000Z</published>
    <updated>2019-11-13T16:51:13.291Z</updated>
    
    <content type="html"><![CDATA[<div id="hbe-security">  <div class="hbe-input-container">  <input type="password" class="hbe-form-control" id="pass" placeholder="Please enter the password to read the blog." />    <label for="pass">Please enter the password to read the blog.</label>    <div class="bottom-line"></div>  </div></div><div id="decryptionError" style="display: none;">Incorrect Password!</div><div id="noContentError" style="display: none;">No content to display!</div><div id="encrypt-blog" style="display:none">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</div><script src="/lib/crypto-js.js"></script><script src="/lib/blog-encrypt.js"></script><link href="/css/blog-encrypt.css" rel="stylesheet" type="text/css">]]></content>
    
    <summary type="html">
    
      The article has been encrypted, please enter your password to view.&lt;br&gt;
    
    </summary>
    
      <category term="计划" scheme="http://a-kali.github.io/categories/%E8%AE%A1%E5%88%92/"/>
    
    
      <category term="Google" scheme="http://a-kali.github.io/tags/Google/"/>
    
      <category term="招聘" scheme="http://a-kali.github.io/tags/%E6%8B%9B%E8%81%98/"/>
    
      <category term="机器学习" scheme="http://a-kali.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="计划" scheme="http://a-kali.github.io/tags/%E8%AE%A1%E5%88%92/"/>
    
  </entry>
  
  <entry>
    <title>在深度学习过程中遇到的一些bug及解决方法</title>
    <link href="http://a-kali.github.io/2019/08/29/%E5%9C%A8%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%BF%87%E7%A8%8B%E4%B8%AD%E9%81%87%E5%88%B0%E7%9A%84%E4%B8%80%E4%BA%9Bbug%E5%8F%8A%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95/"/>
    <id>http://a-kali.github.io/2019/08/29/在深度学习过程中遇到的一些bug及解决方法/</id>
    <published>2019-08-29T09:15:55.000Z</published>
    <updated>2019-08-29T09:15:55.619Z</updated>
    
    <summary type="html">
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>《C++ Primer》 第4章 表达式</title>
    <link href="http://a-kali.github.io/2019/08/29/%E3%80%8AC-Primer%E3%80%8B-%E7%AC%AC4%E7%AB%A0-%E8%A1%A8%E8%BE%BE%E5%BC%8F/"/>
    <id>http://a-kali.github.io/2019/08/29/《C-Primer》-第4章-表达式/</id>
    <published>2019-08-29T08:14:27.000Z</published>
    <updated>2019-08-29T08:54:15.557Z</updated>
    
    <content type="html"><![CDATA[<h1 id="4-8-位运算符"><a href="#4-8-位运算符" class="headerlink" title="4.8 位运算符"></a>4.8 位运算符</h1><p><strong>位运算符</strong>主要作用于整型的运算对象，并把运算对象看成是二进制位的集合。</p><ul><li>~ 位求反</li><li>&lt;&lt; 左移</li><li>>&gt; 右移</li><li>&amp; 位与</li><li>^ 位异或</li><li>| 位或</li></ul><h1 id="4-9-sizeof-运算符"><a href="#4-9-sizeof-运算符" class="headerlink" title="4.9 sizeof 运算符"></a>4.9 sizeof 运算符</h1><p>​    <strong>sizeof</strong> 运算符返回的是表达式结果类型的大小，返回类型为 size_t。</p><p>就这样水完一篇博客（ -_-)</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;4-8-位运算符&quot;&gt;&lt;a href=&quot;#4-8-位运算符&quot; class=&quot;headerlink&quot; title=&quot;4.8 位运算符&quot;&gt;&lt;/a&gt;4.8 位运算符&lt;/h1&gt;&lt;p&gt;&lt;strong&gt;位运算符&lt;/strong&gt;主要作用于整型的运算对象，并把运算对象看成是二进制
      
    
    </summary>
    
      <category term="C++" scheme="http://a-kali.github.io/categories/C/"/>
    
    
      <category term="C++" scheme="http://a-kali.github.io/tags/C/"/>
    
  </entry>
  
  <entry>
    <title>《C++ Primer》 第3章 字符串、向量和数组</title>
    <link href="http://a-kali.github.io/2019/08/26/%E3%80%8AC-Primer%E3%80%8B-%E7%AC%AC3%E7%AB%A0-%E5%AD%97%E7%AC%A6%E4%B8%B2%E3%80%81%E5%90%91%E9%87%8F%E5%92%8C%E6%95%B0%E7%BB%84/"/>
    <id>http://a-kali.github.io/2019/08/26/《C-Primer》-第3章-字符串、向量和数组/</id>
    <published>2019-08-25T17:58:39.000Z</published>
    <updated>2019-08-29T03:37:23.617Z</updated>
    
    <content type="html"><![CDATA[<h1 id="3-1-命名空间的-using-声明"><a href="#3-1-命名空间的-using-声明" class="headerlink" title="3.1 命名空间的 using 声明"></a>3.1 命名空间的 using 声明</h1><p>​    <strong>域操作符</strong>（::）的含义是：编译器应从操作符左侧名字所示作用域中寻找右侧那个名字。因此，std::cin 的意思就是要使用命名空间 std 中的名字 cin。而使用 <strong>using 声明</strong>后则无需专门的前缀也能使用所需的名字了。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">using</span> <span class="built_in">std</span>::<span class="built_in">cin</span>;</span><br><span class="line"><span class="keyword">int</span> i;</span><br><span class="line"><span class="built_in">cin</span> &gt;&gt; i;</span><br></pre></td></tr></table></figure><p>更方便的方法：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br></pre></td></tr></table></figure><p>这样就可以使用 std 命名空间中所有的名字了。</p><h1 id="3-2-标准库类型-string"><a href="#3-2-标准库类型-string" class="headerlink" title="3.2 标准库类型 string"></a>3.2 标准库类型 string</h1><p>​    标准库类型 <strong>string</strong> 表示可变长的字符序列，使用 string 类型必须首先包含 string 头文件。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;string&gt; // 包含 string 头文件</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="built_in">std</span>::<span class="built_in">string</span>; <span class="comment">// string 定义在命名空间 std 中</span></span><br></pre></td></tr></table></figure><h2 id="3-2-1-定义和初始化-string-对象"><a href="#3-2-1-定义和初始化-string-对象" class="headerlink" title="3.2.1 定义和初始化 string 对象"></a>3.2.1 定义和初始化 string 对象</h2><p>​    如何初始化类的对象是由类本身决定的。如下是初始化 string 对象的常用方式：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="built_in">string</span> <span class="title">s1</span><span class="params">(s2)</span></span>;</span><br><span class="line"><span class="built_in">string</span> s1 = s2;    <span class="comment">// 同上</span></span><br><span class="line"><span class="function"><span class="built_in">string</span> <span class="title">s1</span><span class="params">(n, <span class="string">'c'</span>)</span>  <span class="comment">// 将s1初始化为由连续n个'c'组成的字符串</span></span></span><br></pre></td></tr></table></figure><h2 id="3-2-2-string-对象上的操作"><a href="#3-2-2-string-对象上的操作" class="headerlink" title="3.2.2 string 对象上的操作"></a>3.2.2 string 对象上的操作</h2><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">os &lt;&lt; s; <span class="comment">// output stream</span></span><br><span class="line">is &gt;&gt; s; <span class="comment">// 输入到s，字符串以空白分隔</span></span><br><span class="line">getline(is, s); <span class="comment">// 从is中读取一行到s</span></span><br><span class="line">s.empty();</span><br><span class="line">s.size();</span><br><span class="line">s[n];</span><br><span class="line">s1 + s2;</span><br><span class="line">&lt;, &lt;=, &gt;, &gt;=  <span class="comment">// 利用字符在字典中的顺序进行比较，大小写敏感</span></span><br></pre></td></tr></table></figure><h3 id="读写-string-对象"><a href="#读写-string-对象" class="headerlink" title="读写 string 对象"></a>读写 string 对象</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cin</span> &gt;&gt; s; <span class="comment">// 将 string 对象读入 s，遇到空白停止</span></span><br><span class="line"><span class="built_in">cin</span> &gt;&gt; s1 &gt;&gt; s2;   <span class="comment">// 把第一个输入到s1中，第二个输入到s2中</span></span><br></pre></td></tr></table></figure><h2 id="3-2-3-处理-string-对象中的字符"><a href="#3-2-3-处理-string-对象中的字符" class="headerlink" title="3.2.3 处理 string 对象中的字符"></a>3.2.3 处理 string 对象中的字符</h2><p>​    <strong>cctype头文件</strong>中定义了一组标准库函数来处理 string 对象中的字符。比如判断字符是否为数字、字母、控制字符、可打印字符、大写、小写、标点等，以及大小写转换。（p82）</p><h3 id="基于范围的-for-语句"><a href="#基于范围的-for-语句" class="headerlink" title="基于范围的 for 语句"></a>基于范围的 for 语句</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> (declaration: expression)  <span class="comment">// 跟python中 for declaration in expresson 类似</span></span><br><span class="line">    statement</span><br><span class="line"><span class="comment">// 举例    </span></span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">auto</span> c : str)</span><br><span class="line">    <span class="built_in">cout</span> &lt;&lt; c &lt;&lt; <span class="built_in">endl</span>;</span><br></pre></td></tr></table></figure><h3 id="使用范围-for-语句改变字符串中的字符"><a href="#使用范围-for-语句改变字符串中的字符" class="headerlink" title="使用范围 for 语句改变字符串中的字符"></a>使用范围 for 语句改变字符串中的字符</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> (<span class="keyword">auto</span> &amp;c : str)  <span class="comment">// c是一个引用，故赋值语句将改变s中字符的值</span></span><br><span class="line">    c = <span class="built_in">toupper</span>(c);</span><br></pre></td></tr></table></figure><h1 id="3-3-标准库类型-vector"><a href="#3-3-标准库类型-vector" class="headerlink" title="3.3 标准库类型 vector"></a>3.3 标准库类型 vector</h1><p>​    标准库类型 <strong>vector</strong> 表示对象的集合，其中所有对象的类型都相同。集合中每个对象都有一个与之对应的索引，索引用于访问对象。因为 vectot 容纳着其他对象，所以它也常被称作<strong>容器</strong>。</p><p>​    使用 vector：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta"># <span class="meta-keyword">include</span> <span class="meta-string">&lt;vector&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="built_in">std</span>::<span class="built_in">vector</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; ivec;  <span class="comment">// 定义一个能容纳int类型集合的对象</span></span><br><span class="line"><span class="built_in">vector</span>&lt;Sales_item&gt; Sales_vec;</span><br><span class="line"><span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="built_in">string</span>&gt;&gt; file;</span><br></pre></td></tr></table></figure><p>vector 能容纳绝大多数类型的对象作为其元素。</p><h2 id="3-3-1-定义和初始化-vector-对象"><a href="#3-3-1-定义和初始化-vector-对象" class="headerlink" title="3.3.1 定义和初始化 vector 对象"></a>3.3.1 定义和初始化 vector 对象</h2><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">vector</span>&lt;T&gt; v1;</span><br><span class="line"><span class="built_in">vector</span>&lt;T&gt; v2(v1);</span><br><span class="line"><span class="built_in">vector</span>&lt;T&gt; v3 = v1;</span><br><span class="line"><span class="built_in">vector</span>&lt;T&gt; v4(n, val);</span><br><span class="line"><span class="built_in">vector</span>&lt;T&gt; v5(n);</span><br><span class="line"><span class="built_in">vector</span>&lt;T&gt; v6&#123;a,b,c...&#125;;</span><br><span class="line"><span class="built_in">vector</span>&lt;T&gt; v7 = &#123;a,b,c...&#125;;</span><br></pre></td></tr></table></figure><h2 id="3-3-2-向-vector-对象中添加元素"><a href="#3-3-2-向-vector-对象中添加元素" class="headerlink" title="3.3.2 向 vector 对象中添加元素"></a>3.3.2 向 vector 对象中添加元素</h2><p>​    vector 的成员函数 <strong>push_back()</strong> 能将一个元素添加到 vector 的尾端。</p><h2 id="3-3-3-其他-vector-操作"><a href="#3-3-3-其他-vector-操作" class="headerlink" title="3.3.3 其他 vector 操作"></a>3.3.3 其他 vector 操作</h2><p>​    跟 string 差不多。</p><h1 id="3-4-迭代器介绍"><a href="#3-4-迭代器介绍" class="headerlink" title="3.4 迭代器介绍"></a>3.4 迭代器介绍</h1><p>​    <strong>迭代器</strong>能用于访问 string 对象和 vector 对象的元素，并且所有的标准库容器都能使用迭代器。使用迭代器能访问某个元素，迭代器也能从一个元素移动到另外一个元素。</p><h2 id="3-4-1-使用迭代器"><a href="#3-4-1-使用迭代器" class="headerlink" title="3.4.1 使用迭代器"></a>3.4.1 使用迭代器</h2><p>​    能使用迭代器的类型都拥有能返回迭代器的成员函数，比如 <strong>begin</strong> 和 <strong>end</strong>。其中 begin 成员负责指向第一个元素，end 成员则负责指向容器（或 string 对象）的”尾元素的下一个位置“的迭代器。end 成员返回的迭代器常被称为<strong>尾后迭代器</strong>。如果容器为空，则 begin 和 end 返回的是同一个元素。</p><h3 id="迭代器运算符"><a href="#迭代器运算符" class="headerlink" title="迭代器运算符"></a>迭代器运算符</h3><ul><li>*iter              返回迭代器iter所指元素的引用</li><li>iter-&gt;men  相当于(*iter).men</li><li>++iter           令 iter 指向容器下一个元素，同理有 —iter，iter + n，iter1 - iter2 等</li><li>iter1 &gt; iter2 比较位置关系，靠后的值大</li></ul><h3 id="迭代器类型"><a href="#迭代器类型" class="headerlink" title="迭代器类型"></a>迭代器类型</h3><p> 拥有迭代器迭代器的标准库类型使用 iterator 和 const_iterator 来表示迭代器的类型。<strong>const_iterator</strong> 和常量指针差不多，能读但不能修改所指元素的值，而 <strong>iterator</strong> 所指的对象可读可写。 如果容器对象是一个常量，则只能使用 const_iterator；否则两种类型都能使用。</p><h3 id="容器操作使迭代器失效"><a href="#容器操作使迭代器失效" class="headerlink" title="容器操作使迭代器失效"></a>容器操作使迭代器失效</h3><p>​    谨记，但凡是使用了迭代器的循环体，都不要向迭代器所属的容器添加元素。</p><h1 id="3-5-数组"><a href="#3-5-数组" class="headerlink" title="3.5 数组"></a>3.5 数组</h1><p>​    <strong>数组</strong> 是一种类似标准库类型 vector 的数据结构，与 vector 不同的是数组大小固定，不能随意向数组中增加元素。</p><h2 id="3-5-1-定义和初始化内置数组"><a href="#3-5-1-定义和初始化内置数组" class="headerlink" title="3.5.1 定义和初始化内置数组"></a>3.5.1 定义和初始化内置数组</h2><h3 id="显式初始化数组元素"><a href="#显式初始化数组元素" class="headerlink" title="显式初始化数组元素"></a>显式初始化数组元素</h3><p>​    如果声明时没有指明维度，编译器会根据初始值的数量计算并推断出来；如果指明了维度，那么初始值的总数量不应该超出指定的大小。</p><h3 id="字符数组的特殊性"><a href="#字符数组的特殊性" class="headerlink" title="字符数组的特殊性"></a>字符数组的特殊性</h3><p>​    当使用字符串字面值初始化字符数组时，一定要注意字符串字面值的结尾处还有一个隐藏的空字符，这个空字符也会像字符串的其它字符一样被拷贝到数组里去。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">char</span> a1[<span class="number">3</span>] = &#123;<span class="string">'c'</span>, <span class="string">'p'</span>, <span class="string">'p'</span>&#125;;  <span class="comment">// 正确</span></span><br><span class="line"><span class="keyword">char</span> a2[<span class="number">4</span>] = <span class="string">"cpp"</span>;            <span class="comment">// 正确</span></span><br><span class="line"><span class="keyword">char</span> a3[<span class="number">3</span>] = <span class="string">"cpp"</span>;            <span class="comment">// 错误</span></span><br></pre></td></tr></table></figure><h3 id="理解复杂的数组声明"><a href="#理解复杂的数组声明" class="headerlink" title="理解复杂的数组声明"></a>理解复杂的数组声明</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> *ptrs[<span class="number">10</span>];                  <span class="comment">// ptrs是含有10个整型指针的数组</span></span><br><span class="line"><span class="keyword">int</span> &amp;refs[<span class="number">10</span>] = <span class="comment">/*?*/</span>;          <span class="comment">// 错误：不存在引用的数组</span></span><br><span class="line"><span class="keyword">int</span> (*Parray)[<span class="number">10</span>];              <span class="comment">// Parray指向一个整型数组</span></span><br><span class="line"><span class="keyword">int</span> (&amp;arrRef)[<span class="number">10</span>];              <span class="comment">// arrRef引用一个整型数组</span></span><br></pre></td></tr></table></figure><h2 id="3-5-3-指针和数组"><a href="#3-5-3-指针和数组" class="headerlink" title="3.5.3 指针和数组"></a>3.5.3 指针和数组</h2><p>​    数组类型的对象其实是一个指向该数组首元素的指针。该指针也是一个迭代器。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;3-1-命名空间的-using-声明&quot;&gt;&lt;a href=&quot;#3-1-命名空间的-using-声明&quot; class=&quot;headerlink&quot; title=&quot;3.1 命名空间的 using 声明&quot;&gt;&lt;/a&gt;3.1 命名空间的 using 声明&lt;/h1&gt;&lt;p&gt;​    &lt;
      
    
    </summary>
    
      <category term="C++" scheme="http://a-kali.github.io/categories/C/"/>
    
    
      <category term="C++" scheme="http://a-kali.github.io/tags/C/"/>
    
  </entry>
  
  <entry>
    <title>Kaggle 比赛记录之 SIIM-ACR Pneumothorax Segmentation</title>
    <link href="http://a-kali.github.io/2019/08/21/SIIM%E6%AF%94%E8%B5%9B%E4%B8%AD%E9%81%87%E5%88%B0%E7%9A%84%E7%9F%A5%E8%AF%86%E7%9B%B2%E5%8C%BA/"/>
    <id>http://a-kali.github.io/2019/08/21/SIIM比赛中遇到的知识盲区/</id>
    <published>2019-08-21T14:23:24.000Z</published>
    <updated>2019-09-12T12:35:10.317Z</updated>
    
    <content type="html"><![CDATA[<h1 id="记事"><a href="#记事" class="headerlink" title="记事"></a>记事</h1><p>​    随着 <a href="https://www.kaggle.com/c/siim-acr-pneumothorax-segmentation" target="_blank" rel="noopener">Kaggle: SIIM-ACR Pneumothorax Segmentation</a> 接近尾声，我感觉有必要写一篇 blog 来记录一下这两个月的比赛经历，顺便总结一下经验。</p><p>​    刚开始的时候想着这不过是一场普通CV类的比赛而已，肝一肝就能上金牌。但现实狠狠地打了我的脸。最初三天看了看比赛规则，了解了下RLE等语义分割的基本概念，看了看各路大佬的EDA，算是入了个小门。随后就一直沉沦在MMDetection和COCO格式的配置中，由于网上资料太少太旧，导致我花了整整15天才把程序跑通orz，还是在各路大神的帮助下。详情可参考另一篇博客：<a href="https://a-kali.github.io/2019/08/04/%E4%BD%BF%E7%94%A8MMDetection%E8%BF%9B%E8%A1%8C%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2/#more">使用MMDetection进行语义分割</a>。最后出的结果也非常地不尽人意，分数才 0.6+，而把所有预测结果全填上 -1 都有 0.78 分，着实难搞&#x1F611;。</p><p>​    中间一个月基本在走亲访友旅游摸鱼，直到八月中旬回学校，才重回赛场，放弃了MMDetection，找了个比较高分的<a href="https://www.kaggle.com/rishabhiitbhu/unet-with-resnet34-encoder-pytorch" target="_blank" rel="noopener">PyTorch baseline</a>，开始调参，也算是为这场比赛正式拉开了序幕（虽然只剩半个月了）。</p><p>Baseline细节：</p><ul><li>网络模型：UNet + ResNet34，使用imagenet进行预训练</li><li>输入图片尺寸：512 * 512 （为了更加贴近模型预训练时使用的图片尺寸）</li><li>训练集：验证集 = 4：1，使用 sklearn 中的 StratifiedKFold 进行五折划分</li><li>在验证集和训练集中，正负样本数量1：1</li><li>学习率策略：ReduceLROnPlateau</li><li>Loss：Focal Loss &amp; Dice Loss</li><li>优化器：Adam</li><li>最优模型选择：根据Loss的值进行选择，loss越小模型越优</li><li>生成结果时，单个分割区域的最少像素数：min_size == 3500</li><li>输出：1024*1024 的概率矩阵（因为原数据图像大小是 1024*1024），每个元素对应像素点属于 mask 的概率。最后用一个 sigmoid 函数生成 mask</li></ul><p>虽然是个分数挺高的 baseline，但还是有一些瑕疵：</p><ul><li>某行代码的 ‘!=’ 写成了 ‘==’</li><li>Trainer 类里的部分属性与下面传入函数的参数不是同一个变量，导致改了属性后传入的参数依然没改</li><li>验证时没有加 with torch.no_grad() 导致显存溢出</li><li>对数据去重的时候把单图多分割区域给删成了单图单分割区域</li></ul><p>改完上述问题后单 resnet34 分数能上 0.84+。</p><p>​    改完 bug 后第一步，把模型换成 SENet154 &#x1F60F;，单折 0.855 左右，好像海星的亚子。</p><p>​    随后又测了 SE_ReNeXt101、EfficientUNet_B5、DPN131、DenseNet201、DenseNet121等模型，但只有 EfficientUNet_B5 能跟 SENet154 不相上下，而其他模型基本跟 ResNet34 差不多。</p><p>​    对 SENet154 进行五折交叉验证，分数提高到 0.863。</p><p>​    对 EfficientUNet_B5、ResNet34、SENet154 三模型进行等比例融合、min_size == 3000，分数提高到 0.869。同时 EfficientUNet_B5、SENet154 双模型 、min_size == 2800，分数提高到 0.868。</p><p>​    使用 EfficientNet 单独进行二分类，将二分类中的负样本对应的预测样本替换成负样本，结果不理想，大概多模型融合后的分类能力已经很强了。</p><p>​    对 EfficientUNet_B5、ResNet34、SENet154、SE_ReNeXt101 四模型按 3:2:3:2 的比例进行融合，min_size == 3000，分数提高到 0.8694。</p><p>​    与此同时的另一边使用了 chexnet 进行二分类，将二分类的正样本对应的三模型预测样本的min_size降低到2500，负样本保持3000，将三模型的分数也提升到了 0.8694 。在 public leaderboard 排行60名，位于银牌区。</p><p>​    可是离金牌还有 0.01 分的差距，光是这样调参怕是很难上金牌&#x1F62A;  —— 2019.8.28</p><p>​    比赛进入第二阶段，更换了测试集。以新测试集的 1% 数据的成绩作为公榜成绩，剩下 99% 作为最终成绩。—— 2019.8.31</p><h1 id="盲区"><a href="#盲区" class="headerlink" title="盲区"></a>盲区</h1><p>FocalLoss和diceLoss的实现细节和应用场景</p><p>Unet、Unet++、FastRCNN、MaskRCNN、FPN、DCN、Cascade、SENet、efficientNet的技术细节</p><p>学习率的相关优化算法及应用场景，如ReduceLROnPlateau、warm up</p><p>threshold的调整策略</p><p>PyTorch实战经验不足，baseline的自主编写</p><p>新兴模型复现</p><h1 id="疑问"><a href="#疑问" class="headerlink" title="疑问"></a>疑问</h1><ul><li><p>Q：为什么将训练集中的正负样本划为1：1能提高分数？</p><p>A：能避免模型分类时倾向某一方，减少在分类时出现的错误。</p></li><li><p>Q：代码中最佳模型的评判标准为什么不是iOU而是loss？</p><p>A：因为比赛分数的评判标准是Dice Loss</p></li><li><p>Q：每次五折验证的选择是否相同？</p><p>A：是。StratifiedKFold在随机种子不变的情况下，每次五折交叉验证选择的样本都是相同的。</p></li></ul><h1 id="改进"><a href="#改进" class="headerlink" title="改进"></a>改进</h1><p>下次比赛一定要记录每个模型提交的参数、文件和分数啊啊啊啊，不然最后多模型融合的时候不知道如何分配权重</p><p>通过对比两份分数的高低和csv的差别，是否能确定哪些预测是对的（好像有点场外）</p><p>下次比赛要从头跟到尾，这样能尝试到更多的tips和参数</p><h1 id="高分-Solution"><a href="#高分-Solution" class="headerlink" title="高分 Solution"></a>高分 Solution</h1><h2 id="1st-place-solution"><a href="#1st-place-solution" class="headerlink" title="1st place solution"></a><a href="https://www.kaggle.com/c/siim-acr-pneumothorax-segmentation/discussion/107824" target="_blank" rel="noopener">1st place solution</a></h2><h2 id="2rd-place-solution"><a href="#2rd-place-solution" class="headerlink" title="2rd place solution"></a><a href="https://www.kaggle.com/c/siim-acr-pneumothorax-segmentation/discussion/108009#latest-622580" target="_blank" rel="noopener">2rd place solution</a></h2><h2 id="3rd-place-solution"><a href="#3rd-place-solution" class="headerlink" title="3rd place solution"></a><a href="https://www.kaggle.com/c/siim-acr-pneumothorax-segmentation/discussion/108009#latest-622580" target="_blank" rel="noopener">3rd place solution</a></h2><h2 id="4th-place-solution"><a href="#4th-place-solution" class="headerlink" title="4th place solution"></a><a href="https://www.kaggle.com/c/siim-acr-pneumothorax-segmentation/discussion/108397#latest-624615" target="_blank" rel="noopener">4th place solution</a></h2><h2 id="5th-place-solution"><a href="#5th-place-solution" class="headerlink" title="5th place solution"></a><a href="https://www.kaggle.com/c/siim-acr-pneumothorax-segmentation/discussion/107603#latest-620358" target="_blank" rel="noopener">5th place solution</a></h2><ul><li>基于半监督学习，在网络添加了二分类器。</li><li>网络模型：带有 ASPP 结构的 UNet（ASPP 为 DeepLabV3+中的一种结构）</li><li>Backbone：se50 &amp; se101</li><li>图片尺寸：1024*1024</li><li>优化器：Adam</li><li>损失函数：1024 * BCE(results, masks) + BCE(cls, cls_target)</li><li>半监督学习：mean-teacher[1-2] with NIH Dataset </li></ul><p>mean-teacher 参考资料：</p><p>[1] <a href="https://github.com/CuriousAI/mean-teacher" target="_blank" rel="noopener">https://github.com/CuriousAI/mean-teacher</a><br>[2] <a href="https://arxiv.org/pdf/1703.01780.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1703.01780.pdf</a></p><h2 id="6th-place-solution"><a href="#6th-place-solution" class="headerlink" title="6th place solution"></a><a href="https://www.kaggle.com/c/siim-acr-pneumothorax-segmentation/discussion/107743#latest-620263" target="_blank" rel="noopener">6th place solution</a></h2><ul><li>网络模型<ul><li>EncodingNet (ResNets, 512 and 1024 size)</li><li>UNet (EfficientNet4, se-resnext50, SENet154 with 512, 640 and 1024 sizes)</li></ul></li><li>数据增强：Crops 和 Rotations 类型的增强</li><li>损失函数：BCE + Dice （表示FocalLoss不太好用）</li><li>比起原始尺寸的图像，小尺寸图像会少很多分</li><li>Tricks：<ul><li>在 EncodingNet 使用了 11 种 TTA</li><li>删除了预测结果种面积小的mask</li></ul></li></ul><h2 id="8th-place-solution"><a href="#8th-place-solution" class="headerlink" title="8th place solution"></a><a href="https://www.kaggle.com/c/siim-acr-pneumothorax-segmentation/discussion/107522#latest-619268" target="_blank" rel="noopener">8th place solution</a></h2><ul><li>数据分割：10%分出来用于融合(ensemble)，在剩下90%的数据里进行十折交叉验证</li><li>模型架构：DeepLabV3</li><li>Backbone：使用了组归一化的ResNet50/101 和 ResNeXt50/101</li><li>损失函数：BCE（在所有图像上训练）或者 Dice（只在正样本上训练）</li><li>优化器：Vanilla SGD, momentum 0.9</li><li>训练：<ul><li>batch size 4, 1024 x 1024</li><li>batch size 1, 1280 x 1280</li></ul></li><li>学习率策略：余弦退火，LR 0.01-0.0001</li><li>模型融合：<ul><li>4 个模型使用 Dice 损失函数，在正样本上训练</li><li>8 个模型使用 BCE 损失函数，在所有样本上训练。其中四个作为分类器使用</li><li>Max pixel value was taken as classification score, averaged across 4 models</li><li>Multiplied pixel-level scores from 4 models trained on positives only by this classification score, then averaged</li><li>Final ensemble: multiplied score as above averaged with pixel-level scores based on other 4/8 models trained on all images</li></ul></li><li>TTA：Hflip</li><li>后处理：删除了大小小于2048像素的mask（stage2），stage1中为4096像素</li></ul><p>没起到效果的工作：</p><ul><li>使用了Unet, LinkNet, PSPNet, EncNet, HRNet等架构，但效果没有DeepLab好</li><li>SGD 的效果比 Adam, Adabound 优化器的效果更好</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;记事&quot;&gt;&lt;a href=&quot;#记事&quot; class=&quot;headerlink&quot; title=&quot;记事&quot;&gt;&lt;/a&gt;记事&lt;/h1&gt;&lt;p&gt;​    随着 &lt;a href=&quot;https://www.kaggle.com/c/siim-acr-pneumothorax-segmen
      
    
    </summary>
    
      <category term="计算机视觉" scheme="http://a-kali.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/"/>
    
    
      <category term="计算机视觉" scheme="http://a-kali.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/"/>
    
      <category term="语义分割" scheme="http://a-kali.github.io/tags/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2/"/>
    
      <category term="Kaggle" scheme="http://a-kali.github.io/tags/Kaggle/"/>
    
      <category term="PyTorch" scheme="http://a-kali.github.io/tags/PyTorch/"/>
    
  </entry>
  
  <entry>
    <title>《C++ Primer》 第2章 变量和基本类型</title>
    <link href="http://a-kali.github.io/2019/08/20/%E3%80%8AC-Primer%E3%80%8B-%E7%AC%AC2%E7%AB%A0-%E5%8F%98%E9%87%8F%E5%92%8C%E5%9F%BA%E6%9C%AC%E7%B1%BB%E5%9E%8B/"/>
    <id>http://a-kali.github.io/2019/08/20/《C-Primer》-第2章-变量和基本类型/</id>
    <published>2019-08-20T12:41:12.000Z</published>
    <updated>2019-08-27T15:50:13.718Z</updated>
    
    <content type="html"><![CDATA[<p>数据类型决定了程序中数据和操作的意义。</p><h1 id="2-1-基本内置类型"><a href="#2-1-基本内置类型" class="headerlink" title="2.1 基本内置类型"></a>2.1 基本内置类型</h1><h2 id="2-1-1-算术类型"><a href="#2-1-1-算术类型" class="headerlink" title="2.1.1 算术类型"></a>2.1.1 算术类型</h2><p>​    算术类型分为两类：<strong>整型</strong>（包括字符和布尔型在内）和<strong>浮点型</strong>。</p><h3 id="带符号类型和无符号类型"><a href="#带符号类型和无符号类型" class="headerlink" title="带符号类型和无符号类型"></a>带符号类型和无符号类型</h3><p>​    除去布尔型和扩展的字符型之外，其他整形可以划分为<strong>带符号的</strong>（signed）和<strong>无符号的</strong>（unsigned）。带符号类型可以表示正数、负数或0，而无符号类型则仅能表示大于等于0的值。</p><p>​    类型 int、short、long 和 long long 都是带符号的，通过在这些类型名前添加<strong>unsigned</strong> 就可以得到无符号类型。其中 unsigned int 可以缩写为 unsigned。</p><p>​    与其他整型不同，<strong>字符型</strong>被分为了三种：char、signed char 和 unsigned char。但字符型的表现形式只有两种：带符号型和无符号型，char 的实际表现为哪种又编译器决定。</p><p>​    无符号类型中所有的比特都用来存储值。</p><h2 id="2-1-2-类型转换"><a href="#2-1-2-类型转换" class="headerlink" title="2.1.2 类型转换"></a>2.1.2 类型转换</h2><p>类型所能表示的值的范围决定了转换的过程：</p><ul><li>非布尔 → 布尔：除 0 以外均为 true。</li><li>布尔 → 非布尔：false → 0，true → 1。</li><li>浮点数 → 整数：保留小数点前的部分。</li><li>给无符号数赋值超范围：结果为取模后的余数。</li></ul><h3 id="含有无符号类型的表达式"><a href="#含有无符号类型的表达式" class="headerlink" title="含有无符号类型的表达式"></a>含有无符号类型的表达式</h3><p>​    当一个表达式中既有无符号数又有 int 值时，那个 int 值就会转换成无符号数。若 int 值为负数，则相当于将负数赋值给一个无符号数并运算，会产生意料之外的结果。</p><h2 id="2-1-3-字面值常量"><a href="#2-1-3-字面值常量" class="headerlink" title="2.1.3 字面值常量"></a>2.1.3 字面值常量</h2><p>​    每个字面值常量都对应着一种数据类型，字面值常量的形式和值决定了它的数据类型。</p><h3 id="整型和浮点型字面值"><a href="#整型和浮点型字面值" class="headerlink" title="整型和浮点型字面值"></a>整型和浮点型字面值</h3><p>​    我们可以将<strong>整型字面值</strong>写作十进制数、八进制数和十六进制数的形式。以 0 开头的整数代表八进制数，以 0x 或0X 开头的代表十六进制数。</p><p>​    整型字面值具体的数据类型由它的值和符号决定。默认情况下，十进制字面值的类型是能容纳当前值的最小带符号数类型，而八进制和十六进制字面值既可能是带符号的也可能是无符号的。</p><p>​    <strong>浮点型字面值</strong>表现为一个小数或以科学记数法表示的指数，默认类型为double。</p><h3 id="字符和字符串字面值"><a href="#字符和字符串字面值" class="headerlink" title="字符和字符串字面值"></a>字符和字符串字面值</h3><p>​    由单引号括起来的一个字符称为<strong>字符型字面值</strong>，双引号括起来的零个或多个字符则构成<strong>字符串型字面值</strong>。</p><p>​    字符串字面值的类型实际上是由常量字符构成的数组，编译器在每个字符串的结尾添加一个空字符（’\0’），因此字面值实际长度比它的内容多 1。</p><h3 id="布尔字面值和指针字面值"><a href="#布尔字面值和指针字面值" class="headerlink" title="布尔字面值和指针字面值"></a>布尔字面值和指针字面值</h3><p>​    true 和 false 是<strong>布尔类型的字面值</strong>。</p><h1 id="2-2-变量"><a href="#2-2-变量" class="headerlink" title="2.2 变量"></a>2.2 变量</h1><p>​    <strong>变量</strong>提供一个具名的、可供程序操作的存储空间。C++ 中每个变量都有其数据类型，数据类型决定变量所占内存空间的大小和布局方式等。对 C++ 程序员来说，“变量”和“对象”一般可以互换使用。</p><h2 id="2-2-1-变量定义"><a href="#2-2-1-变量定义" class="headerlink" title="2.2.1 变量定义"></a>2.2.1 变量定义</h2><h3 id="初始值"><a href="#初始值" class="headerlink" title="初始值"></a>初始值</h3><p>​    当对象在创建时获得了一个特定的值，我们说这个对象被<strong>初始化</strong>了。初始化不等同于赋值，赋值的含义是把对象的当前值擦除，以一个新的值替代。</p><h3 id="列表初始化"><a href="#列表初始化" class="headerlink" title="列表初始化"></a>列表初始化</h3><p>初始化问题复杂性，e.g. 定义一个名为 sold 的 int 变量并初始化为 0，以下代码均可实现：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> sold = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">int</span> sold = &#123;<span class="number">0</span>&#125;;</span><br><span class="line"><span class="keyword">int</span> sold&#123;<span class="number">0</span>&#125;;</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">sold</span><span class="params">(<span class="number">0</span>)</span></span>;</span><br></pre></td></tr></table></figure><p>用花括号来初始化变量的形式被称为<strong>列表初始化</strong>。</p><h2 id="2-2-2-变量声明和定义的关系"><a href="#2-2-2-变量声明和定义的关系" class="headerlink" title="2.2.2 变量声明和定义的关系"></a>2.2.2 变量声明和定义的关系</h2><p>​    为了允许把程序拆分成多个逻辑部分来编写，C++语言支持<strong>分离式编译</strong>机制，该机制允许将程序分割为若干个文件，每个文件可被独立编译。</p><p>​    为了支持分离式编译，C++将声明和定义区分开来。<strong>声明</strong>使得名字为程序所知，<font color="red">一个文件如果想使用别处定义的名字则必须包含对那个名字的声明</font>。而<strong>定义</strong>负责创建与名字关联的实体。声明和定义都规定了变量的类型和名字，而并以还包括了申请空间，也可能会为变量赋予初始值。</p><p>​    如果想声明一个变量而非定义，就在变量名前添加<strong>关键字extern</strong>，而且不要显示地初始化变量：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">extern</span> <span class="keyword">int</span> i; <span class="comment">// 声明i而非定义i</span></span><br><span class="line"><span class="keyword">int</span> j;        <span class="comment">// 声明并定义j</span></span><br></pre></td></tr></table></figure><p>​    变量只能被定义一次，但可以被多次声明。如果要在多个文件中使用同一个变量，就必须将声明和定义分离。此时变量的定义必须且只能出现在一个文件中，而其他用到该变量的文件必须且只能对其声明。</p><h1 id="2-3-复合类型"><a href="#2-3-复合类型" class="headerlink" title="2.3 复合类型"></a>2.3 复合类型</h1><p>​    <strong>复合类型</strong>是指基于其他类型定义的类型，其中两种为引用和指针。</p><h2 id="2-3-1-引用"><a href="#2-3-1-引用" class="headerlink" title="2.3.1 引用"></a>2.3.1 引用</h2><p>​    <strong>引用</strong>为对象起了另一个名字，引用类型引用另外一种类型。通过将声明符写成&amp;d的形式来定义引用类型，其中d是声明时的变量名：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> ival = <span class="number">1024</span>;     <span class="comment">// 声明了变量名为ival</span></span><br><span class="line"><span class="keyword">int</span> &amp;refVal = ival;  <span class="comment">// 此时refVal成了该变量的第二个名字</span></span><br></pre></td></tr></table></figure><h2 id="2-3-2-指针"><a href="#2-3-2-指针" class="headerlink" title="2.3.2 指针"></a>2.3.2 指针</h2><p>​    <strong>指针</strong>时“指向”另外一种类型的复合类型。定义指针类型的方法将声明符写成 *d 的形式，其中 d 是变量名。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> ip1, *ip2; <span class="comment">//ip1是int型对象，ip2是指向一个int型对象的指针</span></span><br></pre></td></tr></table></figure><h3 id="获取对象的地址"><a href="#获取对象的地址" class="headerlink" title="获取对象的地址"></a>获取对象的地址</h3><p>​    指针存放某个对象的地址，要想获取该地址，需要使用<strong>取地址符（&amp;）</strong>。</p><h3 id="利用指针访问对象"><a href="#利用指针访问对象" class="headerlink" title="利用指针访问对象"></a>利用指针访问对象</h3><p>​    如果指针指向了一个对象，则允许使用<strong>解引用符（*）</strong>来访问该对象。</p><hr><p>Note：引用声明符&amp;、指针声明符*、取地址操作符&amp;、解引用符* 所代表的含义各不相同。</p><hr><h3 id="空指针"><a href="#空指针" class="headerlink" title="空指针"></a>空指针</h3><p>​    <strong>空指针</strong>不指向任何对象，在试图使用一个空指针之前代码可以首先检查它是否为空。以下是三种等价的生成空指针的方法：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> *p1 = <span class="literal">nullptr</span>;</span><br><span class="line"><span class="keyword">int</span> *p2 = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">int</span> *p3 = <span class="literal">NULL</span>;</span><br></pre></td></tr></table></figure><h3 id="void-指针"><a href="#void-指针" class="headerlink" title="void* 指针"></a>void* 指针</h3><p>​    <strong>void*</strong>指针可用于存放任意对象的地址。但由于我们并不知道这个对象到底是什么类型，也就无法确定能在这个对象上做哪些操作，故不能直接操作void*指针所指的对象。</p><h2 id="2-3-3-理解复合类型的声明"><a href="#2-3-3-理解复合类型的声明" class="headerlink" title="2.3.3 理解复合类型的声明"></a>2.3.3 理解复合类型的声明</h2><p>​    类型修饰符仅仅只是在声明时修饰了变量，并不能作为类型的一部分，且对与该声明语句中的其他变量不产生任何作用。</p><p>​    声明语句中的修饰符没有个数限制。</p><h1 id="2-4-const-限定符"><a href="#2-4-const-限定符" class="headerlink" title="2.4 const 限定符"></a>2.4 const 限定符</h1><p>​    关键字<strong>const</strong>可以对变量的类型加以限定，使得被限定的变量的值在定义之后不能再改变。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> <span class="keyword">int</span> bufSize = <span class="number">512</span></span><br></pre></td></tr></table></figure><p>因为const对象一旦创建后其值就不能再改变，所以const对象必须被初始化。</p><h3 id="对const的引用可能引用一个并非const的对象"><a href="#对const的引用可能引用一个并非const的对象" class="headerlink" title="对const的引用可能引用一个并非const的对象"></a>对const的引用可能引用一个并非const的对象</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> i = <span class="number">42</span>;</span><br><span class="line"><span class="keyword">int</span> &amp;r1 = i;</span><br><span class="line"><span class="keyword">const</span> <span class="keyword">int</span> &amp;r2 = i;</span><br><span class="line">r1 = <span class="number">0</span>;  <span class="comment">// 可以通过r1修改i的值</span></span><br><span class="line">r2 = <span class="number">0</span>;  <span class="comment">// 错误；不能通过r2修改i的值</span></span><br></pre></td></tr></table></figure><h2 id="2-4-3-顶层const"><a href="#2-4-3-顶层const" class="headerlink" title="2.4.3 顶层const"></a>2.4.3 顶层const</h2><p>​    用名词<strong>顶层const</strong>表示指针本身是个常量，而<strong>底层const</strong>表示指针所指的对象是一个常量。当执行对象的拷贝操作时，拷入和拷出的对象必须具有相同的底层const资格，或者两个对象的数据类型必须能够转换。（待考究，p58）</p><h2 id="2-4-4-constexpr-和常量表达式"><a href="#2-4-4-constexpr-和常量表达式" class="headerlink" title="2.4.4 constexpr 和常量表达式"></a>2.4.4 constexpr 和常量表达式</h2><p>​    <strong>常量表达式</strong>是指值不会改变并且在编译过程就能得到计算结果的表达式。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> <span class="keyword">int</span> max_files = <span class="number">20</span>; <span class="comment">// 常量表达式</span></span><br><span class="line"><span class="keyword">int</span> staff_size = <span class="number">28</span>; <span class="comment">// 不是常量表达式</span></span><br><span class="line"><span class="keyword">const</span> <span class="keyword">int</span> sz = get_size(); <span class="comment">// 不是常量表达式，因为要在运行时才能获取到</span></span><br></pre></td></tr></table></figure><h3 id="constexpr-变量"><a href="#constexpr-变量" class="headerlink" title="constexpr 变量"></a>constexpr 变量</h3><p>​    C++11 新标准规定，允许将变量声明为<strong>constexpr</strong>类型以便由编译器来验证变量的值是否是一个常量表达式。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">constexpr</span> <span class="keyword">int</span> sz = size(); <span class="comment">// 只有当size()是一个constexpr函数时才是一条正确的语句</span></span><br></pre></td></tr></table></figure><h3 id="字面值类型"><a href="#字面值类型" class="headerlink" title="字面值类型"></a>字面值类型</h3><h1 id="2-5-处理类型"><a href="#2-5-处理类型" class="headerlink" title="2.5 处理类型"></a>2.5 处理类型</h1><h2 id="2-5-1-类型别名"><a href="#2-5-1-类型别名" class="headerlink" title="2.5.1 类型别名"></a>2.5.1 类型别名</h2><p>​    <strong>类型别名</strong>是一个名字，它是某种类型的同义词。使用类型别名能让复杂的类型名变得简单明了、易于理解和使用。</p><p>​    有两种方法可用于定义类型别名。分别是是使用<strong>关键字 typedef</strong>和<strong>别名声明using</strong>：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="keyword">double</span> wage;</span><br><span class="line"></span><br><span class="line"><span class="keyword">using</span> SI = Sale_item;</span><br></pre></td></tr></table></figure><h2 id="2-5-2-auto-类型说明符"><a href="#2-5-2-auto-类型说明符" class="headerlink" title="2.5.2 auto 类型说明符"></a>2.5.2 auto 类型说明符</h2><p>​    <strong>auto</strong>类型说明符能让编译器替我们去分析表达式所属的类型。</p><h2 id="2-5-3-decltype-类型指示符"><a href="#2-5-3-decltype-类型指示符" class="headerlink" title="2.5.3 decltype 类型指示符"></a>2.5.3 decltype 类型指示符</h2><p>​    类型说明符<strong>decltype</strong>能从表达式的类型推断出要定义的变量的类型，但不使用该表达式的值初始化变量。其作用是选择并返回操作数的数据类型。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">decltype</span>(f()) sum = x; <span class="comment">// 使用f()的返回类型初始化sum变量，而不使用f()的值</span></span><br></pre></td></tr></table></figure><h1 id="2-6-自定义数据结构"><a href="#2-6-自定义数据结构" class="headerlink" title="2.6 自定义数据结构"></a>2.6 自定义数据结构</h1><h2 id="2-6-1-定义-Sales-data-类型"><a href="#2-6-1-定义-Sales-data-类型" class="headerlink" title="2.6.1 定义 Sales_data 类型"></a>2.6.1 定义 Sales_data 类型</h2><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">Sales_data</span> &#123;</span>          <span class="comment">// 关键字struct + 类名</span></span><br><span class="line">    <span class="built_in">std</span>::<span class="built_in">string</span> bookNo;      <span class="comment">// 数据成员</span></span><br><span class="line">    <span class="keyword">unsigned</span> units_sold = <span class="number">0</span>; <span class="comment">// 类内初始值</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="2-6-2-使用-Sales-data-类"><a href="#2-6-2-使用-Sales-data-类" class="headerlink" title="2.6.2 使用 Sales_data 类"></a>2.6.2 使用 Sales_data 类</h2><h3 id="添加-Sales-data-对象"><a href="#添加-Sales-data-对象" class="headerlink" title="添加 Sales_data 对象"></a>添加 Sales_data 对象</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Sales_data data1;</span><br></pre></td></tr></table></figure><h3 id="Sales-data-对象读入数据"><a href="#Sales-data-对象读入数据" class="headerlink" title="Sales_data 对象读入数据"></a>Sales_data 对象读入数据</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">std</span>::<span class="built_in">cin</span> &gt;&gt; data1.bookNO &gt;&gt; data1.units_sold &gt;&gt; price;</span><br></pre></td></tr></table></figure><h2 id="2-6-3-编写自己的头文件"><a href="#2-6-3-编写自己的头文件" class="headerlink" title="2.6.3 编写自己的头文件"></a>2.6.3 编写自己的头文件</h2><p>​    为了确保哥哥文件中类的定义一致，类通常被定义在头文件中，而且类所在头文件的名字应与类的名字一样。头文件通常包含那些被定义一次的实体，如类、const 和 constexpr 变量。</p><h3 id="预处理器概述"><a href="#预处理器概述" class="headerlink" title="预处理器概述"></a>预处理器概述</h3><p>​    <strong>预处理器</strong>是在编译之前执行的一段程序，可以部分地改变我们所写的程序。能确保头文件多次包含仍能安全工作。之前用到的一项预处理器功能是#include。</p><p>​    C++用到的另一项与处理功能是<strong>头文件保护符</strong>，头文件保护符依赖于<strong>预处理变量</strong>。预处理变量有两种状态：已定义和未定义。<strong>#define</strong> 指令把一个名字设定为预处理变量，<strong>#ifdef</strong> 当且仅当变量已经定义是为真，<strong>#ifndef</strong> 仅当变量未定义时为真。检查结果为真时，执行后续操作直至遇到<strong>#endif</strong> 指令为止。</p><p>​    以下代码说明了这些功能如何有效防止重复包含：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">ifndef</span> SALES_DATA_H  <span class="comment">// 如果没有定义SALES_DATA_H预处理变量，则执行以下语句</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> SALES_DATA_H  <span class="comment">// 定义SALES_DATA_H预处理变量</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> Sales_data</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">Sales_data</span> &#123;</span></span><br><span class="line">    <span class="built_in">std</span>::<span class="built_in">string</span> bookNo;</span><br><span class="line">    <span class="keyword">unsigned</span> units_sold = <span class="number">0</span>; </span><br><span class="line">&#125;;</span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br></pre></td></tr></table></figure><p>第一次包含该文件时，SALES_DATA_H 未定义，预处理器顺序执行代码。再次被包含时 SALES_DATA_H 已定义，<code>#ifndef SALES_DATA_H</code> 检查结果为假，编译器将跳过中间语句。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;数据类型决定了程序中数据和操作的意义。&lt;/p&gt;
&lt;h1 id=&quot;2-1-基本内置类型&quot;&gt;&lt;a href=&quot;#2-1-基本内置类型&quot; class=&quot;headerlink&quot; title=&quot;2.1 基本内置类型&quot;&gt;&lt;/a&gt;2.1 基本内置类型&lt;/h1&gt;&lt;h2 id=&quot;2-1-1-
      
    
    </summary>
    
      <category term="C++" scheme="http://a-kali.github.io/categories/C/"/>
    
    
      <category term="C++" scheme="http://a-kali.github.io/tags/C/"/>
    
  </entry>
  
  <entry>
    <title>《C++ Primer》 第1章 开始</title>
    <link href="http://a-kali.github.io/2019/08/19/%E3%80%8AC-Primer%E3%80%8B-%E7%AC%AC1%E7%AB%A0-%E5%BC%80%E5%A7%8B/"/>
    <id>http://a-kali.github.io/2019/08/19/《C-Primer》-第1章-开始/</id>
    <published>2019-08-19T13:36:16.000Z</published>
    <updated>2019-08-19T15:34:41.869Z</updated>
    
    <content type="html"><![CDATA[<h1 id="1-1-编写一个简单的C-程序"><a href="#1-1-编写一个简单的C-程序" class="headerlink" title="1.1 编写一个简单的C++程序"></a>1.1 编写一个简单的C++程序</h1><h2 id="1-1-1-编译、运行程序"><a href="#1-1-1-编译、运行程序" class="headerlink" title="1.1.1 编译、运行程序"></a>1.1.1 编译、运行程序</h2><p>​    术语：<strong>集成开发环境</strong>（Integrated Developed Environment, IDE）</p><h3 id="源程序文件命名约定"><a href="#源程序文件命名约定" class="headerlink" title="源程序文件命名约定"></a>源程序文件命名约定</h3><p>​    大多数编译器要求源码存储在一个或多个文件中，这些程序文件通常被称为<strong>源文件</strong>。常见C++程序源文件后缀有：<strong>cc、cxx、cpp、cp、C</strong>。</p><h3 id="从命令行运行编译器"><a href="#从命令行运行编译器" class="headerlink" title="从命令行运行编译器"></a>从命令行运行编译器</h3><p>​    <code>$ CC prog1.cc</code></p><p>​    其中CC是编译器的名字。编译器生成一个可执行文件。Windows系统将这个可执行文件命名为<strong>prog1.exe</strong>。UNIX系统常命名为<strong>a.out</strong>。</p><h1 id="1-2-初识输入输出"><a href="#1-2-初识输入输出" class="headerlink" title="1.2 初识输入输出"></a>1.2 初识输入输出</h1><p>​    C++语言常用<strong>标准库</strong>来提供IO机制。同时本书中很多示例使用了<strong>iostream库</strong>。该库包含两个<strong>基础类型istream和ostream</strong>，分别表示输入流和输出流。“<strong>流</strong>”（stream）这个术语想表达的是，随着时间的推移，字符是序列生成或消耗的。</p><h3 id="标准输入输出对象"><a href="#标准输入输出对象" class="headerlink" title="标准输入输出对象"></a>标准输入输出对象</h3><p>标准库定义了4个<strong>IO对象：cin、cout、cerr、clog</strong>。</p><h3 id="一个IO库的程序"><a href="#一个IO库的程序" class="headerlink" title="一个IO库的程序"></a>一个IO库的程序</h3><p>​    程序的第一行</p><p>​    <code>#include &lt;iostream&gt;</code></p><p>告诉编译器我们想要使用iostream库。尖括号中的名字指出了一个<strong>头文件</strong>。每个使用标准库设施的程序都必须包含相关的头文件。对于非标准库的头文件，则用双引号包围。</p><h3 id="向流写入数据"><a href="#向流写入数据" class="headerlink" title="向流写入数据"></a>向流写入数据</h3><p>​    表达式</p><p>​    <code>std::cout &lt;&lt; &quot;Enter two numbers: &quot; &lt;&lt; std::endl;</code></p><p>使用了<strong>输出运算符</strong>（<strong>&lt;&lt;</strong>）在标准输出上打印信息。输出运算符接受两个运算对象：右侧的运算对象是要打印的值，左侧的运算对象必须是一个ostream对象。左侧的ostream对象是运算符的运算结果。</p><p>​    该语句使用了两次输出运算符，即第一次运算结果成为了第二个运算符的左侧对象。该语句等同于：</p><p>​    <code>(std::cout &lt;&lt; &quot;Enter two numbers: &quot;) &lt;&lt;# std::endl;</code></p><p>也可以用两条语句表达：</p><p>​    <code>std::cout &lt;&lt; &quot;Enter two numbers: &quot;</code></p><p>​    <code>std::cout &lt;&lt; std::endl;</code></p><h1 id="1-4-控制流"><a href="#1-4-控制流" class="headerlink" title="1.4 控制流"></a>1.4 控制流</h1><h2 id="1-4-3-读取数量不定的输入数据"><a href="#1-4-3-读取数量不定的输入数据" class="headerlink" title="1.4.3 读取数量不定的输入数据"></a>1.4.3 读取数量不定的输入数据</h2><p>​    在预先不知道要对多少个数求和时，就需要<strong>不断读取数据直至没有新的输入为止</strong>：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">while</span> (<span class="built_in">std</span>::<span class="built_in">cin</span> &gt;&gt; value)</span><br><span class="line">    sum += value;</span><br><span class="line"><span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; <span class="string">"Sum is: "</span> &lt;&lt; sum &lt;&lt; <span class="built_in">std</span>::<span class="built_in">endl</span>;</span><br></pre></td></tr></table></figure><p>如果我们输入</p><p>​    <code>3 4 5 6</code></p><p>则程序会输出</p><p>​    <code>Sum is: 18</code></p><p>当我们使用一个istream对象作为条件时，其效果是检测流的状态。如果流时有效的，那么检测成功。当遇到文件结束符或一个无效输入（例如读入值与value定义的类型不相符），istream的状态会变为无效。</p><h3 id="从键盘输入文件结束符"><a href="#从键盘输入文件结束符" class="headerlink" title="从键盘输入文件结束符"></a>从键盘输入文件结束符</h3><p>Windows: Ctrl + Z, Enter</p><p>Unix&amp;MacOS: Ctrl + D</p><h1 id="1-5-类简介"><a href="#1-5-类简介" class="headerlink" title="1.5 类简介"></a>1.5 类简介</h1><p>​    在C++中，我们通过定义一个<strong>类</strong>（class）来定义自己的数据结构。一个类定义了一个类型，以及与其关联的一组操作。每个类实际上都定义了一个新的类型，其类型名就是其类名。</p><p>类/对象可以进行的操作：</p><ul><li>定义该类型的变量。</li><li>用输入、输出运算符读写该类型的对象。</li><li>在同类对象间进行赋值。</li><li>在两个同类对象间进行加法运算。</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;1-1-编写一个简单的C-程序&quot;&gt;&lt;a href=&quot;#1-1-编写一个简单的C-程序&quot; class=&quot;headerlink&quot; title=&quot;1.1 编写一个简单的C++程序&quot;&gt;&lt;/a&gt;1.1 编写一个简单的C++程序&lt;/h1&gt;&lt;h2 id=&quot;1-1-1-编译、运行
      
    
    </summary>
    
      <category term="C++" scheme="http://a-kali.github.io/categories/C/"/>
    
    
      <category term="C++" scheme="http://a-kali.github.io/tags/C/"/>
    
  </entry>
  
</feed>
