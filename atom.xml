<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>某科学のBLOG</title>
  
  <subtitle>与其感慨路难行，不如马上出发</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://a-kali.github.io/"/>
  <updated>2019-10-05T01:32:59.249Z</updated>
  <id>http://a-kali.github.io/</id>
  
  <author>
    <name>Hsaki</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>计算机视觉算法岗面试归纳</title>
    <link href="http://a-kali.github.io/2019/10/05/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E7%AE%97%E6%B3%95%E5%B2%97%E9%9D%A2%E8%AF%95%E5%BD%92%E7%BA%B3/"/>
    <id>http://a-kali.github.io/2019/10/05/计算机视觉算法岗面试归纳/</id>
    <published>2019-10-05T01:32:59.000Z</published>
    <updated>2019-10-05T01:32:59.249Z</updated>
    
    <summary type="html">
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>周志华《机器学习》</title>
    <link href="http://a-kali.github.io/2019/09/16/%E5%91%A8%E5%BF%97%E5%8D%8E%E3%80%8A%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E3%80%8B/"/>
    <id>http://a-kali.github.io/2019/09/16/周志华《机器学习》/</id>
    <published>2019-09-16T11:28:39.000Z</published>
    <updated>2019-09-18T12:36:28.450Z</updated>
    
    <content type="html"><![CDATA[<h1 id="第-1-章-绪论"><a href="#第-1-章-绪论" class="headerlink" title="第 1 章    绪论"></a>第 1 章    绪论</h1><h2 id="1-2-基本术语"><a href="#1-2-基本术语" class="headerlink" title="1.2 基本术语"></a>1.2 基本术语</h2><p>假设（hypothesis）：根据数据的潜在规律学习而得的模型。亦称为学习器。</p><p>簇（cluster）：聚类学习中的一个组。</p><p>泛化（generalization）：学得模型适用于新样本的能力。</p><h2 id="1-3-假设空间"><a href="#1-3-假设空间" class="headerlink" title="1.3 假设空间"></a>1.3 假设空间</h2><p>假设空间：机器学习中可能的函数构成的空间。学习的过程即是在假设空间中进行搜索的过程。</p><h1 id="第-2-章-模型评估与选择"><a href="#第-2-章-模型评估与选择" class="headerlink" title="第 2 章    模型评估与选择"></a>第 2 章    模型评估与选择</h1><h2 id="2-2-评估方法"><a href="#2-2-评估方法" class="headerlink" title="2.2 评估方法"></a>2.2 评估方法</h2><h3 id="2-2-1-留出法"><a href="#2-2-1-留出法" class="headerlink" title="2.2.1 留出法"></a>2.2.1 留出法</h3><p><strong>留出法</strong>（hold-out）将数据集划分为两个互斥的集合，分别作为训练集和测试集。</p><h3 id="2-2-2-交叉验证法"><a href="#2-2-2-交叉验证法" class="headerlink" title="2.2.2 交叉验证法"></a>2.2.2 交叉验证法</h3><h3 id="2-2-3-自助法"><a href="#2-2-3-自助法" class="headerlink" title="2.2.3 自助法"></a>2.2.3 自助法</h3><p><strong>自助采样法</strong>（bootstrap sampling）对大小为 m 的数据集进行 m 次放回采样，采样得到的数据作为训练集，初始数据集中大约有 36.8% 的数据未被采样过，这部分数据作为测试集。</p><p>自助法在数据集较小、难以划分测试集和训练集时比较有用。但会改变原有数据集的分布，引入估计偏差。</p><h3 id="2-2-4-调参与最佳模型"><a href="#2-2-4-调参与最佳模型" class="headerlink" title="2.2.4 调参与最佳模型"></a>2.2.4 调参与最佳模型</h3><p>模型评估与选择中，用于评估模型的数据集常称为<strong>验证集</strong>。</p><h2 id="2-3-性能度量"><a href="#2-3-性能度量" class="headerlink" title="2.3 性能度量"></a>2.3 性能度量</h2><p>性能度量：对模型泛化能力的评价标准。</p><p>均方误差（mean squared error）：$E(f;D)=\frac{1}{m} \sum^m_{i=1}(f(x_i)-y_i)^2.$ 常用于回归任务中。</p><h3 id="2-3-1-错误率与精度"><a href="#2-3-1-错误率与精度" class="headerlink" title="2.3.1 错误率与精度"></a>2.3.1 错误率与精度</h3><ul><li><strong>错误率</strong>（error rate）：分类错误的样本数占样本总数的比例</li><li><strong>精度</strong>（accuracy）：分类正确的样本数占样本总数的比例</li></ul><p>此处的评估标准仅仅是根据样本分类的正误个数进行评估，没有表现出单个样本的错误程度。</p><h3 id="2-3-2-查准率、查全率与-F1"><a href="#2-3-2-查准率、查全率与-F1" class="headerlink" title="2.3.2 查准率、查全率与 F1"></a>2.3.2 查准率、查全率与 F1</h3><p>在信息检索等应用场景中经常出现如下的需求，比如想知道“检索出的信息中有多少比例是用户感兴趣的”“用户感兴趣的信息中有多少被检索出来了”。此时用<strong>查准率</strong>（precision）和<strong>查全率</strong>（recall，也被称为召回率）更为适合此类需求。</p><p>混淆矩阵：</p><p><a href="https://imgchr.com/i/nfoRB9" target="_blank" rel="noopener"><img src="https://s2.ax1x.com/2019/09/16/nfoRB9.png" alt="nfoRB9.png"></a></p><p>查准率 P 和查全率 R 分别被定义为</p><script type="math/tex; mode=display">P=\frac{TP}{TP+FP}\\R=\frac{TP}{TP+FN}</script><p>查全率和查准率是一对矛盾的度量。一般来说，查全率高时查准率低，查准率高时查全率低。</p><p>P-R曲线、ROC和AUC可参考<a href="https://a-kali.github.io/2019/09/03/机器学习中的评价指标/">机器学习中的评价指标</a>。</p><h3 id="2-3-4-代价敏感错误率与代价曲线"><a href="#2-3-4-代价敏感错误率与代价曲线" class="headerlink" title="2.3.4 代价敏感错误率与代价曲线"></a>2.3.4 代价敏感错误率与代价曲线</h3><p>不同类型的错误所造成的后果不同，为权衡不同类型错误所造成的不同损失，可以为错误赋予<strong>非均等代价</strong>。</p><p>在非均等代价下，我们所希望的不再是简单地最小化错误次数，而是希望最小化<strong>总体代价</strong>。以二分类为例，其代价敏感错误率为：</p><script type="math/tex; mode=display">E = \frac{1}{m}(\sum_{x_i\in D^+}I(f(x_i)\not=y_i)\times cost_{01}+\sum_{x_i\in D^-}I(f(x_i)\not=y_i)\times cost_{10})</script><p>其中$I(·)$为指示函数，$cost$为错误的权重（即代价）。</p><p><strong>代价曲线</strong>可以直接反映非均等代价下学习器的期望总体代价。代价曲线的绘制很简单：ROC曲线上的每一点对应了代价平面上的一条线段，根据ROC曲线上的每一点的状态绘制一条从(0,FPR) 到 (1, FNR) 的线段，线段下的面积即表示了该条件下的期望总体代价。</p><p><img src="https://s2.ax1x.com/2019/09/18/n7Ri7j.png" alt="n7Ri7j.png"></p><h1 id="第-3-章-线性模型"><a href="#第-3-章-线性模型" class="headerlink" title="第 3 章    线性模型"></a>第 3 章    线性模型</h1>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;第-1-章-绪论&quot;&gt;&lt;a href=&quot;#第-1-章-绪论&quot; class=&quot;headerlink&quot; title=&quot;第 1 章    绪论&quot;&gt;&lt;/a&gt;第 1 章    绪论&lt;/h1&gt;&lt;h2 id=&quot;1-2-基本术语&quot;&gt;&lt;a href=&quot;#1-2-基本术语&quot; class
      
    
    </summary>
    
      <category term="机器学习" scheme="http://a-kali.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="机器学习" scheme="http://a-kali.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>Inception v1-v4 论文解读</title>
    <link href="http://a-kali.github.io/2019/09/04/Inception-v1-v4/"/>
    <id>http://a-kali.github.io/2019/09/04/Inception-v1-v4/</id>
    <published>2019-09-04T09:57:36.000Z</published>
    <updated>2019-10-07T09:32:45.129Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Inception-V1"><a href="#Inception-V1" class="headerlink" title="Inception V1"></a>Inception V1</h1><p>论文地址：<a href="https://arxiv.org/pdf/1409.4842v1.pdf" target="_blank" rel="noopener">Going deeper with convolutions</a></p><h2 id="动机与深层思考"><a href="#动机与深层思考" class="headerlink" title="动机与深层思考"></a>动机与深层思考</h2><p>直接提升神经网络性能的方法是提升网络的深度和宽度。然而，更深的网络意味着其参数的大幅增加，从而导致计算量爆炸。因此，作者希望能在计算资源消耗恒定不变的条件下，提升网络性能。</p><p>降低计算资源消耗的一个方法是使用<a href="https://baike.baidu.com/item/稀疏连接/22764619?fr=aladdin" target="_blank" rel="noopener">稀疏连接</a>结构，但不均匀的稀疏数值运算在当前适合密集运算的硬件条件下运行十分低效。作者希望将稀疏连接结构运用于卷积层，并以此解决稀疏连接在密集运算条件下效率低下的问题。于是Inception便应运而生。</p><h2 id="架构细节"><a href="#架构细节" class="headerlink" title="架构细节"></a>架构细节</h2><p> <img src="https://s2.ax1x.com/2019/10/04/uDtGDI.png" alt="uDtGDI.png"></p><p>作者希望“找到最优的局部结构，并在空间上重复它”，如上的Inception模块便是作者找到的最优局部结构。该结构有四个通道，同时使用了1×1、3×3、5×5的卷积核。作者表示“卷积核的大小并没有什么特殊含义，其便利性大于必要性”，在padding=0，1，2的时候特征图大小相同，方便对齐。</p><p>随着网路层数的加深，其特征图的抽象程度变高，空间集中程度下降。这意味着5×5卷积核占比应逐渐增加。然而在具有大量滤波器的卷积层，5×5卷积核运算量太大。这催生了对Inception的第二个改进：在计算量要求较多的地方使用1×1卷积核进行降维。于是便诞生了完整版的Inception V1模块：</p><p><img src="https://s2.ax1x.com/2019/10/04/uDB4kn.png" alt="uDB4kn.png"></p><h2 id="GoogLeNet"><a href="#GoogLeNet" class="headerlink" title="GoogLeNet"></a>GoogLeNet</h2><p>GoogLeNet是一个大量使用了Inception模块堆叠的一个神经网络，其结构如下（图太大了，这里就不放完整图片了）：</p><p><img src="https://s2.ax1x.com/2019/10/04/uDrWin.png" alt="#uDrWin.png"></p><p>值得一提的是，考虑到深层网络的梯度消失问题（当时还没出现批归一化和残差结构），GoogLeNet使用了在网络的中间隐藏层使用了<strong>辅助分类器</strong>（auxiliary classifiers），其训练时给出的分类结果的损失的以0.3的权重加到总损失上，以在一定程度上解决梯度消失问题。</p><h2 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h2><ul><li><p>很多文章中都有提到，Inception结构使用不同大小的卷积核能够适应不同尺度的特征。虽然并没有在原论文中看见相关阐述，但我觉得有点道理。论文中提到Inception在目标检测任务中有更出色的效果，这很可能与其能适应不同尺度特征有关。</p><p><img src="https://s2.ax1x.com/2019/10/04/uDo1Ds.png" alt="如图，图中三只狗狗所占图片区域大小不同"></p></li><li><p>作者并没有在原论文中提到Inception结构起作用的原因，但我认为Inception结构和ResNet的残差结构有异曲同工之妙（虽然ResNet的诞生在GoogLeNet之后）。残差结构能让神经网络自己通过调整参数来选择是否趋近于恒等映射，而Inception能让神经网络自己选择卷积核大小（3×3、5×5 convolutions），或是将这层作为全连接（1×1 convolutions，Inception结构最左边的那个1×1卷积核作用相当于全连接），抑或是池化（3×3 Max Pooling）。</p></li></ul><h1 id="Inception-V2-amp-V3"><a href="#Inception-V2-amp-V3" class="headerlink" title="Inception V2&amp;V3"></a>Inception V2&amp;V3</h1><p>论文链接：<a href="https://arxiv.org/abs/1512.00567" target="_blank" rel="noopener">Rethinking the Inception Architecture for Computer Vision</a></p><h2 id="通用设计准则"><a href="#通用设计准则" class="headerlink" title="通用设计准则"></a>通用设计准则</h2><p>该论文提出了4个神经网络的设计准则，并根据这些准则改进Inception。以下列出关键的两条：</p><ul><li>避免一次性大幅压缩（大尺寸卷积、池化等）特征图的尺寸，否则会造成<strong>表征性瓶颈</strong>，特征图中的信息会大量损失。</li><li>高维度的特征更容易局部处理，解耦更多的特征，加速网络训练。</li></ul><h2 id="分解（Factorization）大尺寸卷积"><a href="#分解（Factorization）大尺寸卷积" class="headerlink" title="分解（Factorization）大尺寸卷积"></a>分解（Factorization）大尺寸卷积</h2><p>作者提出，大尺寸卷积的计算量和它的尺寸是不成比例的。于是将原来的5×5卷积改成了两个3×3卷积：</p><p><img src="https://s2.ax1x.com/2019/10/07/uRSdMD.png" alt="uRSdMD.png"></p><p>然后减少了28%的计算量。</p><h2 id="分解为不对称的卷积"><a href="#分解为不对称的卷积" class="headerlink" title="分解为不对称的卷积"></a>分解为不对称的卷积</h2><p>然后作者想把3×3分解成更小的卷积……尝试了分解成两个2×2，节省了11%的计算量。然后尝试了分解成1×3和3×1，节省了33%计算量。于是便多出了如下两类不对称分解的Inception模块：</p><p><img src="https://s2.ax1x.com/2019/10/07/uRCVIA.png" alt="uRCVIA.png"></p><p>左图模块特性：</p><ul><li>在网络的浅层表现不佳，但在网络的中层有较好的效果。</li><li>由于比原版模块增加了一层非线性层，提高了模型的表达能力。</li></ul><p>右图模块特性：</p><ul><li>能够维持特征的高维度，符合上述通用设计准则的第二条。</li></ul><h2 id="减少特征图尺寸"><a href="#减少特征图尺寸" class="headerlink" title="减少特征图尺寸"></a>减少特征图尺寸</h2><p>当网络需要将一个尺寸为 2d×2d、维度为 k 的特征图转换为一个尺寸为 d×d、维度为 2k 的特征图时，问题就来了：如果先减小尺寸，那么将会损失大量信息，造成准则第一条中的表征性瓶颈；如果先增大维度，那么计算量将翻3倍。如何高效地减小特征图尺寸呢？作者提出了以下结构：</p><p><img src="https://s2.ax1x.com/2019/10/07/uRkv3n.png" alt="uRkv3n.png"></p><p>该结构在增加特征维度、减少特征图尺寸的同时避免了表征性瓶颈和计算量过大的问题。</p><h2 id="Inception-v2"><a href="#Inception-v2" class="headerlink" title="Inception-v2"></a>Inception-v2</h2><p><img src="https://s2.ax1x.com/2019/10/07/uRVxgA.png" alt="uRVxgA.png"></p><p>其中使用了三种Inception模块（图中红框处），包括3个传统模块和5个不对称分解堆叠模块以及2个不对称分解扩展模块。值得一提的是原网络中的7×7卷积被分解成了3个3×3卷积。</p><h2 id="Inception-v3"><a href="#Inception-v3" class="headerlink" title="Inception-v3"></a>Inception-v3</h2><p>在论文的后续中，作者对Inception v2进行了如下改进：</p><ul><li>使用RMSProp优化器</li><li>辅助分类器使用了BatchNorm</li><li>标签平滑（正则化）</li></ul><h1 id="Inception-V4"><a href="#Inception-V4" class="headerlink" title="Inception V4"></a>Inception V4</h1><p>论文地址：<a href="https://arxiv.org/pdf/1602.07261.pdf" target="_blank" rel="noopener">Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Inception-V1&quot;&gt;&lt;a href=&quot;#Inception-V1&quot; class=&quot;headerlink&quot; title=&quot;Inception V1&quot;&gt;&lt;/a&gt;Inception V1&lt;/h1&gt;&lt;p&gt;论文地址：&lt;a href=&quot;https://arxiv.or
      
    
    </summary>
    
      <category term="计算机视觉" scheme="http://a-kali.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/"/>
    
    
      <category term="论文解读" scheme="http://a-kali.github.io/tags/%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB/"/>
    
      <category term="Inception" scheme="http://a-kali.github.io/tags/Inception/"/>
    
      <category term="计算机视觉" scheme="http://a-kali.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/"/>
    
      <category term="神经网络" scheme="http://a-kali.github.io/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>线性回归与逻辑回归</title>
    <link href="http://a-kali.github.io/2019/09/03/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E4%B8%8E%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/"/>
    <id>http://a-kali.github.io/2019/09/03/线性回归与逻辑回归/</id>
    <published>2019-09-03T13:21:16.000Z</published>
    <updated>2019-09-04T09:56:45.073Z</updated>
    
    <content type="html"><![CDATA[<h1 id="线性回归"><a href="#线性回归" class="headerlink" title="线性回归"></a>线性回归</h1><p>​    <strong>线性回归</strong>通常是解决连续数值预测问题, 利用数理统计的回归分析, 来确定变量之间的相互依赖关系. 其公式通常表示如下:</p><script type="math/tex; mode=display">h_\theta(x)=\theta_0 +\theta_1x_1+\theta_2x_2+……+\theta_nx_n=θ^Tx</script><h1 id="逻辑回归"><a href="#逻辑回归" class="headerlink" title="逻辑回归"></a>逻辑回归</h1><p>​    <strong>逻辑（Logistic，又称 Sigmoid）回归</strong>常用于解决二分类问题，用于估算某种事物的可能性。Sigmoid 函数公式如下：</p><script type="math/tex; mode=display">g(z)=\frac{1}{1+e^{-z}}</script><p>该函数的值域为 (0, 1)，其值的意义为输入特征被分到 1 类的概率。逻辑回归的本质是在线性回归之后加了一层函数映射。将线性回归方程带入到逻辑回归方程中，得到逻辑回归表达式：</p><script type="math/tex; mode=display">h_\theta(x) = g(\theta^Tx)=\frac{1}{1+e^{-\theta^Tx}}</script>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;线性回归&quot;&gt;&lt;a href=&quot;#线性回归&quot; class=&quot;headerlink&quot; title=&quot;线性回归&quot;&gt;&lt;/a&gt;线性回归&lt;/h1&gt;&lt;p&gt;​    &lt;strong&gt;线性回归&lt;/strong&gt;通常是解决连续数值预测问题, 利用数理统计的回归分析, 来确定变量之间的
      
    
    </summary>
    
      <category term="机器学习" scheme="http://a-kali.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="机器学习" scheme="http://a-kali.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="线性回归" scheme="http://a-kali.github.io/tags/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/"/>
    
      <category term="逻辑回归" scheme="http://a-kali.github.io/tags/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/"/>
    
  </entry>
  
  <entry>
    <title>机器学习中的评价指标</title>
    <link href="http://a-kali.github.io/2019/09/03/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E8%AF%84%E4%BB%B7%E6%8C%87%E6%A0%87/"/>
    <id>http://a-kali.github.io/2019/09/03/机器学习中的评价指标/</id>
    <published>2019-09-03T08:52:16.000Z</published>
    <updated>2019-09-18T07:01:26.902Z</updated>
    
    <content type="html"><![CDATA[<h1 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h1><h2 id="混淆矩阵"><a href="#混淆矩阵" class="headerlink" title="混淆矩阵"></a>混淆矩阵</h2><div class="table-container"><table><thead><tr><th style="text-align:center">-</th><th style="text-align:center">Positive Predictions</th><th style="text-align:center">Negative Predictions</th></tr></thead><tbody><tr><td style="text-align:center">Positive Label</td><td style="text-align:center">TP (True Positive)</td><td style="text-align:center">FN</td></tr><tr><td style="text-align:center">Negative Label</td><td style="text-align:center">FP</td><td style="text-align:center">TN</td></tr></tbody></table></div><h2 id="Accuracy（ACC，准确率）"><a href="#Accuracy（ACC，准确率）" class="headerlink" title="Accuracy（ACC，准确率）"></a>Accuracy（ACC，准确率）</h2><script type="math/tex; mode=display">ACC= \frac{TP+TN}{FP+FN+TP+TN}=\frac{预测正确的样本数}{总样本数}</script><h2 id="Precision（PRE，精度、查准率）"><a href="#Precision（PRE，精度、查准率）" class="headerlink" title="Precision（PRE，精度、查准率）"></a>Precision（PRE，精度、查准率）</h2><script type="math/tex; mode=display">PRE=\frac{TP}{TP+FP}=\frac{预测正确的正样本数}{所有预测为正的样本数}</script><h2 id="True-Positive-Rate（TPR，召回率、查全率）"><a href="#True-Positive-Rate（TPR，召回率、查全率）" class="headerlink" title="True Positive Rate（TPR，召回率、查全率）"></a>True Positive Rate（TPR，召回率、查全率）</h2><script type="math/tex; mode=display">TPR=\frac{TP}{TP+FN}= \frac{预测正确的正样本数}{总正样本数}</script><h2 id="False-Positive-Rate（FPR，误报率）"><a href="#False-Positive-Rate（FPR，误报率）" class="headerlink" title="False Positive Rate（FPR，误报率）"></a>False Positive Rate（FPR，误报率）</h2><script type="math/tex; mode=display">FPR=\frac{FP}{TN+FP}=\frac{预测为正的负样本数}{总负样本数}</script><h2 id="False-Negative-Rate（FNR，漏报率）"><a href="#False-Negative-Rate（FNR，漏报率）" class="headerlink" title="False Negative Rate（FNR，漏报率）"></a>False Negative Rate（FNR，漏报率）</h2><script type="math/tex; mode=display">FNR=\frac{FN}{TN+FN}=\frac{预测为负的正样本数}{预测成负样本的总数量}</script><h1 id="评估曲线"><a href="#评估曲线" class="headerlink" title="评估曲线"></a>评估曲线</h1><h2 id="PR-曲线"><a href="#PR-曲线" class="headerlink" title="PR 曲线"></a>PR 曲线</h2><p>精度又名查准率, 关心的是 “查出的所有正例中, 哪些正例是查对的”<br>召回率又名查全率, 关心的是 “对于所有的正例, 正确查出了多少个”</p><p>这二者是一对矛盾的度量, 因为我们很容易知道:</p><ul><li>如果我们希望查准率高, 那么可以认为是 “只有当十成把握认为其是正例时, 才将其挑出”。</li><li>而如果我们希望召回率高, 那么可以认为是 “宁错杀一百, 不放过一个”. 查准率和查全率的曲线又叫 PR 曲线, 如下图所示：</li></ul><p><img src="https://s2.ax1x.com/2019/09/03/nkRp6J.jpg" alt="nkRp6J.jpg"></p><p>通常情况下, 如果一个学习器的 PR 曲线被另一个学习器 <strong>完全包住</strong>. 那么我们就认为后者的性能优于前者. 当二者存在交叉时, 我们可以通过四种方式来确定学习器的优劣：</p><ol><li><p>计算 PR 曲线与横纵坐标轴围成的面积, 面积越大越好；</p></li><li><p>利用平衡点 (BEP, 查准率=查全率), BEP 越大越好；</p></li><li><p>利用$F<em>\beta$度量, 当 $\beta<1$ 时， 查准率(精度)权重更大, 当$\beta>1$时， 查全率(召回率)权重更大。$F</1$></em>\beta$的计算公式来自于加权调和平均数：</p><script type="math/tex; mode=display">\frac{1}{F_\beta}=\frac{1}{1+β^2}(\frac{1}{P}+\frac{β^2}{R})</script><script type="math/tex; mode=display">F_β=\frac{(1+β^2)×P×R}{β^2×P+R}</script></li></ol><h2 id="ROC-曲线"><a href="#ROC-曲线" class="headerlink" title="ROC 曲线"></a>ROC 曲线</h2><p>​    很多学习器是为测试样本产生一个实值或概率预测，然后将这个预测值与一个分类阈值进行比较，若大于阈值分为正例，否则分为负例，因此<strong>分类过程可以看做是选取一个合适的截断点</strong>。那么到底什么样的截断点更合适呢？ ROC 正是从这个角度来研究学习器好坏的工具。</p><p>​    ROC 曲线的纵坐标和横坐标分别是召回率和误诊率，下图为 ROC 曲线图，实际任务中会利用有限个测试样本来绘制 ROC 图，所以产生的大多不是平滑的曲线。</p><p><img src="https://s2.ax1x.com/2019/09/03/nk7o59.jpg" alt="nk7o59.jpg"></p><h3 id="绘制-ROC-曲线"><a href="#绘制-ROC-曲线" class="headerlink" title="绘制 ROC 曲线"></a>绘制 ROC 曲线</h3><p>​    假设已经得出一系列样本被划分为正类的概率，然后按照大小排序，下图是一个示例，图中共有20个测试样本，”Class” 一栏表示每个测试样本真正的标签（p表示正样本，n表示负样本），”Score” 表示每个测试样本属于正样本的概率。</p><p><img src="https://s2.ax1x.com/2019/09/03/nkLzOP.jpg" alt="nkLzOP.jpg"></p><p>​    接下来，我们从高到低，依次将“Score”值作为阈值threshold，当测试样本属于正样本的概率大于或等于这个threshold时，我们认为它为正样本，否则为负样本。举例来说，对于图中的第4个样本，其“Score”值为0.6，那么样本1，2，3，4都被认为是正样本，因为它们的“Score”值都大于等于0.6，而其他样本则都认为是负样本。每次选取一个不同的threshold，我们就可以得到一组FPR和TPR，即ROC曲线上的一点。这样一来，我们一共得到了20组FPR和TPR的值，将它们画在ROC曲线的结果如下图：</p><p><img src="https://s2.ax1x.com/2019/09/03/nkOQkF.jpg" alt="nkOQkF.jpg"></p><h3 id="ROC-曲线的意义"><a href="#ROC-曲线的意义" class="headerlink" title="ROC 曲线的意义"></a>ROC 曲线的意义</h3><p>​    有助于选择最佳的阈值。ROC曲线越靠近左上角，模型的准确性就越高。最靠近左上角的ROC曲线上的点是分类错误最少的最好阈值，其假正例和假反例总数最少。</p><h2 id="AUC-的含义及计算"><a href="#AUC-的含义及计算" class="headerlink" title="AUC 的含义及计算"></a>AUC 的含义及计算</h2><p>​    <strong>AUC</strong>（Area Under Curve）被定义为ROC曲线下与坐标轴围成的面积，显然这个面积的数值不会大于1。又由于ROC曲线一般都处于y=x这条直线的上方，所以AUC的取值范围在0.5和1之间。</p><p>​    在进行学习器的比较时，若一个学习器的ROC曲线被另一个学习器的曲线完全“包住”，则可断言后者的性能优于前者；若两个学习器的ROC曲线发生交叉，则难以一般性的断言两者孰优孰劣。此时如果一定要进行比较，则比较合理的判断依据是比较AUC，AUC大的学习器通常性能更好。</p><h1 id="参考文献："><a href="#参考文献：" class="headerlink" title="参考文献："></a>参考文献：</h1><p><a href="https://hellozhaozheng.github.io/z_post/计算机视觉-计算机视觉知识点总结/" target="_blank" rel="noopener">计算机视觉知识总结</a></p><p><a href="https://baike.baidu.com/item/AUC/19282953?fr=aladdin" target="_blank" rel="noopener">AUC 百度百科</a></p><p><a href="https://zdkswd.github.io/2018/11/20/精确率、召回率、真正类率（TPR）、假正类率（FPR）ROC曲线/" target="_blank" rel="noopener">精确率、召回率、真正类率（TPR）、假正类率（FPR）ROC曲线</a></p><p><a href="https://blog.csdn.net/Libo_Learner/article/details/83615715" target="_blank" rel="noopener">机器学习笔记~F-score beta衡量precision和recall之间重要性</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;基本概念&quot;&gt;&lt;a href=&quot;#基本概念&quot; class=&quot;headerlink&quot; title=&quot;基本概念&quot;&gt;&lt;/a&gt;基本概念&lt;/h1&gt;&lt;h2 id=&quot;混淆矩阵&quot;&gt;&lt;a href=&quot;#混淆矩阵&quot; class=&quot;headerlink&quot; title=&quot;混淆矩阵&quot;&gt;&lt;/a
      
    
    </summary>
    
      <category term="机器学习" scheme="http://a-kali.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="机器学习" scheme="http://a-kali.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="评价指标" scheme="http://a-kali.github.io/tags/%E8%AF%84%E4%BB%B7%E6%8C%87%E6%A0%87/"/>
    
  </entry>
  
  <entry>
    <title>Kaggle 比赛记录之 Severstal: Steel Defect Detection</title>
    <link href="http://a-kali.github.io/2019/09/02/Severstal-Steel-Defect-Detection-%E6%AF%94%E8%B5%9B%E8%AE%B0%E5%BD%95/"/>
    <id>http://a-kali.github.io/2019/09/02/Severstal-Steel-Defect-Detection-比赛记录/</id>
    <published>2019-09-02T02:18:54.000Z</published>
    <updated>2019-09-05T14:32:20.392Z</updated>
    
    <content type="html"><![CDATA[<div id="hbe-security">  <div class="hbe-input-container">  <input type="password" class="hbe-form-control" id="pass" placeholder="Please enter the password to read the blog." />    <label for="pass">Please enter the password to read the blog.</label>    <div class="bottom-line"></div>  </div></div><div id="decryptionError" style="display: none;">Incorrect Password!</div><div id="noContentError" style="display: none;">No content to display!</div><div id="encrypt-blog" style="display:none">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</div><script src="/lib/crypto-js.js"></script><script src="/lib/blog-encrypt.js"></script><link href="/css/blog-encrypt.css" rel="stylesheet" type="text/css">]]></content>
    
    <summary type="html">
    
      The article has been encrypted, please enter your password to view.&lt;br&gt;
    
    </summary>
    
      <category term="计算机视觉" scheme="http://a-kali.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/"/>
    
    
      <category term="计算机视觉" scheme="http://a-kali.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/"/>
    
      <category term="语义分割" scheme="http://a-kali.github.io/tags/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2/"/>
    
      <category term="Kaggle" scheme="http://a-kali.github.io/tags/Kaggle/"/>
    
  </entry>
  
  <entry>
    <title>ResNet (CVPR, 2016)</title>
    <link href="http://a-kali.github.io/2019/09/01/ResNet-CVPR-2016/"/>
    <id>http://a-kali.github.io/2019/09/01/ResNet-CVPR-2016/</id>
    <published>2019-09-01T15:48:36.000Z</published>
    <updated>2019-09-02T08:47:47.484Z</updated>
    
    <content type="html"><![CDATA[<p><strong>文章：</strong>Deep Residual Learning for Image Recognition</p><p><strong>作者：</strong>Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun</p><h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h1><p>​    越深的神经网络越难训练。对于那些明显比我们过去使用的神经网络要深得多得网络，我们提出了一种残差学习框架来简化训练其训练过程。我们提供了全面的实验性证据表明这些残差网络更容易优化，并且一定程度上加深网络能提高准确率。在 ImageNet 数据集上，我们评估了深达 152 层的残差网络。该网络比 VGG 深 8 倍，但任然具有较低的复杂度。整体的残差网络能够在 ImageNet 的测试集上达到 3.57% 的错误率。</p><h1 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h1><p>​    众所周知，深度的网络使各层特征和分类器在一个端到端多层网络中融为一个整体，最近的研究也表明网络的深度非常重要。但网络的学习是否像堆积更深层的网络那么简单呢？一个阻碍深层网络学习的阻碍就是臭名昭著的梯度消失和梯度爆炸问题，严重妨碍到神经网络的收敛。这个问题由于归一初始化和中间层归一化的诞生得到了一定的解决，这使得十层以上的神经网络在随机梯度下降的反向传播时也能得到很好的收敛。</p><p>​    然而，实验告诉我们，更深层的神经网络容易表现出<strong>退化</strong>问题（随着层数的加深，准确率达到饱和然后迅速下降），而模型退化的根本原因很大程度上不是因为过拟合，而是因为梯度消失问题。</p><p>​    退化问题表明不是所有的网络结构都能轻易得到优化。假设我们有一个浅层网络和一个深层网络，深层网络的一部分是浅层网络的拷贝，其余部分为恒等映射。在这种情况下深层网络不应该会比浅层网络有更大的误差。<strong>而导致深层网络比浅层网络准确率低的原因是深层网络更难以优化</strong>。</p><p>​    这篇论文将介绍一个深度残差学习框架如何解决退化问题。深度残差框架没有使用直接堆叠网络层来拟合期望的映射函数，而是选择<strong>让这些网络层来拟合一个残差映射</strong>。比如说，我们所期望得到的映射函数射函数为 H(x), 那么我们通过残差函数 F(x) := H(x) - x。那么原始的映射函数就可以通过 F(x) + x 得到。如图所示：</p><p><img src="https://s2.ax1x.com/2019/09/01/nS6Rc8.png" alt="nS6Rc8.png"></p><h1 id="深度残差学习"><a href="#深度残差学习" class="headerlink" title="深度残差学习"></a>深度残差学习</h1><h2 id="残差学习"><a href="#残差学习" class="headerlink" title="残差学习"></a>残差学习</h2><p>​    假设 H(x) 由几个堆叠层组成，其输入为 x，并且其最终能被训练为残差函数 F(x)，即 H(x) = F(x) + x。其也能起到所要求的函数的效果，但是使堆叠层训练成残差函数的难度和使用残差结构训练的难度是不一样的。</p><p>​    引言中所提到的反直觉现象促成了这种重构。如同我们在引言中所讨论的，额外增加的层次如果都是恒等映射，深层模型的不会比浅层模型有更大的误差。退化问题则表明，由多个非线性层的叠加而成的额外层很难近似于恒等映射。<strong>而在残差学习的结构下，如果恒等映射是可选择的，额外层可能会简单地将权重降低至接近0来实现恒等映射。</strong></p><h2 id="快捷恒等映射"><a href="#快捷恒等映射" class="headerlink" title="快捷恒等映射"></a>快捷恒等映射</h2><p>​    我们在每几层之间使用残差学习，如上图的结构。在这篇论文中我们将残差块定义为：</p><script type="math/tex; mode=display">y = F(x,{W_i})+x</script><p>x 和 y 分别表示残差块的输入和输出，函数 F 表示残差映射所需要学习的函数。上图中的 F(x) 为：</p><script type="math/tex; mode=display">F=W_2 \sigma(W_1x)</script><p>其中 σ 表示 ReLU，为了简化写法忽略偏置项。之后 F + x 通过快捷连接来完成，之后再进行一段ReLU。</p><p>​    第一条方程式中的 F 和 x 的维度必须是相等的。如果不是这种情况（比如当改变输入输出通道时），<strong>我们可以添加系数矩阵 $W_s$ 来使得 F 和 x 维度相等</strong>。</p><script type="math/tex; mode=display">y=F(x,W_i)+W_sx</script><p>​    <strong>残差函数 F 的形式时可变的。本文的实验中包含了两层和三层的结构，当然更多层也是可以的，甚至可以用于卷积层。</strong></p><h2 id="网络架构"><a href="#网络架构" class="headerlink" title="网络架构"></a>网络架构</h2><p><img src="https://img-blog.csdn.net/20171218163309386?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvUXVpbmN1bnRpYWw=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt></p><h1 id="ResNet-的意义"><a href="#ResNet-的意义" class="headerlink" title="ResNet 的意义"></a>ResNet 的意义</h1><p>​    从关联性的角度来看，残差结构使得深层网络和浅层网络的关联性更强，输出端的损失能更加有效地调整到浅层网络的参数。当网络层数过深时，优化器会调低网络权重，使得反向传播“选择性地”使用捷径。</p><p>​    从函数角度来看，残差结构直接构建了一个更接近”绝对不比浅层网络差“的结构。</p><h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><p><a href="https://hellozhaozheng.github.io/z_post/计算机视觉-ResNet-CVPR2016" target="_blank" rel="noopener">从零开始的BLOG</a></p><p><a href="https://blog.csdn.net/Quincuntial/article/details/77263562?locationNum=6" target="_blank" rel="noopener">ResNet 论文翻译</a></p><p><a href="https://arxiv.org/abs/1512.03385" target="_blank" rel="noopener">Deep Residual Learning for Image Recognition</a></p><p>恺明大佬牛逼！</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;strong&gt;文章：&lt;/strong&gt;Deep Residual Learning for Image Recognition&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;作者：&lt;/strong&gt;Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian
      
    
    </summary>
    
    
      <category term="论文解读" scheme="http://a-kali.github.io/tags/%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB/"/>
    
      <category term="计算机视觉" scheme="http://a-kali.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/"/>
    
      <category term="神经网络" scheme="http://a-kali.github.io/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
      <category term="ResNet" scheme="http://a-kali.github.io/tags/ResNet/"/>
    
  </entry>
  
  <entry>
    <title>Aiming to 谷歌机器学习冬令营</title>
    <link href="http://a-kali.github.io/2019/08/29/Aiming-to-%E8%B0%B7%E6%AD%8C%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%86%AC%E4%BB%A4%E8%90%A5/"/>
    <id>http://a-kali.github.io/2019/08/29/Aiming-to-谷歌机器学习冬令营/</id>
    <published>2019-08-29T15:02:43.000Z</published>
    <updated>2019-09-05T01:05:28.418Z</updated>
    
    <content type="html"><![CDATA[<p>​    又瞅了瞅谷歌去年的招聘推文，才发现机器学习工程师压根没有算法笔试这一环节╮(╯▽╰)╭。吓得我赶紧删掉了写了一半的Kick Start笔记，将《C++ Primer》塞回书架上，开始重新定制计划。</p><p>​    根据去年的推文，谷歌机器学习冬令营的申请时间是9.20-11.18，需提交中英文简历各一份，根据简历筛选入营名额。这意味着充实简历是当务之急，而某凯最多还剩两个月的时间为充实简历。回想起这毫无作为的两个月暑假，心里不免升起一丝丝悔恨之意( ＿ ＿)ノ｜。但比起回首过去，我们更应该展望未来才是。现在让某凯认真思考一下如何亡羊补牢。</p><p>​    让我们理一下逻辑：</p><p>简历充实⟶机器学习冬令营⟶表现够屌⟶机器学习工程师实习⟶表现牛逼⟶转正⟶走向人生癫疯</p><h1 id="充实简历"><a href="#充实简历" class="headerlink" title="充实简历"></a>充实简历</h1><p>​    整个逻辑链首要的就是简历要充实。我的简历充不充实我不知道，但作为一个只会调参的普通985的本科生赛棍在这个面向整个本硕博的招募中还是非常悬的。那么该如何充实简历呢？我们知道，简历三大法宝：论文、项目和竞赛。项目？周期太长；论文？呵。于是竞赛成了仅剩的唯一选择，而两个月的时间刚好够打一场kaggle，打kaggle不拿金牌就没啥意义。</p><p>让我们瞅瞅现在有哪些剩余时间在两个月左右的比赛：</p><ul><li><a href="https://www.kaggle.com/c/severstal-steel-defect-detection" target="_blank" rel="noopener">Severstal: Steel Defect Detection</a>：钢铁缺陷分割+多分类，分割类比赛本来就难顶，参赛人数还多，怕是很难搞。比 SIIM 好的一点就是不用处理医学图像。</li><li><a href="https://www.kaggle.com/c/kuzushiji-recognition" target="_blank" rel="noopener">Kuzushiji Recognition</a>：古日文识别，将古日文翻译成当代日文。大概是目标检测+细粒度超多分类。参赛队伍少，可以一试。但……没有奖牌？</li></ul><p>卧槽，就这俩？顶不住啊顶不住。看样子只能硬着头皮上 Severstal 了。 多刷 kernel 和 discussion，开场三模型五折交叉验证，多调参多提交，多思考多记录，多看论文，紧紧咬住金牌的尾巴不放，应该还是有机会的。</p><h1 id="提升实力"><a href="#提升实力" class="headerlink" title="提升实力"></a>提升实力</h1><p>​    简历屌一点挺好，但要是实力不够去了也是白给。根据某凯对自己弱点的了解，提升实力应从下面几个点入手。</p><h2 id="1-机器学习"><a href="#1-机器学习" class="headerlink" title="1. 机器学习"></a>1. 机器学习</h2><p>​    这里的机器学习指的是除去当下火爆的深度学习以外的传统的机器学习算法。虽然神经网络已经取代了机器学习大部分的工作，但是在赛场、面试和神经网络的架构中还是能时常见到一些经典的机器学习算法的身影。</p><p>机器学习基础学习资料：</p><ul><li><a href="https://study.163.com/course/courseMain.htm?courseId=1004570029" target="_blank" rel="noopener">吴恩达机器学习</a></li><li>《百面机器学习》</li><li>《Python 数据科学手册》</li></ul><p>西瓜书什么的就算了，啃不动。</p><h2 id="2-深度学习基础巩固"><a href="#2-深度学习基础巩固" class="headerlink" title="2. 深度学习基础巩固"></a>2. 深度学习基础巩固</h2><p>​    巩固最基本的反向传播、损失函数、CNN和RNN等</p><p>参考资料：</p><ul><li>《神经网络入门》</li><li>吴恩达——深度学习工程师</li></ul><h2 id="3-计算机视觉进阶"><a href="#3-计算机视觉进阶" class="headerlink" title="3. 计算机视觉进阶"></a>3. 计算机视觉进阶</h2><p>​    作为一个 CV 爱好者，还是得对前沿的 CV 算法熟悉点好，何况还要经常和相关竞赛打交道。</p><h3 id="神经网络："><a href="#神经网络：" class="headerlink" title="神经网络："></a>神经网络：</h3><ul><li>SqueezeNet</li><li>R-CNN, Fast R-CNN, Faster R-CNN, Mask R-CNN</li><li>InceptionV1-V4, Inception-ResNet, Xception</li><li>YOLOv1, YOLO9000, YOLOv3</li><li>FCN</li><li>MoblieNet</li><li><del>ResNet</del>(9.2), DenseNet</li><li>FPN</li><li>U-Net, U-Net++</li><li>ResNeXt</li><li>EfficientNet</li><li>ResObj</li><li>SSD, DSSD</li><li>SegNet</li><li>PSPNet</li><li>LinkNet</li><li>Cascade</li><li>DPN</li><li>Siamese Network</li><li>NasNet</li><li>DCN</li><li>ShuffleNet</li></ul><p>好像要两天一篇才能在两个月内看完……不过不指望看那么多啦，三天一篇就行了。</p><h3 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h3><ul><li><a href="https://blog.csdn.net/m0_37477175/article/details/83004746" target="_blank" rel="noopener">图像分割相关损失函数</a></li><li><a href="https://hellozhaozheng.github.io/z_post/深度学习-各种损失函数深入解析/" target="_blank" rel="noopener">常见损失函数</a></li><li>MultiLoss</li><li>TripletLoss</li><li>Arcface</li></ul><h2 id="优化器"><a href="#优化器" class="headerlink" title="优化器"></a>优化器</h2><h2 id="增强学习"><a href="#增强学习" class="headerlink" title="增强学习"></a>增强学习</h2><h2 id="4-实战能力"><a href="#4-实战能力" class="headerlink" title="4. 实战能力"></a>4. 实战能力</h2><p>Python语言：复习《流畅的Python》。</p><p>深度学习框架：目前主要用PyTorch，虽然很好用但用得并不熟练，也不知道怎么学。但进谷歌八成要用Tensorflow……有空学学顺便学学keras吧，不过优先级不高。</p><p>数据分析工具：复习《Python数据科学手册》，给比赛做做EDA。</p><p> 学习OpenCV：暂时还没找到好点的资料。</p><h1 id="执行日志"><a href="#执行日志" class="headerlink" title="执行日志"></a>执行日志</h1><p>9.1 - 9.3</p><ul><li>任务：<del>阅读 ResNet 论文</del></li></ul><p>9.2 - 9.4</p><ul><li>任务：<ul><li><del>整理机器学习评价指标</del></li><li><del>线性回归与逻辑回归</del></li></ul></li></ul><p>9.5 - 9.6</p><ul><li>任务：<ul><li>《百面机器学习》特征工程、模型评估</li><li>ReNeXt 论文</li></ul></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;​    又瞅了瞅谷歌去年的招聘推文，才发现机器学习工程师压根没有算法笔试这一环节╮(╯▽╰)╭。吓得我赶紧删掉了写了一半的Kick Start笔记，将《C++ Primer》塞回书架上，开始重新定制计划。&lt;/p&gt;
&lt;p&gt;​    根据去年的推文，谷歌机器学习冬令营的申请时
      
    
    </summary>
    
      <category term="计划" scheme="http://a-kali.github.io/categories/%E8%AE%A1%E5%88%92/"/>
    
    
      <category term="Google" scheme="http://a-kali.github.io/tags/Google/"/>
    
      <category term="招聘" scheme="http://a-kali.github.io/tags/%E6%8B%9B%E8%81%98/"/>
    
      <category term="机器学习" scheme="http://a-kali.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="计划" scheme="http://a-kali.github.io/tags/%E8%AE%A1%E5%88%92/"/>
    
  </entry>
  
  <entry>
    <title>在深度学习过程中遇到的一些bug及解决方法</title>
    <link href="http://a-kali.github.io/2019/08/29/%E5%9C%A8%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%BF%87%E7%A8%8B%E4%B8%AD%E9%81%87%E5%88%B0%E7%9A%84%E4%B8%80%E4%BA%9Bbug%E5%8F%8A%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95/"/>
    <id>http://a-kali.github.io/2019/08/29/在深度学习过程中遇到的一些bug及解决方法/</id>
    <published>2019-08-29T09:15:55.000Z</published>
    <updated>2019-08-29T09:15:55.619Z</updated>
    
    <summary type="html">
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>《C++ Primer》 第4章 表达式</title>
    <link href="http://a-kali.github.io/2019/08/29/%E3%80%8AC-Primer%E3%80%8B-%E7%AC%AC4%E7%AB%A0-%E8%A1%A8%E8%BE%BE%E5%BC%8F/"/>
    <id>http://a-kali.github.io/2019/08/29/《C-Primer》-第4章-表达式/</id>
    <published>2019-08-29T08:14:27.000Z</published>
    <updated>2019-08-29T08:54:15.557Z</updated>
    
    <content type="html"><![CDATA[<h1 id="4-8-位运算符"><a href="#4-8-位运算符" class="headerlink" title="4.8 位运算符"></a>4.8 位运算符</h1><p><strong>位运算符</strong>主要作用于整型的运算对象，并把运算对象看成是二进制位的集合。</p><ul><li>~ 位求反</li><li>&lt;&lt; 左移</li><li>>&gt; 右移</li><li>&amp; 位与</li><li>^ 位异或</li><li>| 位或</li></ul><h1 id="4-9-sizeof-运算符"><a href="#4-9-sizeof-运算符" class="headerlink" title="4.9 sizeof 运算符"></a>4.9 sizeof 运算符</h1><p>​    <strong>sizeof</strong> 运算符返回的是表达式结果类型的大小，返回类型为 size_t。</p><p>就这样水完一篇博客（ -_-)</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;4-8-位运算符&quot;&gt;&lt;a href=&quot;#4-8-位运算符&quot; class=&quot;headerlink&quot; title=&quot;4.8 位运算符&quot;&gt;&lt;/a&gt;4.8 位运算符&lt;/h1&gt;&lt;p&gt;&lt;strong&gt;位运算符&lt;/strong&gt;主要作用于整型的运算对象，并把运算对象看成是二进制
      
    
    </summary>
    
      <category term="C++" scheme="http://a-kali.github.io/categories/C/"/>
    
    
      <category term="C++" scheme="http://a-kali.github.io/tags/C/"/>
    
  </entry>
  
  <entry>
    <title>《C++ Primer》 第3章 字符串、向量和数组</title>
    <link href="http://a-kali.github.io/2019/08/26/%E3%80%8AC-Primer%E3%80%8B-%E7%AC%AC3%E7%AB%A0-%E5%AD%97%E7%AC%A6%E4%B8%B2%E3%80%81%E5%90%91%E9%87%8F%E5%92%8C%E6%95%B0%E7%BB%84/"/>
    <id>http://a-kali.github.io/2019/08/26/《C-Primer》-第3章-字符串、向量和数组/</id>
    <published>2019-08-25T17:58:39.000Z</published>
    <updated>2019-08-29T03:37:23.617Z</updated>
    
    <content type="html"><![CDATA[<h1 id="3-1-命名空间的-using-声明"><a href="#3-1-命名空间的-using-声明" class="headerlink" title="3.1 命名空间的 using 声明"></a>3.1 命名空间的 using 声明</h1><p>​    <strong>域操作符</strong>（::）的含义是：编译器应从操作符左侧名字所示作用域中寻找右侧那个名字。因此，std::cin 的意思就是要使用命名空间 std 中的名字 cin。而使用 <strong>using 声明</strong>后则无需专门的前缀也能使用所需的名字了。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">using</span> <span class="built_in">std</span>::<span class="built_in">cin</span>;</span><br><span class="line"><span class="keyword">int</span> i;</span><br><span class="line"><span class="built_in">cin</span> &gt;&gt; i;</span><br></pre></td></tr></table></figure><p>更方便的方法：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br></pre></td></tr></table></figure><p>这样就可以使用 std 命名空间中所有的名字了。</p><h1 id="3-2-标准库类型-string"><a href="#3-2-标准库类型-string" class="headerlink" title="3.2 标准库类型 string"></a>3.2 标准库类型 string</h1><p>​    标准库类型 <strong>string</strong> 表示可变长的字符序列，使用 string 类型必须首先包含 string 头文件。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;string&gt; // 包含 string 头文件</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="built_in">std</span>::<span class="built_in">string</span>; <span class="comment">// string 定义在命名空间 std 中</span></span><br></pre></td></tr></table></figure><h2 id="3-2-1-定义和初始化-string-对象"><a href="#3-2-1-定义和初始化-string-对象" class="headerlink" title="3.2.1 定义和初始化 string 对象"></a>3.2.1 定义和初始化 string 对象</h2><p>​    如何初始化类的对象是由类本身决定的。如下是初始化 string 对象的常用方式：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="built_in">string</span> <span class="title">s1</span><span class="params">(s2)</span></span>;</span><br><span class="line"><span class="built_in">string</span> s1 = s2;    <span class="comment">// 同上</span></span><br><span class="line"><span class="function"><span class="built_in">string</span> <span class="title">s1</span><span class="params">(n, <span class="string">'c'</span>)</span>  <span class="comment">// 将s1初始化为由连续n个'c'组成的字符串</span></span></span><br></pre></td></tr></table></figure><h2 id="3-2-2-string-对象上的操作"><a href="#3-2-2-string-对象上的操作" class="headerlink" title="3.2.2 string 对象上的操作"></a>3.2.2 string 对象上的操作</h2><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">os &lt;&lt; s; <span class="comment">// output stream</span></span><br><span class="line">is &gt;&gt; s; <span class="comment">// 输入到s，字符串以空白分隔</span></span><br><span class="line">getline(is, s); <span class="comment">// 从is中读取一行到s</span></span><br><span class="line">s.empty();</span><br><span class="line">s.size();</span><br><span class="line">s[n];</span><br><span class="line">s1 + s2;</span><br><span class="line">&lt;, &lt;=, &gt;, &gt;=  <span class="comment">// 利用字符在字典中的顺序进行比较，大小写敏感</span></span><br></pre></td></tr></table></figure><h3 id="读写-string-对象"><a href="#读写-string-对象" class="headerlink" title="读写 string 对象"></a>读写 string 对象</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cin</span> &gt;&gt; s; <span class="comment">// 将 string 对象读入 s，遇到空白停止</span></span><br><span class="line"><span class="built_in">cin</span> &gt;&gt; s1 &gt;&gt; s2;   <span class="comment">// 把第一个输入到s1中，第二个输入到s2中</span></span><br></pre></td></tr></table></figure><h2 id="3-2-3-处理-string-对象中的字符"><a href="#3-2-3-处理-string-对象中的字符" class="headerlink" title="3.2.3 处理 string 对象中的字符"></a>3.2.3 处理 string 对象中的字符</h2><p>​    <strong>cctype头文件</strong>中定义了一组标准库函数来处理 string 对象中的字符。比如判断字符是否为数字、字母、控制字符、可打印字符、大写、小写、标点等，以及大小写转换。（p82）</p><h3 id="基于范围的-for-语句"><a href="#基于范围的-for-语句" class="headerlink" title="基于范围的 for 语句"></a>基于范围的 for 语句</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> (declaration: expression)  <span class="comment">// 跟python中 for declaration in expresson 类似</span></span><br><span class="line">    statement</span><br><span class="line"><span class="comment">// 举例    </span></span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">auto</span> c : str)</span><br><span class="line">    <span class="built_in">cout</span> &lt;&lt; c &lt;&lt; <span class="built_in">endl</span>;</span><br></pre></td></tr></table></figure><h3 id="使用范围-for-语句改变字符串中的字符"><a href="#使用范围-for-语句改变字符串中的字符" class="headerlink" title="使用范围 for 语句改变字符串中的字符"></a>使用范围 for 语句改变字符串中的字符</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> (<span class="keyword">auto</span> &amp;c : str)  <span class="comment">// c是一个引用，故赋值语句将改变s中字符的值</span></span><br><span class="line">    c = <span class="built_in">toupper</span>(c);</span><br></pre></td></tr></table></figure><h1 id="3-3-标准库类型-vector"><a href="#3-3-标准库类型-vector" class="headerlink" title="3.3 标准库类型 vector"></a>3.3 标准库类型 vector</h1><p>​    标准库类型 <strong>vector</strong> 表示对象的集合，其中所有对象的类型都相同。集合中每个对象都有一个与之对应的索引，索引用于访问对象。因为 vectot 容纳着其他对象，所以它也常被称作<strong>容器</strong>。</p><p>​    使用 vector：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta"># <span class="meta-keyword">include</span> <span class="meta-string">&lt;vector&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="built_in">std</span>::<span class="built_in">vector</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; ivec;  <span class="comment">// 定义一个能容纳int类型集合的对象</span></span><br><span class="line"><span class="built_in">vector</span>&lt;Sales_item&gt; Sales_vec;</span><br><span class="line"><span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="built_in">string</span>&gt;&gt; file;</span><br></pre></td></tr></table></figure><p>vector 能容纳绝大多数类型的对象作为其元素。</p><h2 id="3-3-1-定义和初始化-vector-对象"><a href="#3-3-1-定义和初始化-vector-对象" class="headerlink" title="3.3.1 定义和初始化 vector 对象"></a>3.3.1 定义和初始化 vector 对象</h2><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">vector</span>&lt;T&gt; v1;</span><br><span class="line"><span class="built_in">vector</span>&lt;T&gt; v2(v1);</span><br><span class="line"><span class="built_in">vector</span>&lt;T&gt; v3 = v1;</span><br><span class="line"><span class="built_in">vector</span>&lt;T&gt; v4(n, val);</span><br><span class="line"><span class="built_in">vector</span>&lt;T&gt; v5(n);</span><br><span class="line"><span class="built_in">vector</span>&lt;T&gt; v6&#123;a,b,c...&#125;;</span><br><span class="line"><span class="built_in">vector</span>&lt;T&gt; v7 = &#123;a,b,c...&#125;;</span><br></pre></td></tr></table></figure><h2 id="3-3-2-向-vector-对象中添加元素"><a href="#3-3-2-向-vector-对象中添加元素" class="headerlink" title="3.3.2 向 vector 对象中添加元素"></a>3.3.2 向 vector 对象中添加元素</h2><p>​    vector 的成员函数 <strong>push_back()</strong> 能将一个元素添加到 vector 的尾端。</p><h2 id="3-3-3-其他-vector-操作"><a href="#3-3-3-其他-vector-操作" class="headerlink" title="3.3.3 其他 vector 操作"></a>3.3.3 其他 vector 操作</h2><p>​    跟 string 差不多。</p><h1 id="3-4-迭代器介绍"><a href="#3-4-迭代器介绍" class="headerlink" title="3.4 迭代器介绍"></a>3.4 迭代器介绍</h1><p>​    <strong>迭代器</strong>能用于访问 string 对象和 vector 对象的元素，并且所有的标准库容器都能使用迭代器。使用迭代器能访问某个元素，迭代器也能从一个元素移动到另外一个元素。</p><h2 id="3-4-1-使用迭代器"><a href="#3-4-1-使用迭代器" class="headerlink" title="3.4.1 使用迭代器"></a>3.4.1 使用迭代器</h2><p>​    能使用迭代器的类型都拥有能返回迭代器的成员函数，比如 <strong>begin</strong> 和 <strong>end</strong>。其中 begin 成员负责指向第一个元素，end 成员则负责指向容器（或 string 对象）的”尾元素的下一个位置“的迭代器。end 成员返回的迭代器常被称为<strong>尾后迭代器</strong>。如果容器为空，则 begin 和 end 返回的是同一个元素。</p><h3 id="迭代器运算符"><a href="#迭代器运算符" class="headerlink" title="迭代器运算符"></a>迭代器运算符</h3><ul><li>*iter              返回迭代器iter所指元素的引用</li><li>iter-&gt;men  相当于(*iter).men</li><li>++iter           令 iter 指向容器下一个元素，同理有 —iter，iter + n，iter1 - iter2 等</li><li>iter1 &gt; iter2 比较位置关系，靠后的值大</li></ul><h3 id="迭代器类型"><a href="#迭代器类型" class="headerlink" title="迭代器类型"></a>迭代器类型</h3><p> 拥有迭代器迭代器的标准库类型使用 iterator 和 const_iterator 来表示迭代器的类型。<strong>const_iterator</strong> 和常量指针差不多，能读但不能修改所指元素的值，而 <strong>iterator</strong> 所指的对象可读可写。 如果容器对象是一个常量，则只能使用 const_iterator；否则两种类型都能使用。</p><h3 id="容器操作使迭代器失效"><a href="#容器操作使迭代器失效" class="headerlink" title="容器操作使迭代器失效"></a>容器操作使迭代器失效</h3><p>​    谨记，但凡是使用了迭代器的循环体，都不要向迭代器所属的容器添加元素。</p><h1 id="3-5-数组"><a href="#3-5-数组" class="headerlink" title="3.5 数组"></a>3.5 数组</h1><p>​    <strong>数组</strong> 是一种类似标准库类型 vector 的数据结构，与 vector 不同的是数组大小固定，不能随意向数组中增加元素。</p><h2 id="3-5-1-定义和初始化内置数组"><a href="#3-5-1-定义和初始化内置数组" class="headerlink" title="3.5.1 定义和初始化内置数组"></a>3.5.1 定义和初始化内置数组</h2><h3 id="显式初始化数组元素"><a href="#显式初始化数组元素" class="headerlink" title="显式初始化数组元素"></a>显式初始化数组元素</h3><p>​    如果声明时没有指明维度，编译器会根据初始值的数量计算并推断出来；如果指明了维度，那么初始值的总数量不应该超出指定的大小。</p><h3 id="字符数组的特殊性"><a href="#字符数组的特殊性" class="headerlink" title="字符数组的特殊性"></a>字符数组的特殊性</h3><p>​    当使用字符串字面值初始化字符数组时，一定要注意字符串字面值的结尾处还有一个隐藏的空字符，这个空字符也会像字符串的其它字符一样被拷贝到数组里去。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">char</span> a1[<span class="number">3</span>] = &#123;<span class="string">'c'</span>, <span class="string">'p'</span>, <span class="string">'p'</span>&#125;;  <span class="comment">// 正确</span></span><br><span class="line"><span class="keyword">char</span> a2[<span class="number">4</span>] = <span class="string">"cpp"</span>;            <span class="comment">// 正确</span></span><br><span class="line"><span class="keyword">char</span> a3[<span class="number">3</span>] = <span class="string">"cpp"</span>;            <span class="comment">// 错误</span></span><br></pre></td></tr></table></figure><h3 id="理解复杂的数组声明"><a href="#理解复杂的数组声明" class="headerlink" title="理解复杂的数组声明"></a>理解复杂的数组声明</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> *ptrs[<span class="number">10</span>];                  <span class="comment">// ptrs是含有10个整型指针的数组</span></span><br><span class="line"><span class="keyword">int</span> &amp;refs[<span class="number">10</span>] = <span class="comment">/*?*/</span>;          <span class="comment">// 错误：不存在引用的数组</span></span><br><span class="line"><span class="keyword">int</span> (*Parray)[<span class="number">10</span>];              <span class="comment">// Parray指向一个整型数组</span></span><br><span class="line"><span class="keyword">int</span> (&amp;arrRef)[<span class="number">10</span>];              <span class="comment">// arrRef引用一个整型数组</span></span><br></pre></td></tr></table></figure><h2 id="3-5-3-指针和数组"><a href="#3-5-3-指针和数组" class="headerlink" title="3.5.3 指针和数组"></a>3.5.3 指针和数组</h2><p>​    数组类型的对象其实是一个指向该数组首元素的指针。该指针也是一个迭代器。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;3-1-命名空间的-using-声明&quot;&gt;&lt;a href=&quot;#3-1-命名空间的-using-声明&quot; class=&quot;headerlink&quot; title=&quot;3.1 命名空间的 using 声明&quot;&gt;&lt;/a&gt;3.1 命名空间的 using 声明&lt;/h1&gt;&lt;p&gt;​    &lt;
      
    
    </summary>
    
      <category term="C++" scheme="http://a-kali.github.io/categories/C/"/>
    
    
      <category term="C++" scheme="http://a-kali.github.io/tags/C/"/>
    
  </entry>
  
  <entry>
    <title>Kaggle 比赛记录之 SIIM-ACR Pneumothorax Segmentation</title>
    <link href="http://a-kali.github.io/2019/08/21/SIIM%E6%AF%94%E8%B5%9B%E4%B8%AD%E9%81%87%E5%88%B0%E7%9A%84%E7%9F%A5%E8%AF%86%E7%9B%B2%E5%8C%BA/"/>
    <id>http://a-kali.github.io/2019/08/21/SIIM比赛中遇到的知识盲区/</id>
    <published>2019-08-21T14:23:24.000Z</published>
    <updated>2019-09-12T12:35:10.317Z</updated>
    
    <content type="html"><![CDATA[<h1 id="记事"><a href="#记事" class="headerlink" title="记事"></a>记事</h1><p>​    随着 <a href="https://www.kaggle.com/c/siim-acr-pneumothorax-segmentation" target="_blank" rel="noopener">Kaggle: SIIM-ACR Pneumothorax Segmentation</a> 接近尾声，我感觉有必要写一篇 blog 来记录一下这两个月的比赛经历，顺便总结一下经验。</p><p>​    刚开始的时候想着这不过是一场普通CV类的比赛而已，肝一肝就能上金牌。但现实狠狠地打了我的脸。最初三天看了看比赛规则，了解了下RLE等语义分割的基本概念，看了看各路大佬的EDA，算是入了个小门。随后就一直沉沦在MMDetection和COCO格式的配置中，由于网上资料太少太旧，导致我花了整整15天才把程序跑通orz，还是在各路大神的帮助下。详情可参考另一篇博客：<a href="https://a-kali.github.io/2019/08/04/%E4%BD%BF%E7%94%A8MMDetection%E8%BF%9B%E8%A1%8C%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2/#more">使用MMDetection进行语义分割</a>。最后出的结果也非常地不尽人意，分数才 0.6+，而把所有预测结果全填上 -1 都有 0.78 分，着实难搞&#x1F611;。</p><p>​    中间一个月基本在走亲访友旅游摸鱼，直到八月中旬回学校，才重回赛场，放弃了MMDetection，找了个比较高分的<a href="https://www.kaggle.com/rishabhiitbhu/unet-with-resnet34-encoder-pytorch" target="_blank" rel="noopener">PyTorch baseline</a>，开始调参，也算是为这场比赛正式拉开了序幕（虽然只剩半个月了）。</p><p>Baseline细节：</p><ul><li>网络模型：UNet + ResNet34，使用imagenet进行预训练</li><li>输入图片尺寸：512 * 512 （为了更加贴近模型预训练时使用的图片尺寸）</li><li>训练集：验证集 = 4：1，使用 sklearn 中的 StratifiedKFold 进行五折划分</li><li>在验证集和训练集中，正负样本数量1：1</li><li>学习率策略：ReduceLROnPlateau</li><li>Loss：Focal Loss &amp; Dice Loss</li><li>优化器：Adam</li><li>最优模型选择：根据Loss的值进行选择，loss越小模型越优</li><li>生成结果时，单个分割区域的最少像素数：min_size == 3500</li><li>输出：1024*1024 的概率矩阵（因为原数据图像大小是 1024*1024），每个元素对应像素点属于 mask 的概率。最后用一个 sigmoid 函数生成 mask</li></ul><p>虽然是个分数挺高的 baseline，但还是有一些瑕疵：</p><ul><li>某行代码的 ‘!=’ 写成了 ‘==’</li><li>Trainer 类里的部分属性与下面传入函数的参数不是同一个变量，导致改了属性后传入的参数依然没改</li><li>验证时没有加 with torch.no_grad() 导致显存溢出</li><li>对数据去重的时候把单图多分割区域给删成了单图单分割区域</li></ul><p>改完上述问题后单 resnet34 分数能上 0.84+。</p><p>​    改完 bug 后第一步，把模型换成 SENet154 &#x1F60F;，单折 0.855 左右，好像海星的亚子。</p><p>​    随后又测了 SE_ReNeXt101、EfficientUNet_B5、DPN131、DenseNet201、DenseNet121等模型，但只有 EfficientUNet_B5 能跟 SENet154 不相上下，而其他模型基本跟 ResNet34 差不多。</p><p>​    对 SENet154 进行五折交叉验证，分数提高到 0.863。</p><p>​    对 EfficientUNet_B5、ResNet34、SENet154 三模型进行等比例融合、min_size == 3000，分数提高到 0.869。同时 EfficientUNet_B5、SENet154 双模型 、min_size == 2800，分数提高到 0.868。</p><p>​    使用 EfficientNet 单独进行二分类，将二分类中的负样本对应的预测样本替换成负样本，结果不理想，大概多模型融合后的分类能力已经很强了。</p><p>​    对 EfficientUNet_B5、ResNet34、SENet154、SE_ReNeXt101 四模型按 3:2:3:2 的比例进行融合，min_size == 3000，分数提高到 0.8694。</p><p>​    与此同时的另一边使用了 chexnet 进行二分类，将二分类的正样本对应的三模型预测样本的min_size降低到2500，负样本保持3000，将三模型的分数也提升到了 0.8694 。在 public leaderboard 排行60名，位于银牌区。</p><p>​    可是离金牌还有 0.01 分的差距，光是这样调参怕是很难上金牌&#x1F62A;  —— 2019.8.28</p><p>​    比赛进入第二阶段，更换了测试集。以新测试集的 1% 数据的成绩作为公榜成绩，剩下 99% 作为最终成绩。—— 2019.8.31</p><h1 id="盲区"><a href="#盲区" class="headerlink" title="盲区"></a>盲区</h1><p>FocalLoss和diceLoss的实现细节和应用场景</p><p>Unet、Unet++、FastRCNN、MaskRCNN、FPN、DCN、Cascade、SENet、efficientNet的技术细节</p><p>学习率的相关优化算法及应用场景，如ReduceLROnPlateau、warm up</p><p>threshold的调整策略</p><p>PyTorch实战经验不足，baseline的自主编写</p><p>新兴模型复现</p><h1 id="疑问"><a href="#疑问" class="headerlink" title="疑问"></a>疑问</h1><ul><li><p>Q：为什么将训练集中的正负样本划为1：1能提高分数？</p><p>A：能避免模型分类时倾向某一方，减少在分类时出现的错误。</p></li><li><p>Q：代码中最佳模型的评判标准为什么不是iOU而是loss？</p><p>A：因为比赛分数的评判标准是Dice Loss</p></li><li><p>Q：每次五折验证的选择是否相同？</p><p>A：是。StratifiedKFold在随机种子不变的情况下，每次五折交叉验证选择的样本都是相同的。</p></li></ul><h1 id="改进"><a href="#改进" class="headerlink" title="改进"></a>改进</h1><p>下次比赛一定要记录每个模型提交的参数、文件和分数啊啊啊啊，不然最后多模型融合的时候不知道如何分配权重</p><p>通过对比两份分数的高低和csv的差别，是否能确定哪些预测是对的（好像有点场外）</p><p>下次比赛要从头跟到尾，这样能尝试到更多的tips和参数</p><h1 id="高分-Solution"><a href="#高分-Solution" class="headerlink" title="高分 Solution"></a>高分 Solution</h1><h2 id="1st-place-solution"><a href="#1st-place-solution" class="headerlink" title="1st place solution"></a><a href="https://www.kaggle.com/c/siim-acr-pneumothorax-segmentation/discussion/107824" target="_blank" rel="noopener">1st place solution</a></h2><h2 id="2rd-place-solution"><a href="#2rd-place-solution" class="headerlink" title="2rd place solution"></a><a href="https://www.kaggle.com/c/siim-acr-pneumothorax-segmentation/discussion/108009#latest-622580" target="_blank" rel="noopener">2rd place solution</a></h2><h2 id="3rd-place-solution"><a href="#3rd-place-solution" class="headerlink" title="3rd place solution"></a><a href="https://www.kaggle.com/c/siim-acr-pneumothorax-segmentation/discussion/108009#latest-622580" target="_blank" rel="noopener">3rd place solution</a></h2><h2 id="4th-place-solution"><a href="#4th-place-solution" class="headerlink" title="4th place solution"></a><a href="https://www.kaggle.com/c/siim-acr-pneumothorax-segmentation/discussion/108397#latest-624615" target="_blank" rel="noopener">4th place solution</a></h2><h2 id="5th-place-solution"><a href="#5th-place-solution" class="headerlink" title="5th place solution"></a><a href="https://www.kaggle.com/c/siim-acr-pneumothorax-segmentation/discussion/107603#latest-620358" target="_blank" rel="noopener">5th place solution</a></h2><ul><li>基于半监督学习，在网络添加了二分类器。</li><li>网络模型：带有 ASPP 结构的 UNet（ASPP 为 DeepLabV3+中的一种结构）</li><li>Backbone：se50 &amp; se101</li><li>图片尺寸：1024*1024</li><li>优化器：Adam</li><li>损失函数：1024 * BCE(results, masks) + BCE(cls, cls_target)</li><li>半监督学习：mean-teacher[1-2] with NIH Dataset </li></ul><p>mean-teacher 参考资料：</p><p>[1] <a href="https://github.com/CuriousAI/mean-teacher" target="_blank" rel="noopener">https://github.com/CuriousAI/mean-teacher</a><br>[2] <a href="https://arxiv.org/pdf/1703.01780.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1703.01780.pdf</a></p><h2 id="6th-place-solution"><a href="#6th-place-solution" class="headerlink" title="6th place solution"></a><a href="https://www.kaggle.com/c/siim-acr-pneumothorax-segmentation/discussion/107743#latest-620263" target="_blank" rel="noopener">6th place solution</a></h2><ul><li>网络模型<ul><li>EncodingNet (ResNets, 512 and 1024 size)</li><li>UNet (EfficientNet4, se-resnext50, SENet154 with 512, 640 and 1024 sizes)</li></ul></li><li>数据增强：Crops 和 Rotations 类型的增强</li><li>损失函数：BCE + Dice （表示FocalLoss不太好用）</li><li>比起原始尺寸的图像，小尺寸图像会少很多分</li><li>Tricks：<ul><li>在 EncodingNet 使用了 11 种 TTA</li><li>删除了预测结果种面积小的mask</li></ul></li></ul><h2 id="8th-place-solution"><a href="#8th-place-solution" class="headerlink" title="8th place solution"></a><a href="https://www.kaggle.com/c/siim-acr-pneumothorax-segmentation/discussion/107522#latest-619268" target="_blank" rel="noopener">8th place solution</a></h2><ul><li>数据分割：10%分出来用于融合(ensemble)，在剩下90%的数据里进行十折交叉验证</li><li>模型架构：DeepLabV3</li><li>Backbone：使用了组归一化的ResNet50/101 和 ResNeXt50/101</li><li>损失函数：BCE（在所有图像上训练）或者 Dice（只在正样本上训练）</li><li>优化器：Vanilla SGD, momentum 0.9</li><li>训练：<ul><li>batch size 4, 1024 x 1024</li><li>batch size 1, 1280 x 1280</li></ul></li><li>学习率策略：余弦退火，LR 0.01-0.0001</li><li>模型融合：<ul><li>4 个模型使用 Dice 损失函数，在正样本上训练</li><li>8 个模型使用 BCE 损失函数，在所有样本上训练。其中四个作为分类器使用</li><li>Max pixel value was taken as classification score, averaged across 4 models</li><li>Multiplied pixel-level scores from 4 models trained on positives only by this classification score, then averaged</li><li>Final ensemble: multiplied score as above averaged with pixel-level scores based on other 4/8 models trained on all images</li></ul></li><li>TTA：Hflip</li><li>后处理：删除了大小小于2048像素的mask（stage2），stage1中为4096像素</li></ul><p>没起到效果的工作：</p><ul><li>使用了Unet, LinkNet, PSPNet, EncNet, HRNet等架构，但效果没有DeepLab好</li><li>SGD 的效果比 Adam, Adabound 优化器的效果更好</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;记事&quot;&gt;&lt;a href=&quot;#记事&quot; class=&quot;headerlink&quot; title=&quot;记事&quot;&gt;&lt;/a&gt;记事&lt;/h1&gt;&lt;p&gt;​    随着 &lt;a href=&quot;https://www.kaggle.com/c/siim-acr-pneumothorax-segmen
      
    
    </summary>
    
      <category term="计算机视觉" scheme="http://a-kali.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/"/>
    
    
      <category term="计算机视觉" scheme="http://a-kali.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/"/>
    
      <category term="语义分割" scheme="http://a-kali.github.io/tags/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2/"/>
    
      <category term="Kaggle" scheme="http://a-kali.github.io/tags/Kaggle/"/>
    
      <category term="PyTorch" scheme="http://a-kali.github.io/tags/PyTorch/"/>
    
  </entry>
  
  <entry>
    <title>《C++ Primer》 第2章 变量和基本类型</title>
    <link href="http://a-kali.github.io/2019/08/20/%E3%80%8AC-Primer%E3%80%8B-%E7%AC%AC2%E7%AB%A0-%E5%8F%98%E9%87%8F%E5%92%8C%E5%9F%BA%E6%9C%AC%E7%B1%BB%E5%9E%8B/"/>
    <id>http://a-kali.github.io/2019/08/20/《C-Primer》-第2章-变量和基本类型/</id>
    <published>2019-08-20T12:41:12.000Z</published>
    <updated>2019-08-27T15:50:13.718Z</updated>
    
    <content type="html"><![CDATA[<p>数据类型决定了程序中数据和操作的意义。</p><h1 id="2-1-基本内置类型"><a href="#2-1-基本内置类型" class="headerlink" title="2.1 基本内置类型"></a>2.1 基本内置类型</h1><h2 id="2-1-1-算术类型"><a href="#2-1-1-算术类型" class="headerlink" title="2.1.1 算术类型"></a>2.1.1 算术类型</h2><p>​    算术类型分为两类：<strong>整型</strong>（包括字符和布尔型在内）和<strong>浮点型</strong>。</p><h3 id="带符号类型和无符号类型"><a href="#带符号类型和无符号类型" class="headerlink" title="带符号类型和无符号类型"></a>带符号类型和无符号类型</h3><p>​    除去布尔型和扩展的字符型之外，其他整形可以划分为<strong>带符号的</strong>（signed）和<strong>无符号的</strong>（unsigned）。带符号类型可以表示正数、负数或0，而无符号类型则仅能表示大于等于0的值。</p><p>​    类型 int、short、long 和 long long 都是带符号的，通过在这些类型名前添加<strong>unsigned</strong> 就可以得到无符号类型。其中 unsigned int 可以缩写为 unsigned。</p><p>​    与其他整型不同，<strong>字符型</strong>被分为了三种：char、signed char 和 unsigned char。但字符型的表现形式只有两种：带符号型和无符号型，char 的实际表现为哪种又编译器决定。</p><p>​    无符号类型中所有的比特都用来存储值。</p><h2 id="2-1-2-类型转换"><a href="#2-1-2-类型转换" class="headerlink" title="2.1.2 类型转换"></a>2.1.2 类型转换</h2><p>类型所能表示的值的范围决定了转换的过程：</p><ul><li>非布尔 → 布尔：除 0 以外均为 true。</li><li>布尔 → 非布尔：false → 0，true → 1。</li><li>浮点数 → 整数：保留小数点前的部分。</li><li>给无符号数赋值超范围：结果为取模后的余数。</li></ul><h3 id="含有无符号类型的表达式"><a href="#含有无符号类型的表达式" class="headerlink" title="含有无符号类型的表达式"></a>含有无符号类型的表达式</h3><p>​    当一个表达式中既有无符号数又有 int 值时，那个 int 值就会转换成无符号数。若 int 值为负数，则相当于将负数赋值给一个无符号数并运算，会产生意料之外的结果。</p><h2 id="2-1-3-字面值常量"><a href="#2-1-3-字面值常量" class="headerlink" title="2.1.3 字面值常量"></a>2.1.3 字面值常量</h2><p>​    每个字面值常量都对应着一种数据类型，字面值常量的形式和值决定了它的数据类型。</p><h3 id="整型和浮点型字面值"><a href="#整型和浮点型字面值" class="headerlink" title="整型和浮点型字面值"></a>整型和浮点型字面值</h3><p>​    我们可以将<strong>整型字面值</strong>写作十进制数、八进制数和十六进制数的形式。以 0 开头的整数代表八进制数，以 0x 或0X 开头的代表十六进制数。</p><p>​    整型字面值具体的数据类型由它的值和符号决定。默认情况下，十进制字面值的类型是能容纳当前值的最小带符号数类型，而八进制和十六进制字面值既可能是带符号的也可能是无符号的。</p><p>​    <strong>浮点型字面值</strong>表现为一个小数或以科学记数法表示的指数，默认类型为double。</p><h3 id="字符和字符串字面值"><a href="#字符和字符串字面值" class="headerlink" title="字符和字符串字面值"></a>字符和字符串字面值</h3><p>​    由单引号括起来的一个字符称为<strong>字符型字面值</strong>，双引号括起来的零个或多个字符则构成<strong>字符串型字面值</strong>。</p><p>​    字符串字面值的类型实际上是由常量字符构成的数组，编译器在每个字符串的结尾添加一个空字符（’\0’），因此字面值实际长度比它的内容多 1。</p><h3 id="布尔字面值和指针字面值"><a href="#布尔字面值和指针字面值" class="headerlink" title="布尔字面值和指针字面值"></a>布尔字面值和指针字面值</h3><p>​    true 和 false 是<strong>布尔类型的字面值</strong>。</p><h1 id="2-2-变量"><a href="#2-2-变量" class="headerlink" title="2.2 变量"></a>2.2 变量</h1><p>​    <strong>变量</strong>提供一个具名的、可供程序操作的存储空间。C++ 中每个变量都有其数据类型，数据类型决定变量所占内存空间的大小和布局方式等。对 C++ 程序员来说，“变量”和“对象”一般可以互换使用。</p><h2 id="2-2-1-变量定义"><a href="#2-2-1-变量定义" class="headerlink" title="2.2.1 变量定义"></a>2.2.1 变量定义</h2><h3 id="初始值"><a href="#初始值" class="headerlink" title="初始值"></a>初始值</h3><p>​    当对象在创建时获得了一个特定的值，我们说这个对象被<strong>初始化</strong>了。初始化不等同于赋值，赋值的含义是把对象的当前值擦除，以一个新的值替代。</p><h3 id="列表初始化"><a href="#列表初始化" class="headerlink" title="列表初始化"></a>列表初始化</h3><p>初始化问题复杂性，e.g. 定义一个名为 sold 的 int 变量并初始化为 0，以下代码均可实现：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> sold = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">int</span> sold = &#123;<span class="number">0</span>&#125;;</span><br><span class="line"><span class="keyword">int</span> sold&#123;<span class="number">0</span>&#125;;</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">sold</span><span class="params">(<span class="number">0</span>)</span></span>;</span><br></pre></td></tr></table></figure><p>用花括号来初始化变量的形式被称为<strong>列表初始化</strong>。</p><h2 id="2-2-2-变量声明和定义的关系"><a href="#2-2-2-变量声明和定义的关系" class="headerlink" title="2.2.2 变量声明和定义的关系"></a>2.2.2 变量声明和定义的关系</h2><p>​    为了允许把程序拆分成多个逻辑部分来编写，C++语言支持<strong>分离式编译</strong>机制，该机制允许将程序分割为若干个文件，每个文件可被独立编译。</p><p>​    为了支持分离式编译，C++将声明和定义区分开来。<strong>声明</strong>使得名字为程序所知，<font color="red">一个文件如果想使用别处定义的名字则必须包含对那个名字的声明</font>。而<strong>定义</strong>负责创建与名字关联的实体。声明和定义都规定了变量的类型和名字，而并以还包括了申请空间，也可能会为变量赋予初始值。</p><p>​    如果想声明一个变量而非定义，就在变量名前添加<strong>关键字extern</strong>，而且不要显示地初始化变量：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">extern</span> <span class="keyword">int</span> i; <span class="comment">// 声明i而非定义i</span></span><br><span class="line"><span class="keyword">int</span> j;        <span class="comment">// 声明并定义j</span></span><br></pre></td></tr></table></figure><p>​    变量只能被定义一次，但可以被多次声明。如果要在多个文件中使用同一个变量，就必须将声明和定义分离。此时变量的定义必须且只能出现在一个文件中，而其他用到该变量的文件必须且只能对其声明。</p><h1 id="2-3-复合类型"><a href="#2-3-复合类型" class="headerlink" title="2.3 复合类型"></a>2.3 复合类型</h1><p>​    <strong>复合类型</strong>是指基于其他类型定义的类型，其中两种为引用和指针。</p><h2 id="2-3-1-引用"><a href="#2-3-1-引用" class="headerlink" title="2.3.1 引用"></a>2.3.1 引用</h2><p>​    <strong>引用</strong>为对象起了另一个名字，引用类型引用另外一种类型。通过将声明符写成&amp;d的形式来定义引用类型，其中d是声明时的变量名：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> ival = <span class="number">1024</span>;     <span class="comment">// 声明了变量名为ival</span></span><br><span class="line"><span class="keyword">int</span> &amp;refVal = ival;  <span class="comment">// 此时refVal成了该变量的第二个名字</span></span><br></pre></td></tr></table></figure><h2 id="2-3-2-指针"><a href="#2-3-2-指针" class="headerlink" title="2.3.2 指针"></a>2.3.2 指针</h2><p>​    <strong>指针</strong>时“指向”另外一种类型的复合类型。定义指针类型的方法将声明符写成 *d 的形式，其中 d 是变量名。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> ip1, *ip2; <span class="comment">//ip1是int型对象，ip2是指向一个int型对象的指针</span></span><br></pre></td></tr></table></figure><h3 id="获取对象的地址"><a href="#获取对象的地址" class="headerlink" title="获取对象的地址"></a>获取对象的地址</h3><p>​    指针存放某个对象的地址，要想获取该地址，需要使用<strong>取地址符（&amp;）</strong>。</p><h3 id="利用指针访问对象"><a href="#利用指针访问对象" class="headerlink" title="利用指针访问对象"></a>利用指针访问对象</h3><p>​    如果指针指向了一个对象，则允许使用<strong>解引用符（*）</strong>来访问该对象。</p><hr><p>Note：引用声明符&amp;、指针声明符*、取地址操作符&amp;、解引用符* 所代表的含义各不相同。</p><hr><h3 id="空指针"><a href="#空指针" class="headerlink" title="空指针"></a>空指针</h3><p>​    <strong>空指针</strong>不指向任何对象，在试图使用一个空指针之前代码可以首先检查它是否为空。以下是三种等价的生成空指针的方法：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> *p1 = <span class="literal">nullptr</span>;</span><br><span class="line"><span class="keyword">int</span> *p2 = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">int</span> *p3 = <span class="literal">NULL</span>;</span><br></pre></td></tr></table></figure><h3 id="void-指针"><a href="#void-指针" class="headerlink" title="void* 指针"></a>void* 指针</h3><p>​    <strong>void*</strong>指针可用于存放任意对象的地址。但由于我们并不知道这个对象到底是什么类型，也就无法确定能在这个对象上做哪些操作，故不能直接操作void*指针所指的对象。</p><h2 id="2-3-3-理解复合类型的声明"><a href="#2-3-3-理解复合类型的声明" class="headerlink" title="2.3.3 理解复合类型的声明"></a>2.3.3 理解复合类型的声明</h2><p>​    类型修饰符仅仅只是在声明时修饰了变量，并不能作为类型的一部分，且对与该声明语句中的其他变量不产生任何作用。</p><p>​    声明语句中的修饰符没有个数限制。</p><h1 id="2-4-const-限定符"><a href="#2-4-const-限定符" class="headerlink" title="2.4 const 限定符"></a>2.4 const 限定符</h1><p>​    关键字<strong>const</strong>可以对变量的类型加以限定，使得被限定的变量的值在定义之后不能再改变。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> <span class="keyword">int</span> bufSize = <span class="number">512</span></span><br></pre></td></tr></table></figure><p>因为const对象一旦创建后其值就不能再改变，所以const对象必须被初始化。</p><h3 id="对const的引用可能引用一个并非const的对象"><a href="#对const的引用可能引用一个并非const的对象" class="headerlink" title="对const的引用可能引用一个并非const的对象"></a>对const的引用可能引用一个并非const的对象</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> i = <span class="number">42</span>;</span><br><span class="line"><span class="keyword">int</span> &amp;r1 = i;</span><br><span class="line"><span class="keyword">const</span> <span class="keyword">int</span> &amp;r2 = i;</span><br><span class="line">r1 = <span class="number">0</span>;  <span class="comment">// 可以通过r1修改i的值</span></span><br><span class="line">r2 = <span class="number">0</span>;  <span class="comment">// 错误；不能通过r2修改i的值</span></span><br></pre></td></tr></table></figure><h2 id="2-4-3-顶层const"><a href="#2-4-3-顶层const" class="headerlink" title="2.4.3 顶层const"></a>2.4.3 顶层const</h2><p>​    用名词<strong>顶层const</strong>表示指针本身是个常量，而<strong>底层const</strong>表示指针所指的对象是一个常量。当执行对象的拷贝操作时，拷入和拷出的对象必须具有相同的底层const资格，或者两个对象的数据类型必须能够转换。（待考究，p58）</p><h2 id="2-4-4-constexpr-和常量表达式"><a href="#2-4-4-constexpr-和常量表达式" class="headerlink" title="2.4.4 constexpr 和常量表达式"></a>2.4.4 constexpr 和常量表达式</h2><p>​    <strong>常量表达式</strong>是指值不会改变并且在编译过程就能得到计算结果的表达式。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> <span class="keyword">int</span> max_files = <span class="number">20</span>; <span class="comment">// 常量表达式</span></span><br><span class="line"><span class="keyword">int</span> staff_size = <span class="number">28</span>; <span class="comment">// 不是常量表达式</span></span><br><span class="line"><span class="keyword">const</span> <span class="keyword">int</span> sz = get_size(); <span class="comment">// 不是常量表达式，因为要在运行时才能获取到</span></span><br></pre></td></tr></table></figure><h3 id="constexpr-变量"><a href="#constexpr-变量" class="headerlink" title="constexpr 变量"></a>constexpr 变量</h3><p>​    C++11 新标准规定，允许将变量声明为<strong>constexpr</strong>类型以便由编译器来验证变量的值是否是一个常量表达式。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">constexpr</span> <span class="keyword">int</span> sz = size(); <span class="comment">// 只有当size()是一个constexpr函数时才是一条正确的语句</span></span><br></pre></td></tr></table></figure><h3 id="字面值类型"><a href="#字面值类型" class="headerlink" title="字面值类型"></a>字面值类型</h3><h1 id="2-5-处理类型"><a href="#2-5-处理类型" class="headerlink" title="2.5 处理类型"></a>2.5 处理类型</h1><h2 id="2-5-1-类型别名"><a href="#2-5-1-类型别名" class="headerlink" title="2.5.1 类型别名"></a>2.5.1 类型别名</h2><p>​    <strong>类型别名</strong>是一个名字，它是某种类型的同义词。使用类型别名能让复杂的类型名变得简单明了、易于理解和使用。</p><p>​    有两种方法可用于定义类型别名。分别是是使用<strong>关键字 typedef</strong>和<strong>别名声明using</strong>：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="keyword">double</span> wage;</span><br><span class="line"></span><br><span class="line"><span class="keyword">using</span> SI = Sale_item;</span><br></pre></td></tr></table></figure><h2 id="2-5-2-auto-类型说明符"><a href="#2-5-2-auto-类型说明符" class="headerlink" title="2.5.2 auto 类型说明符"></a>2.5.2 auto 类型说明符</h2><p>​    <strong>auto</strong>类型说明符能让编译器替我们去分析表达式所属的类型。</p><h2 id="2-5-3-decltype-类型指示符"><a href="#2-5-3-decltype-类型指示符" class="headerlink" title="2.5.3 decltype 类型指示符"></a>2.5.3 decltype 类型指示符</h2><p>​    类型说明符<strong>decltype</strong>能从表达式的类型推断出要定义的变量的类型，但不使用该表达式的值初始化变量。其作用是选择并返回操作数的数据类型。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">decltype</span>(f()) sum = x; <span class="comment">// 使用f()的返回类型初始化sum变量，而不使用f()的值</span></span><br></pre></td></tr></table></figure><h1 id="2-6-自定义数据结构"><a href="#2-6-自定义数据结构" class="headerlink" title="2.6 自定义数据结构"></a>2.6 自定义数据结构</h1><h2 id="2-6-1-定义-Sales-data-类型"><a href="#2-6-1-定义-Sales-data-类型" class="headerlink" title="2.6.1 定义 Sales_data 类型"></a>2.6.1 定义 Sales_data 类型</h2><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">Sales_data</span> &#123;</span>          <span class="comment">// 关键字struct + 类名</span></span><br><span class="line">    <span class="built_in">std</span>::<span class="built_in">string</span> bookNo;      <span class="comment">// 数据成员</span></span><br><span class="line">    <span class="keyword">unsigned</span> units_sold = <span class="number">0</span>; <span class="comment">// 类内初始值</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="2-6-2-使用-Sales-data-类"><a href="#2-6-2-使用-Sales-data-类" class="headerlink" title="2.6.2 使用 Sales_data 类"></a>2.6.2 使用 Sales_data 类</h2><h3 id="添加-Sales-data-对象"><a href="#添加-Sales-data-对象" class="headerlink" title="添加 Sales_data 对象"></a>添加 Sales_data 对象</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Sales_data data1;</span><br></pre></td></tr></table></figure><h3 id="Sales-data-对象读入数据"><a href="#Sales-data-对象读入数据" class="headerlink" title="Sales_data 对象读入数据"></a>Sales_data 对象读入数据</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">std</span>::<span class="built_in">cin</span> &gt;&gt; data1.bookNO &gt;&gt; data1.units_sold &gt;&gt; price;</span><br></pre></td></tr></table></figure><h2 id="2-6-3-编写自己的头文件"><a href="#2-6-3-编写自己的头文件" class="headerlink" title="2.6.3 编写自己的头文件"></a>2.6.3 编写自己的头文件</h2><p>​    为了确保哥哥文件中类的定义一致，类通常被定义在头文件中，而且类所在头文件的名字应与类的名字一样。头文件通常包含那些被定义一次的实体，如类、const 和 constexpr 变量。</p><h3 id="预处理器概述"><a href="#预处理器概述" class="headerlink" title="预处理器概述"></a>预处理器概述</h3><p>​    <strong>预处理器</strong>是在编译之前执行的一段程序，可以部分地改变我们所写的程序。能确保头文件多次包含仍能安全工作。之前用到的一项预处理器功能是#include。</p><p>​    C++用到的另一项与处理功能是<strong>头文件保护符</strong>，头文件保护符依赖于<strong>预处理变量</strong>。预处理变量有两种状态：已定义和未定义。<strong>#define</strong> 指令把一个名字设定为预处理变量，<strong>#ifdef</strong> 当且仅当变量已经定义是为真，<strong>#ifndef</strong> 仅当变量未定义时为真。检查结果为真时，执行后续操作直至遇到<strong>#endif</strong> 指令为止。</p><p>​    以下代码说明了这些功能如何有效防止重复包含：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">ifndef</span> SALES_DATA_H  <span class="comment">// 如果没有定义SALES_DATA_H预处理变量，则执行以下语句</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> SALES_DATA_H  <span class="comment">// 定义SALES_DATA_H预处理变量</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> Sales_data</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">Sales_data</span> &#123;</span></span><br><span class="line">    <span class="built_in">std</span>::<span class="built_in">string</span> bookNo;</span><br><span class="line">    <span class="keyword">unsigned</span> units_sold = <span class="number">0</span>; </span><br><span class="line">&#125;;</span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br></pre></td></tr></table></figure><p>第一次包含该文件时，SALES_DATA_H 未定义，预处理器顺序执行代码。再次被包含时 SALES_DATA_H 已定义，<code>#ifndef SALES_DATA_H</code> 检查结果为假，编译器将跳过中间语句。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;数据类型决定了程序中数据和操作的意义。&lt;/p&gt;
&lt;h1 id=&quot;2-1-基本内置类型&quot;&gt;&lt;a href=&quot;#2-1-基本内置类型&quot; class=&quot;headerlink&quot; title=&quot;2.1 基本内置类型&quot;&gt;&lt;/a&gt;2.1 基本内置类型&lt;/h1&gt;&lt;h2 id=&quot;2-1-1-
      
    
    </summary>
    
      <category term="C++" scheme="http://a-kali.github.io/categories/C/"/>
    
    
      <category term="C++" scheme="http://a-kali.github.io/tags/C/"/>
    
  </entry>
  
  <entry>
    <title>《C++ Primer》 第1章 开始</title>
    <link href="http://a-kali.github.io/2019/08/19/%E3%80%8AC-Primer%E3%80%8B-%E7%AC%AC1%E7%AB%A0-%E5%BC%80%E5%A7%8B/"/>
    <id>http://a-kali.github.io/2019/08/19/《C-Primer》-第1章-开始/</id>
    <published>2019-08-19T13:36:16.000Z</published>
    <updated>2019-08-19T15:34:41.869Z</updated>
    
    <content type="html"><![CDATA[<h1 id="1-1-编写一个简单的C-程序"><a href="#1-1-编写一个简单的C-程序" class="headerlink" title="1.1 编写一个简单的C++程序"></a>1.1 编写一个简单的C++程序</h1><h2 id="1-1-1-编译、运行程序"><a href="#1-1-1-编译、运行程序" class="headerlink" title="1.1.1 编译、运行程序"></a>1.1.1 编译、运行程序</h2><p>​    术语：<strong>集成开发环境</strong>（Integrated Developed Environment, IDE）</p><h3 id="源程序文件命名约定"><a href="#源程序文件命名约定" class="headerlink" title="源程序文件命名约定"></a>源程序文件命名约定</h3><p>​    大多数编译器要求源码存储在一个或多个文件中，这些程序文件通常被称为<strong>源文件</strong>。常见C++程序源文件后缀有：<strong>cc、cxx、cpp、cp、C</strong>。</p><h3 id="从命令行运行编译器"><a href="#从命令行运行编译器" class="headerlink" title="从命令行运行编译器"></a>从命令行运行编译器</h3><p>​    <code>$ CC prog1.cc</code></p><p>​    其中CC是编译器的名字。编译器生成一个可执行文件。Windows系统将这个可执行文件命名为<strong>prog1.exe</strong>。UNIX系统常命名为<strong>a.out</strong>。</p><h1 id="1-2-初识输入输出"><a href="#1-2-初识输入输出" class="headerlink" title="1.2 初识输入输出"></a>1.2 初识输入输出</h1><p>​    C++语言常用<strong>标准库</strong>来提供IO机制。同时本书中很多示例使用了<strong>iostream库</strong>。该库包含两个<strong>基础类型istream和ostream</strong>，分别表示输入流和输出流。“<strong>流</strong>”（stream）这个术语想表达的是，随着时间的推移，字符是序列生成或消耗的。</p><h3 id="标准输入输出对象"><a href="#标准输入输出对象" class="headerlink" title="标准输入输出对象"></a>标准输入输出对象</h3><p>标准库定义了4个<strong>IO对象：cin、cout、cerr、clog</strong>。</p><h3 id="一个IO库的程序"><a href="#一个IO库的程序" class="headerlink" title="一个IO库的程序"></a>一个IO库的程序</h3><p>​    程序的第一行</p><p>​    <code>#include &lt;iostream&gt;</code></p><p>告诉编译器我们想要使用iostream库。尖括号中的名字指出了一个<strong>头文件</strong>。每个使用标准库设施的程序都必须包含相关的头文件。对于非标准库的头文件，则用双引号包围。</p><h3 id="向流写入数据"><a href="#向流写入数据" class="headerlink" title="向流写入数据"></a>向流写入数据</h3><p>​    表达式</p><p>​    <code>std::cout &lt;&lt; &quot;Enter two numbers: &quot; &lt;&lt; std::endl;</code></p><p>使用了<strong>输出运算符</strong>（<strong>&lt;&lt;</strong>）在标准输出上打印信息。输出运算符接受两个运算对象：右侧的运算对象是要打印的值，左侧的运算对象必须是一个ostream对象。左侧的ostream对象是运算符的运算结果。</p><p>​    该语句使用了两次输出运算符，即第一次运算结果成为了第二个运算符的左侧对象。该语句等同于：</p><p>​    <code>(std::cout &lt;&lt; &quot;Enter two numbers: &quot;) &lt;&lt;# std::endl;</code></p><p>也可以用两条语句表达：</p><p>​    <code>std::cout &lt;&lt; &quot;Enter two numbers: &quot;</code></p><p>​    <code>std::cout &lt;&lt; std::endl;</code></p><h1 id="1-4-控制流"><a href="#1-4-控制流" class="headerlink" title="1.4 控制流"></a>1.4 控制流</h1><h2 id="1-4-3-读取数量不定的输入数据"><a href="#1-4-3-读取数量不定的输入数据" class="headerlink" title="1.4.3 读取数量不定的输入数据"></a>1.4.3 读取数量不定的输入数据</h2><p>​    在预先不知道要对多少个数求和时，就需要<strong>不断读取数据直至没有新的输入为止</strong>：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">while</span> (<span class="built_in">std</span>::<span class="built_in">cin</span> &gt;&gt; value)</span><br><span class="line">    sum += value;</span><br><span class="line"><span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; <span class="string">"Sum is: "</span> &lt;&lt; sum &lt;&lt; <span class="built_in">std</span>::<span class="built_in">endl</span>;</span><br></pre></td></tr></table></figure><p>如果我们输入</p><p>​    <code>3 4 5 6</code></p><p>则程序会输出</p><p>​    <code>Sum is: 18</code></p><p>当我们使用一个istream对象作为条件时，其效果是检测流的状态。如果流时有效的，那么检测成功。当遇到文件结束符或一个无效输入（例如读入值与value定义的类型不相符），istream的状态会变为无效。</p><h3 id="从键盘输入文件结束符"><a href="#从键盘输入文件结束符" class="headerlink" title="从键盘输入文件结束符"></a>从键盘输入文件结束符</h3><p>Windows: Ctrl + Z, Enter</p><p>Unix&amp;MacOS: Ctrl + D</p><h1 id="1-5-类简介"><a href="#1-5-类简介" class="headerlink" title="1.5 类简介"></a>1.5 类简介</h1><p>​    在C++中，我们通过定义一个<strong>类</strong>（class）来定义自己的数据结构。一个类定义了一个类型，以及与其关联的一组操作。每个类实际上都定义了一个新的类型，其类型名就是其类名。</p><p>类/对象可以进行的操作：</p><ul><li>定义该类型的变量。</li><li>用输入、输出运算符读写该类型的对象。</li><li>在同类对象间进行赋值。</li><li>在两个同类对象间进行加法运算。</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;1-1-编写一个简单的C-程序&quot;&gt;&lt;a href=&quot;#1-1-编写一个简单的C-程序&quot; class=&quot;headerlink&quot; title=&quot;1.1 编写一个简单的C++程序&quot;&gt;&lt;/a&gt;1.1 编写一个简单的C++程序&lt;/h1&gt;&lt;h2 id=&quot;1-1-1-编译、运行
      
    
    </summary>
    
      <category term="C++" scheme="http://a-kali.github.io/categories/C/"/>
    
    
      <category term="C++" scheme="http://a-kali.github.io/tags/C/"/>
    
  </entry>
  
  <entry>
    <title>深度学习工程师（吴恩达）——  序列模型</title>
    <link href="http://a-kali.github.io/2019/08/10/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%B7%A5%E7%A8%8B%E5%B8%88%EF%BC%88%E5%90%B4%E6%81%A9%E8%BE%BE%EF%BC%89%E2%80%94%E2%80%94-%E5%BA%8F%E5%88%97%E6%A8%A1%E5%9E%8B/"/>
    <id>http://a-kali.github.io/2019/08/10/深度学习工程师（吴恩达）——-序列模型/</id>
    <published>2019-08-10T06:02:58.000Z</published>
    <updated>2019-08-21T15:50:16.284Z</updated>
    
    <content type="html"><![CDATA[<h1 id="一、循环序列模型"><a href="#一、循环序列模型" class="headerlink" title="一、循环序列模型"></a>一、循环序列模型</h1><h2 id="1-1-为什么选择序列模型"><a href="#1-1-为什么选择序列模型" class="headerlink" title="1.1 为什么选择序列模型"></a>1.1 为什么选择序列模型</h2><p><img src="https://s2.ax1x.com/2019/08/10/eOFH3R.png" alt="序列模型举例"></p><h2 id="1-2-数学符号定义"><a href="#1-2-数学符号定义" class="headerlink" title="1.2 数学符号定义"></a>1.2 数学符号定义</h2><script type="math/tex; mode=display">x^{<n>} \Rightarrow 序列中的第n个符号所对应的向量</script><p><img src="https://s2.ax1x.com/2019/08/10/eOZuwV.png" alt></p><h2 id="1-3-循环神经网络模型（RNN）"><a href="#1-3-循环神经网络模型（RNN）" class="headerlink" title="1.3 循环神经网络模型（RNN）"></a>1.3 循环神经网络模型（RNN）</h2><p>​    由于序列数据每次输入长度相差较大的特性，使其无法适应常规神经网络模型，于是便有了循环神经网络模型。</p><p><img src="https://s2.ax1x.com/2019/08/10/eO1htI.png" alt="eO1htI.png"></p><p>​    循环神经网络每次输入一个词向量，当神经网络读取到x<sup><2></2></sup>的信息时，它也会按照一定权重输入一些来自时间步1的信息，称为a<sup><1></1></sup>；读取x<sup><3></3></sup>时则会输入来自时间步1和2的信息，以此类推。而读取x<sup><1></1></sup>时则需要输入一个自定义的激活值a<sup><0></0></sup>，这个值通常为0。w和b分别表示权重和偏置，为每个时间步所共享。</p><script type="math/tex; mode=display">a^{<t>} = g(w_{aa}a^{<t-1>}+w_{ax}x^{<t>}+b_a)\\\hat y^{<t>} = g(w_{ya}a^{<t>}+b_y)</script><p>​    g(x)为激活函数，通常为tanh，最后得出输出值的激活函数可以为sigmod。</p><p>​    简化方程如下：</p><script type="math/tex; mode=display">a^{<t>} = g(w_{a}[a^{<t-1>},x^{<t>}])\\其中w_a为w_{aa}和w_{ax}的横向拼接，[a^{<t-1>},x^{<t>}]表示a^{<t-1>}和x^{<t>}纵向拼接。</script><p>​    RNN的一个缺点是其只能使用当前输入之前的信息，而没有使用到之后的信息。后续将提到的BRNN将解决这个问题。</p><h2 id="1-4-通过时间的反向传播"><a href="#1-4-通过时间的反向传播" class="headerlink" title="1.4 通过时间的反向传播"></a>1.4 通过时间的反向传播</h2><script type="math/tex; mode=display">损失函数：L^{<t>}(\hat y^{<t>},y^{<t>}) = -y^{<t>}\log \hat y^{<t>}-(1-y^{<t>})\log (1-y^{<t>})\\L^(\hat y^{<t>},y^{<t>}) = \sum_{t=1}^{T_y} L^{<t>}(\hat y^{<t>},y^{<t>})</script><p>即总损失为各时间损失之和。</p><h2 id="1-5-不同类型的循环神经网络"><a href="#1-5-不同类型的循环神经网络" class="headerlink" title="1.5 不同类型的循环神经网络"></a>1.5 不同类型的循环神经网络</h2><ul><li>等长多输入多输出结构，如找出句子中的人名</li><li>多输入单输出结构，如情感分类</li><li>单输入多输出结构，如音乐生成</li><li>非等长多输入多输出结构，如语言翻译</li></ul><p><img src="https://s2.ax1x.com/2019/08/19/mlQIqs.png" alt="mlQIqs.png"></p><h2 id="1-6-语言模型和序列生成"><a href="#1-6-语言模型和序列生成" class="headerlink" title="1.6 语言模型和序列生成"></a>1.6 语言模型和序列生成</h2><p>​    语言模型的训练集由一个巨大的语料库组成，句子中的每个词向量都对应着字典中其所在的位置，句末由\<eos>来表示句子的结束。语料中没有的词向量以\<unk>表示。</unk></eos></p><h2 id="1-7-对新序列采样"><a href="#1-7-对新序列采样" class="headerlink" title="1.7 对新序列采样"></a>1.7 对新序列采样</h2><p>暂时没看懂</p><h2 id="1-8-RNN的梯度消失"><a href="#1-8-RNN的梯度消失" class="headerlink" title="1.8 RNN的梯度消失"></a>1.8 RNN的梯度消失</h2><p>示例：</p><ul><li>The <strong>cat</strong>, which already ate …… <strong>was</strong> full.</li><li>The <strong>cats</strong>, which already ate …… <strong>were</strong> full.</li></ul><p>在这两个句子中，cat的单复数直接决定了后面的谓语使用was还是were。但由于主语和谓语的距离太远，时间的反向传播很难从谓语传播到主语，导致梯度消失，因此网络很难调整前面的计算。</p><h2 id="1-9-Gated-Recurrent-Unit-GRU"><a href="#1-9-Gated-Recurrent-Unit-GRU" class="headerlink" title="1.9 Gated Recurrent Unit (GRU)"></a>1.9 Gated Recurrent Unit (GRU)</h2><p><strong>门控循环单元（GRU）</strong>改变了RNN的隐藏层，使得RNN能更好地捕捉深层次的连接，并改善了梯度消失问题。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;一、循环序列模型&quot;&gt;&lt;a href=&quot;#一、循环序列模型&quot; class=&quot;headerlink&quot; title=&quot;一、循环序列模型&quot;&gt;&lt;/a&gt;一、循环序列模型&lt;/h1&gt;&lt;h2 id=&quot;1-1-为什么选择序列模型&quot;&gt;&lt;a href=&quot;#1-1-为什么选择序列模型&quot; c
      
    
    </summary>
    
      <category term="深度学习" scheme="http://a-kali.github.io/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="深度学习" scheme="http://a-kali.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="吴恩达" scheme="http://a-kali.github.io/tags/%E5%90%B4%E6%81%A9%E8%BE%BE/"/>
    
      <category term="序列模型" scheme="http://a-kali.github.io/tags/%E5%BA%8F%E5%88%97%E6%A8%A1%E5%9E%8B/"/>
    
      <category term="自然语言处理" scheme="http://a-kali.github.io/tags/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/"/>
    
      <category term="笔记" scheme="http://a-kali.github.io/tags/%E7%AC%94%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>使用MMDetection进行语义分割</title>
    <link href="http://a-kali.github.io/2019/08/04/%E4%BD%BF%E7%94%A8MMDetection%E8%BF%9B%E8%A1%8C%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2/"/>
    <id>http://a-kali.github.io/2019/08/04/使用MMDetection进行语义分割/</id>
    <published>2019-08-04T01:53:42.000Z</published>
    <updated>2019-09-01T16:18:08.099Z</updated>
    
    <content type="html"><![CDATA[<p>​    <a href="https://github.com/open-mmlab/mmdetection" target="_blank" rel="noopener">MMDetection</a>是商汤科技开源的用于深度学习目标检测的库，而SIIM-ACR Pneumothorax Segmentation（以下简称SIIM）是发布于Kaggle平台的一个分割气胸所在位置的计算机视觉类竞赛。以下我将以SIIM比赛为例，介绍如何使用MMDetection进行语义分割。</p><h1 id="一、安装MMDetection"><a href="#一、安装MMDetection" class="headerlink" title="一、安装MMDetection"></a>一、安装MMDetection</h1><p>​    安装过程可能会有更新，以官方为准：</p><p>​    <a href="https://github.com/open-mmlab/mmdetection" target="_blank" rel="noopener">https://github.com/open-mmlab/mmdetection</a></p><h2 id="安装准备"><a href="#安装准备" class="headerlink" title="安装准备"></a>安装准备</h2><ul><li>操作系统：Linux</li><li>Python 3.5+</li><li>PyTorch 1.0+ 或 PyTorch-nightly</li><li>CUDA 9.0+</li><li>NCCL 2+</li><li>GCC 4.9+</li></ul><h2 id="安装步骤"><a href="#安装步骤" class="headerlink" title="安装步骤"></a>安装步骤</h2><ol><li><p>创建conda虚拟环境并激活、安装Cython</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">conda create -n open-mmlab python=3.7 -y</span><br><span class="line">conda activate open-mmlab</span><br><span class="line"></span><br><span class="line">conda install cython</span><br></pre></td></tr></table></figure></li><li><p>根据<a href="https://pytorch.org/get-started/locally/" target="_blank" rel="noopener">PyTorch官网</a>中对应的版本在conda的虚拟环境中安装PyTorch stable/nightly和torchvision。<strong>注意需要去掉安装命令中的 -c 参数</strong>（如果有的话），不然下载过程会很慢。</p></li><li><p>在虚拟环境中安装<a href="https://github.com/open-mmlab/mmcv" target="_blank" rel="noopener">mmcv</a>和<a href="https://github.com/philferriere/cocoapi" target="_blank" rel="noopener">cocoapi</a></p></li><li><p>克隆MMDetection并安装</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">git <span class="built_in">clone</span> https://github.com/open-mmlab/mmdetection.git</span><br><span class="line"><span class="built_in">cd</span> mmdetection</span><br><span class="line">python setup.py develop</span><br><span class="line"><span class="comment"># or "pip install -v -e ."</span></span><br></pre></td></tr></table></figure></li></ol><h1 id="二、准备COCO格式数据标注"><a href="#二、准备COCO格式数据标注" class="headerlink" title="二、准备COCO格式数据标注"></a>二、准备COCO格式数据标注</h1><p>   COCO的全称是Common Objects in COntext，是微软团队提供的一个可以用来进行图像识别的数据集。而我们在这次比赛中需要用到的是COCO数据集的标注格式，mmdetection将通过标注来对数据进行训练和测试。</p><p>   COCO数据集现在有5种标注类型：<strong>Object Detection（目标检测）、Keypoint Detection（关键点检测）、 Stuff Segmentation（语义分割）、Panoptic Segmentation（全景分割）和image captions（看图说话）</strong>，使用JSON文件存储。在SIIM比赛中使用的是语义分割。</p><h2 id="基本的JSON结构体类型"><a href="#基本的JSON结构体类型" class="headerlink" title="基本的JSON结构体类型"></a>基本的JSON结构体类型</h2><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">"info"</span>: info,</span><br><span class="line">    <span class="attr">"licenses"</span>: [license],</span><br><span class="line">    <span class="attr">"images"</span>: [image],</span><br><span class="line">    <span class="attr">"annotations"</span>: [annotation],</span><br><span class="line">&#125;</span><br><span class="line">    </span><br><span class="line">info&#123;</span><br><span class="line">    "year": int,</span><br><span class="line">    "version": str,</span><br><span class="line">    "description": str,</span><br><span class="line">    "contributor": str,</span><br><span class="line">    "url": str,</span><br><span class="line">    "date_created": datetime,</span><br><span class="line">&#125;</span><br><span class="line">license&#123;</span><br><span class="line">    "id": int,</span><br><span class="line">    "name": str,</span><br><span class="line">    "url": str,</span><br><span class="line">&#125; </span><br><span class="line">image&#123;</span><br><span class="line">    "id": int,</span><br><span class="line">    "width": int,</span><br><span class="line">    "height": int,</span><br><span class="line">    "file_name": str,</span><br><span class="line">    "license": int,</span><br><span class="line">    "flickr_url": str,</span><br><span class="line">    "coco_url": str,</span><br><span class="line">    "date_captured": datetime,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ol><li>info类型，以下是一个info类型的实例：</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&quot;info&quot;:&#123;</span><br><span class="line">&quot;description&quot;:&quot;This is stable 1.0 version of the 2014 MS COCO dataset.&quot;,</span><br><span class="line">&quot;url&quot;:&quot;http:\/\/mscoco.org&quot;,</span><br><span class="line">&quot;version&quot;:&quot;1.0&quot;,&quot;year&quot;:2014,</span><br><span class="line">&quot;contributor&quot;:&quot;Microsoft COCO group&quot;,</span><br><span class="line">&quot;date_created&quot;:&quot;2015-01-27 09:11:52.357475&quot;</span><br><span class="line">&#125;,</span><br></pre></td></tr></table></figure><ol><li>images是包含多个image实例的数组，以下是一个image类型的实例：</li></ol><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">   <span class="attr">"license"</span>:<span class="number">3</span>,</span><br><span class="line">   <span class="attr">"file_name"</span>:<span class="string">"COCO_val2014_000000391895.jpg"</span>,</span><br><span class="line">   <span class="attr">"coco_url"</span>:<span class="string">"http:\/\/mscoco.org\/images\/391895"</span>,</span><br><span class="line">    <span class="attr">"height"</span>:<span class="number">360</span>,<span class="attr">"width"</span>:<span class="number">640</span>,<span class="attr">"date_captured"</span>:<span class="string">"2013-11-14 11:18:45"</span>,</span><br><span class="line">   <span class="attr">"flickr_url"</span>:<span class="string">"http:\/\/farm9.staticflickr.com\/8186\/8119368305_4e622c8349_z.jpg"</span>,</span><br><span class="line">   <span class="attr">"id"</span>:<span class="number">391895</span></span><br><span class="line">&#125;,</span><br></pre></td></tr></table></figure><ol><li>licenses是包含多个license实例的数组，以下是一个license类型的实例：</li></ol><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line"><span class="attr">"url"</span>:<span class="string">"http:\/\/creativecommons.org\/licenses\/by-nc-sa\/2.0\/"</span>,</span><br><span class="line"><span class="attr">"id"</span>:<span class="number">1</span>,</span><br><span class="line"><span class="attr">"name"</span>:<span class="string">"Attribution-NonCommercial-ShareAlike License"</span></span><br><span class="line">&#125;,</span><br></pre></td></tr></table></figure><p>   info和licenses是不必要的，留空即可。</p><h2 id="Stuff-Segmentation-类型的标注"><a href="#Stuff-Segmentation-类型的标注" class="headerlink" title="Stuff Segmentation 类型的标注"></a>Stuff Segmentation 类型的标注</h2><p>   Stuff Segmentation 的标注格式和 Object Detection 的格式一样，如下：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">"info"</span>: info,</span><br><span class="line">    <span class="attr">"licenses"</span>: [license],</span><br><span class="line">    <span class="attr">"images"</span>: [image],</span><br><span class="line">    <span class="attr">"annotations"</span>: [annotation],</span><br><span class="line">    <span class="attr">"categories"</span>: [category]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>   可以看到segmentation的结构体比通用结构体多了两种类型：annotations和categories。</p><ol><li>annotations字段是包含多个annotation实例的一个数组，annotation类型本身又包含了一系列的字段，如下所示：</li></ol><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">annotation&#123;</span><br><span class="line">    "id": int,    </span><br><span class="line">    "image_id": int,</span><br><span class="line">    "category_id": int,</span><br><span class="line">    "segmentation": RLE or [polygon],</span><br><span class="line">    "area": float,</span><br><span class="line">    "bbox": [x,y,width,height],</span><br><span class="line">    "iscrowd": 0 or 1,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>   在Stuff Segmentation任务中，segmentation的编码为RLE格式，iscrowd为0；area字段为标注覆盖的面积；bbox是一个长度为4的数组，用于表示目标检测的边框，x和y表示边框左上角的坐标，width和height表示边框的宽和高。当编码为RLE格式时，segmentation的格式如下：</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">segmentation : </span><br><span class="line">&#123;</span><br><span class="line">    'counts': [272, 2, 4, 4, 4, 4, 2, 9, 1, 2, 16, 43, 143, 24......], </span><br><span class="line">    'size': [240, 320]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>   size是这张图片的宽高，counts字段的内容为RLE编码。此处举例使用的是uncompressed RLE，做语义分割任务时需编码为compact RLE。可使用pycocotools中的函数生成compact RLE，以下用SIIM中的一个RLE码举例:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> pycocotools.mask <span class="keyword">import</span> encode</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> mask_function <span class="keyword">import</span> rle2mask</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>rle = <span class="string">'407576 2 1021 7 1015 10 1013 12 1011 14 1008 17 1006 19 1005 20 1003 21 1003 22 1001 23 1001 24 999 25 999 25 999 26 997 27 997 27 996 28 996 28 996 29 994 30 994 30 994 30 993 31 993 32 992 32 992 32 992 32 991 33 991 33 991 33 991 33 991 33 990 34 990 34 990 34 990 34 990 34 989 35 989 36 988 36 988 16 1 19 988 15 3 18 988 15 4 16 989 14 8 13 989 14 8 13 989 13 9 13 989 13 9 13 989 12 10 13 989 12 10 13 989 11 11 13 989 11 11 13 989 11 11 13 989 10 11 14 989 10 11 14 990 9 9 16 990 9 7 18 990 9 6 18 991 9 6 18 991 9 5 19 992 8 4 20 992 7 5 20 993 6 4 21 993 6 4 21 994 4 4 22 995 3 5 20 997 2 5 20 1005 19 1006 17 1008 15 1010 12 1015 7'</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>mask = rle2mask(rle, <span class="number">1024</span>, <span class="number">1024</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>mask = mask.T.astype(np.uint8) <span class="comment"># uint8是encode函数参数的指定数值类型</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>segmentation = encode(np.asfortranarray(mask))</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>segmentation</span><br><span class="line">&#123;<span class="string">'size'</span>: [<span class="number">1024</span>, <span class="number">1024</span>], <span class="string">'counts'</span>: <span class="string">b'hP^&lt;2mo05J3N2N2M3N2O1N101N101N10001N100O10001N10000O101O00000O100000000O100000000O101O00\\OUQO3kn0LWQO3in0MXQO1in0N[QOOen01[QOOen00\\QO0dn00\\QO0dn0O]QO1cn0O]QO1cn0N^QO2bn0N^QO2bn0N^QO2bn0M^QO4bn0L^QO4cn0K[QO7en0IYQO9gn0GXQO9in0GWQO9in0GVQO:kn0ETQO&lt;ln0CUQO=ln0BSQO?mn0ASQO?nn0_ORQOb0on0]ORQOa0Po0^OPQOb0Xo0O1N2N2M5KXoYa0'</span>&#125; <span class="comment"># compact RLE</span></span><br></pre></td></tr></table></figure><p>   rle2mask是SIIM比赛官方提供的用于将RLE转化成mask的函数，内容如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">rle2mask</span><span class="params">(rle, width, height)</span>:</span></span><br><span class="line">    mask = np.zeros(width * height)</span><br><span class="line">    array = np.asarray([int(x) <span class="keyword">for</span> x <span class="keyword">in</span> rle.split()])</span><br><span class="line">    starts = array[<span class="number">0</span>::<span class="number">2</span>]</span><br><span class="line">    lengths = array[<span class="number">1</span>::<span class="number">2</span>]</span><br><span class="line"></span><br><span class="line">    current_position = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> index, start <span class="keyword">in</span> enumerate(starts):</span><br><span class="line">        current_position += start</span><br><span class="line">        mask[current_position:current_position+lengths[index]] = <span class="number">255</span></span><br><span class="line">        current_position += lengths[index]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> mask.reshape(width, height)</span><br></pre></td></tr></table></figure><p>   以下是COCO2017的语义分割标注文件中一个完整的annotation:</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">"segmentation"</span>:</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="attr">"counts"</span>:<span class="string">"Q[d04_;3L1O1O2M2O10001O0O10O11O00000000N2N2FkD3\\;Nem[6"</span>,</span><br><span class="line">        <span class="attr">"size"</span>: [<span class="number">371</span>, <span class="number">640</span>]</span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="attr">"area"</span>: <span class="number">257.0</span>,</span><br><span class="line">    <span class="attr">"iscrowd"</span>: <span class="number">0</span>,</span><br><span class="line">    <span class="attr">"image_id"</span>: <span class="number">19042</span>,</span><br><span class="line">    <span class="attr">"bbox"</span>: [<span class="number">56.0</span>, <span class="number">50.0</span>, <span class="number">21.0</span>, <span class="number">16.0</span>],</span><br><span class="line">    <span class="attr">"category_id"</span>: <span class="number">127</span>,</span><br><span class="line">    <span class="attr">"id"</span>: <span class="number">20001212</span></span><br><span class="line">&#125;,</span><br></pre></td></tr></table></figure><ol><li>categories 字段是一个包含多个category实例的数组，表示标注的物体类型，category结构体描述如下：</li></ol><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">"id"</span>: int,</span><br><span class="line">    <span class="attr">"name"</span>: str,</span><br><span class="line">    <span class="attr">"supercategory"</span>: str,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>​    在SIIM的检测目标里只有一种类型，即气胸（Pneumothorax）。于是自定义一种category如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"categories"</span>: [</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="string">'supercategory'</span>: <span class="string">'Pneumothorax'</span>,</span><br><span class="line">        <span class="string">'id'</span>: <span class="number">1</span>,</span><br><span class="line">        <span class="string">'name'</span>: <span class="string">'Pneumothorax'</span></span><br><span class="line">    &#125;</span><br><span class="line">]</span><br></pre></td></tr></table></figure><p>   以上是关于Stuff Segmentation 类型标注的所有内容，接下来就可以自己动手写一个脚本自动生成标注文件了。值得一提的是测试集的标注文件无需annotations字段。</p><p>   准备好的COCO格式数据集按如下形式摆放。官方建议新建一个data文件夹，将数据集放在data文件夹下（建议使用软链接的方式）。生成的标注文件放在annotations文件夹下。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">mmdetection</span><br><span class="line">├── mmdetc</span><br><span class="line">├── tools</span><br><span class="line">├── configs</span><br><span class="line">├── data</span><br><span class="line">│   ├── coco</span><br><span class="line">│   │   ├── annotations</span><br><span class="line">│   │   ├── train2017</span><br><span class="line">│   │   ├── val2017</span><br><span class="line">│   │   ├── test2017</span><br></pre></td></tr></table></figure><p>软连接方式，其中$COCO_ROOT需改为你的coco数据集根目录：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cd mmdetection</span><br><span class="line">mkdir data</span><br><span class="line">ln -s $COCO_ROOT data</span><br></pre></td></tr></table></figure><h1 id="三、训练模型"><a href="#三、训练模型" class="headerlink" title="三、训练模型"></a>三、训练模型</h1><h2 id="修改模型配置文件"><a href="#修改模型配置文件" class="headerlink" title="修改模型配置文件"></a>修改模型配置文件</h2><p>   进入配置文件夹configs，编辑你想使用的模型对应的配置文件。以下以cascade_mask_rcnn_x101_64x4d_fpn_1x.py为例，解释其中几个比较关键的参数：</p>   <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># model settings</span></span><br><span class="line">model = dict(</span><br><span class="line">    type=<span class="string">'CascadeRCNN'</span>,</span><br><span class="line">    num_stages=<span class="number">3</span>,</span><br><span class="line">    pretrained=<span class="string">'open-mmlab://resnext101_64x4d'</span>,</span><br><span class="line">    backbone=dict(</span><br><span class="line">        type=<span class="string">'ResNeXt'</span>,</span><br><span class="line">        depth=<span class="number">101</span>,</span><br><span class="line">        groups=<span class="number">64</span>,</span><br><span class="line">        base_width=<span class="number">4</span>,</span><br><span class="line">        num_stages=<span class="number">4</span>,</span><br><span class="line">        out_indices=(<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>),</span><br><span class="line">        frozen_stages=<span class="number">1</span>,</span><br><span class="line">        style=<span class="string">'pytorch'</span>),</span><br><span class="line">    neck=dict(</span><br><span class="line">        type=<span class="string">'FPN'</span>,</span><br><span class="line">        in_channels=[<span class="number">256</span>, <span class="number">512</span>, <span class="number">1024</span>, <span class="number">2048</span>],</span><br><span class="line">        out_channels=<span class="number">256</span>,</span><br><span class="line">        num_outs=<span class="number">5</span>),</span><br><span class="line">    rpn_head=dict(</span><br><span class="line">        type=<span class="string">'RPNHead'</span>,</span><br><span class="line">        in_channels=<span class="number">256</span>,</span><br><span class="line">        feat_channels=<span class="number">256</span>,</span><br><span class="line">        anchor_scales=[<span class="number">8</span>],</span><br><span class="line">        anchor_ratios=[<span class="number">0.5</span>, <span class="number">1.0</span>, <span class="number">2.0</span>],</span><br><span class="line">        anchor_strides=[<span class="number">4</span>, <span class="number">8</span>, <span class="number">16</span>, <span class="number">32</span>, <span class="number">64</span>],</span><br><span class="line">        target_means=[<span class="number">.0</span>, <span class="number">.0</span>, <span class="number">.0</span>, <span class="number">.0</span>],</span><br><span class="line">        target_stds=[<span class="number">1.0</span>, <span class="number">1.0</span>, <span class="number">1.0</span>, <span class="number">1.0</span>],</span><br><span class="line">        loss_cls=dict(</span><br><span class="line">            type=<span class="string">'CrossEntropyLoss'</span>, use_sigmoid=<span class="literal">True</span>, loss_weight=<span class="number">1.0</span>),</span><br><span class="line">        loss_bbox=dict(type=<span class="string">'SmoothL1Loss'</span>, beta=<span class="number">1.0</span> / <span class="number">9.0</span>, loss_weight=<span class="number">1.0</span>)),</span><br><span class="line">    bbox_roi_extractor=dict(</span><br><span class="line">        type=<span class="string">'SingleRoIExtractor'</span>,</span><br><span class="line">        roi_layer=dict(type=<span class="string">'RoIAlign'</span>, out_size=<span class="number">7</span>, sample_num=<span class="number">2</span>),</span><br><span class="line">        out_channels=<span class="number">256</span>,</span><br><span class="line">        featmap_strides=[<span class="number">4</span>, <span class="number">8</span>, <span class="number">16</span>, <span class="number">32</span>]),</span><br><span class="line">    bbox_head=[</span><br><span class="line">        dict(</span><br><span class="line">            type=<span class="string">'SharedFCBBoxHead'</span>,</span><br><span class="line">            num_fcs=<span class="number">2</span>,</span><br><span class="line">            in_channels=<span class="number">256</span>,</span><br><span class="line">            fc_out_channels=<span class="number">1024</span>,</span><br><span class="line">            roi_feat_size=<span class="number">7</span>,</span><br><span class="line">            num_classes=<span class="number">2</span>,  <span class="comment">#种类的数目+1，+1为背景类。</span></span><br><span class="line">                            <span class="comment">#SIIM比赛中只有一种类即气胸类，所以此处为1+1=2。</span></span><br><span class="line">                            <span class="comment">#下面的num_classes一样</span></span><br><span class="line">            target_means=[<span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>],</span><br><span class="line">            target_stds=[<span class="number">0.1</span>, <span class="number">0.1</span>, <span class="number">0.2</span>, <span class="number">0.2</span>],</span><br><span class="line">            reg_class_agnostic=<span class="literal">True</span>,</span><br><span class="line">            loss_cls=dict(</span><br><span class="line">                type=<span class="string">'CrossEntropyLoss'</span>,</span><br><span class="line">                use_sigmoid=<span class="literal">False</span>,</span><br><span class="line">                loss_weight=<span class="number">1.0</span>),</span><br><span class="line">            loss_bbox=dict(</span><br><span class="line">                type=<span class="string">'SmoothL1Loss'</span>,</span><br><span class="line">                beta=<span class="number">1.0</span>,</span><br><span class="line">                loss_weight=<span class="number">1.0</span>)),</span><br><span class="line">        dict(</span><br><span class="line">            type=<span class="string">'SharedFCBBoxHead'</span>,</span><br><span class="line">            num_fcs=<span class="number">2</span>,</span><br><span class="line">            in_channels=<span class="number">256</span>,</span><br><span class="line">            fc_out_channels=<span class="number">1024</span>,</span><br><span class="line">            roi_feat_size=<span class="number">7</span>,</span><br><span class="line">            num_classes=<span class="number">2</span>,</span><br><span class="line">            target_means=[<span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>],</span><br><span class="line">            target_stds=[<span class="number">0.05</span>, <span class="number">0.05</span>, <span class="number">0.1</span>, <span class="number">0.1</span>],</span><br><span class="line">            reg_class_agnostic=<span class="literal">True</span>,</span><br><span class="line">            loss_cls=dict(</span><br><span class="line">                type=<span class="string">'CrossEntropyLoss'</span>,</span><br><span class="line">                use_sigmoid=<span class="literal">False</span>,</span><br><span class="line">                loss_weight=<span class="number">1.0</span>),</span><br><span class="line">            loss_bbox=dict(</span><br><span class="line">                type=<span class="string">'SmoothL1Loss'</span>,</span><br><span class="line">                beta=<span class="number">1.0</span>,</span><br><span class="line">                loss_weight=<span class="number">1.0</span>)),</span><br><span class="line">        dict(</span><br><span class="line">            type=<span class="string">'SharedFCBBoxHead'</span>,</span><br><span class="line">            num_fcs=<span class="number">2</span>,</span><br><span class="line">            in_channels=<span class="number">256</span>,</span><br><span class="line">            fc_out_channels=<span class="number">1024</span>,</span><br><span class="line">            roi_feat_size=<span class="number">7</span>,</span><br><span class="line">            num_classes=<span class="number">2</span>,</span><br><span class="line">            target_means=[<span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>],</span><br><span class="line">            target_stds=[<span class="number">0.033</span>, <span class="number">0.033</span>, <span class="number">0.067</span>, <span class="number">0.067</span>],</span><br><span class="line">            reg_class_agnostic=<span class="literal">True</span>,</span><br><span class="line">            loss_cls=dict(</span><br><span class="line">                type=<span class="string">'CrossEntropyLoss'</span>,</span><br><span class="line">                use_sigmoid=<span class="literal">False</span>,</span><br><span class="line">                loss_weight=<span class="number">1.0</span>),</span><br><span class="line">            loss_bbox=dict(</span><br><span class="line">                type=<span class="string">'SmoothL1Loss'</span>,</span><br><span class="line">                beta=<span class="number">1.0</span>,</span><br><span class="line">                loss_weight=<span class="number">1.0</span>))</span><br><span class="line">    ],</span><br><span class="line">    mask_roi_extractor=dict(</span><br><span class="line">        type=<span class="string">'SingleRoIExtractor'</span>,</span><br><span class="line">        roi_layer=dict(type=<span class="string">'RoIAlign'</span>, out_size=<span class="number">14</span>, sample_num=<span class="number">2</span>),</span><br><span class="line">        out_channels=<span class="number">256</span>,</span><br><span class="line">        featmap_strides=[<span class="number">4</span>, <span class="number">8</span>, <span class="number">16</span>, <span class="number">32</span>]),</span><br><span class="line">    mask_head=dict(</span><br><span class="line">        type=<span class="string">'FCNMaskHead'</span>,</span><br><span class="line">        num_convs=<span class="number">4</span>,</span><br><span class="line">        in_channels=<span class="number">256</span>,</span><br><span class="line">        conv_out_channels=<span class="number">256</span>,</span><br><span class="line">        num_classes=<span class="number">2</span>,</span><br><span class="line">        loss_mask=dict(</span><br><span class="line">            type=<span class="string">'CrossEntropyLoss'</span>, use_mask=<span class="literal">True</span>, loss_weight=<span class="number">1.0</span>)))</span><br><span class="line"><span class="comment"># model training and testing settings</span></span><br><span class="line">train_cfg = dict(</span><br><span class="line">    rpn=dict(</span><br><span class="line">        assigner=dict(</span><br><span class="line">            type=<span class="string">'MaxIoUAssigner'</span>,</span><br><span class="line">            pos_iou_thr=<span class="number">0.7</span>,</span><br><span class="line">            neg_iou_thr=<span class="number">0.3</span>,</span><br><span class="line">            min_pos_iou=<span class="number">0.3</span>,</span><br><span class="line">            ignore_iof_thr=<span class="number">-1</span>),</span><br><span class="line">        sampler=dict(</span><br><span class="line">            type=<span class="string">'RandomSampler'</span>,</span><br><span class="line">            num=<span class="number">256</span>,</span><br><span class="line">            pos_fraction=<span class="number">0.5</span>,</span><br><span class="line">            neg_pos_ub=<span class="number">-1</span>,</span><br><span class="line">            add_gt_as_proposals=<span class="literal">False</span>),</span><br><span class="line">        allowed_border=<span class="number">0</span>,</span><br><span class="line">        pos_weight=<span class="number">-1</span>,</span><br><span class="line">        debug=<span class="literal">False</span>),</span><br><span class="line">    rpn_proposal=dict(</span><br><span class="line">        nms_across_levels=<span class="literal">False</span>,</span><br><span class="line">        nms_pre=<span class="number">2000</span>,</span><br><span class="line">        nms_post=<span class="number">2000</span>,</span><br><span class="line">        max_num=<span class="number">2000</span>,</span><br><span class="line">        nms_thr=<span class="number">0.7</span>,</span><br><span class="line">        min_bbox_size=<span class="number">0</span>),</span><br><span class="line">    rcnn=[</span><br><span class="line">        dict(</span><br><span class="line">            assigner=dict(</span><br><span class="line">                type=<span class="string">'MaxIoUAssigner'</span>,</span><br><span class="line">                pos_iou_thr=<span class="number">0.5</span>,</span><br><span class="line">                neg_iou_thr=<span class="number">0.5</span>,</span><br><span class="line">                min_pos_iou=<span class="number">0.5</span>,</span><br><span class="line">                ignore_iof_thr=<span class="number">-1</span>),</span><br><span class="line">            sampler=dict(</span><br><span class="line">                type=<span class="string">'RandomSampler'</span>,</span><br><span class="line">                num=<span class="number">512</span>,</span><br><span class="line">                pos_fraction=<span class="number">0.25</span>,</span><br><span class="line">                neg_pos_ub=<span class="number">-1</span>,</span><br><span class="line">                add_gt_as_proposals=<span class="literal">True</span>),</span><br><span class="line">            mask_size=<span class="number">28</span>,</span><br><span class="line">            pos_weight=<span class="number">-1</span>,</span><br><span class="line">            debug=<span class="literal">False</span>),</span><br><span class="line">        dict(</span><br><span class="line">            assigner=dict(</span><br><span class="line">                type=<span class="string">'MaxIoUAssigner'</span>,</span><br><span class="line">                pos_iou_thr=<span class="number">0.6</span>,</span><br><span class="line">                neg_iou_thr=<span class="number">0.6</span>,</span><br><span class="line">                min_pos_iou=<span class="number">0.6</span>,</span><br><span class="line">                ignore_iof_thr=<span class="number">-1</span>),</span><br><span class="line">            sampler=dict(</span><br><span class="line">                type=<span class="string">'RandomSampler'</span>,</span><br><span class="line">                num=<span class="number">512</span>,</span><br><span class="line">                pos_fraction=<span class="number">0.25</span>,</span><br><span class="line">                neg_pos_ub=<span class="number">-1</span>,</span><br><span class="line">                add_gt_as_proposals=<span class="literal">True</span>),</span><br><span class="line">            mask_size=<span class="number">28</span>,</span><br><span class="line">            pos_weight=<span class="number">-1</span>,</span><br><span class="line">            debug=<span class="literal">False</span>),</span><br><span class="line">        dict(</span><br><span class="line">            assigner=dict(</span><br><span class="line">                type=<span class="string">'MaxIoUAssigner'</span>,</span><br><span class="line">                pos_iou_thr=<span class="number">0.7</span>,</span><br><span class="line">                neg_iou_thr=<span class="number">0.7</span>,</span><br><span class="line">                min_pos_iou=<span class="number">0.7</span>,</span><br><span class="line">                ignore_iof_thr=<span class="number">-1</span>),</span><br><span class="line">            sampler=dict(</span><br><span class="line">                type=<span class="string">'RandomSampler'</span>,</span><br><span class="line">                num=<span class="number">512</span>,</span><br><span class="line">                pos_fraction=<span class="number">0.25</span>,</span><br><span class="line">                neg_pos_ub=<span class="number">-1</span>,</span><br><span class="line">                add_gt_as_proposals=<span class="literal">True</span>),</span><br><span class="line">            mask_size=<span class="number">28</span>,</span><br><span class="line">            pos_weight=<span class="number">-1</span>,</span><br><span class="line">            debug=<span class="literal">False</span>)</span><br><span class="line">    ],</span><br><span class="line">    stage_loss_weights=[<span class="number">1</span>, <span class="number">0.5</span>, <span class="number">0.25</span>])</span><br><span class="line">test_cfg = dict(</span><br><span class="line">    rpn=dict(</span><br><span class="line">        nms_across_levels=<span class="literal">False</span>,</span><br><span class="line">        nms_pre=<span class="number">1000</span>,</span><br><span class="line">        nms_post=<span class="number">1000</span>,</span><br><span class="line">        max_num=<span class="number">1000</span>,</span><br><span class="line">        nms_thr=<span class="number">0.7</span>,</span><br><span class="line">        min_bbox_size=<span class="number">0</span>),</span><br><span class="line">    rcnn=dict(</span><br><span class="line">        score_thr=<span class="number">0.05</span>,</span><br><span class="line">        nms=dict(type=<span class="string">'nms'</span>, iou_thr=<span class="number">0.5</span>),</span><br><span class="line">        max_per_img=<span class="number">100</span>,</span><br><span class="line">        mask_thr_binary=<span class="number">0.5</span>),</span><br><span class="line">    keep_all_stages=<span class="literal">False</span>)</span><br><span class="line"><span class="comment"># dataset settings</span></span><br><span class="line">dataset_type = <span class="string">'CocoDataset'</span>  <span class="comment">#数据类型</span></span><br><span class="line">data_root = <span class="string">'data/coco/'</span>  <span class="comment">#数据所在目录</span></span><br><span class="line">img_norm_cfg = dict(</span><br><span class="line">    mean=[<span class="number">123.675</span>, <span class="number">116.28</span>, <span class="number">103.53</span>], std=[<span class="number">58.395</span>, <span class="number">57.12</span>, <span class="number">57.375</span>], to_rgb=<span class="literal">True</span>)</span><br><span class="line">data = dict(</span><br><span class="line">    imgs_per_gpu=<span class="number">2</span>,  <span class="comment">#每块GPU每次所载入的图片</span></span><br><span class="line">    workers_per_gpu=<span class="number">2</span>,</span><br><span class="line">    train=dict(</span><br><span class="line">        type=dataset_type,</span><br><span class="line">        ann_file=data_root + <span class="string">'annotations/instances_train2017.json'</span>, <span class="comment">#标注文件</span></span><br><span class="line">        img_prefix=data_root + <span class="string">'train2017/'</span>, <span class="comment">#训练集所在目录</span></span><br><span class="line">        img_scale=(<span class="number">1024</span>, <span class="number">1024</span>), <span class="comment">#图片宽高</span></span><br><span class="line">        img_norm_cfg=img_norm_cfg,</span><br><span class="line">        size_divisor=<span class="number">32</span>,</span><br><span class="line">        flip_ratio=<span class="number">0</span>,</span><br><span class="line">        with_mask=<span class="literal">True</span>,</span><br><span class="line">        with_crowd=<span class="literal">True</span>,</span><br><span class="line">        with_label=<span class="literal">True</span>),</span><br><span class="line">    val=dict(</span><br><span class="line">        type=dataset_type,</span><br><span class="line">        ann_file=data_root + <span class="string">'annotations/instances_val2017.json'</span>,</span><br><span class="line">        img_prefix=data_root + <span class="string">'train2017/'</span>,</span><br><span class="line">        img_scale=(<span class="number">1024</span>, <span class="number">1024</span>),</span><br><span class="line">        img_norm_cfg=img_norm_cfg,</span><br><span class="line">        size_divisor=<span class="number">32</span>,</span><br><span class="line">        flip_ratio=<span class="number">0</span>,</span><br><span class="line">        with_mask=<span class="literal">True</span>,</span><br><span class="line">        with_crowd=<span class="literal">True</span>,</span><br><span class="line">        with_label=<span class="literal">True</span>),</span><br><span class="line">    test=dict(</span><br><span class="line">        type=dataset_type,</span><br><span class="line">        ann_file=data_root + <span class="string">'annotations/instances_test2017.json'</span>,</span><br><span class="line">        img_prefix=data_root + <span class="string">'test2017/'</span>,</span><br><span class="line">        img_scale=(<span class="number">1024</span>, <span class="number">1024</span>),</span><br><span class="line">        img_norm_cfg=img_norm_cfg,</span><br><span class="line">        size_divisor=<span class="number">32</span>,</span><br><span class="line">        flip_ratio=<span class="number">0</span>,</span><br><span class="line">        with_mask=<span class="literal">True</span>,</span><br><span class="line">        with_label=<span class="literal">False</span>,</span><br><span class="line">        test_mode=<span class="literal">True</span>))</span><br><span class="line"><span class="comment"># optimizer</span></span><br><span class="line">optimizer = dict(type=<span class="string">'SGD'</span>, lr=<span class="number">0.0002</span>, momentum=<span class="number">0.9</span>, weight_decay=<span class="number">0.0001</span>)</span><br><span class="line">optimizer_config = dict(grad_clip=dict(max_norm=<span class="number">35</span>, norm_type=<span class="number">2</span>))</span><br><span class="line"><span class="comment"># learning policy</span></span><br><span class="line">lr_config = dict(</span><br><span class="line">    policy=<span class="string">'step'</span>,</span><br><span class="line">    warmup=<span class="string">'linear'</span>,</span><br><span class="line">    warmup_iters=<span class="number">300</span>, <span class="comment">#预训练迭代次数</span></span><br><span class="line">    warmup_ratio=<span class="number">0.00015</span>,</span><br><span class="line">    step=[<span class="number">8</span>, <span class="number">11</span>])</span><br><span class="line">checkpoint_config = dict(interval=<span class="number">1</span>)</span><br><span class="line"><span class="comment"># yapf:disable</span></span><br><span class="line">log_config = dict(</span><br><span class="line">    interval=<span class="number">50</span>,</span><br><span class="line">    hooks=[</span><br><span class="line">        dict(type=<span class="string">'TextLoggerHook'</span>),</span><br><span class="line">        <span class="comment"># dict(type='TensorboardLoggerHook')</span></span><br><span class="line">    ])</span><br><span class="line"><span class="comment"># yapf:enable</span></span><br><span class="line"><span class="comment"># runtime settings</span></span><br><span class="line">total_epochs = <span class="number">50</span>   <span class="comment">#训练的epoch数，SIIM的训练集较小，故需要多训练几轮</span></span><br><span class="line">dist_params = dict(backend=<span class="string">'nccl'</span>)</span><br><span class="line">log_level = <span class="string">'INFO'</span></span><br><span class="line">work_dir = <span class="string">'./work_dirs/cascade_mask_rcnn_x101_64x4d_fpn_1x'</span> <span class="comment">#模型和日志的存放位置</span></span><br><span class="line">load_from = <span class="literal">None</span>   </span><br><span class="line">resume_from = <span class="literal">None</span>   <span class="comment">#加载checkpoint</span></span><br><span class="line">workflow = [(<span class="string">'train'</span>, <span class="number">1</span>)]</span><br></pre></td></tr></table></figure><h2 id="修改coco数据配置文件"><a href="#修改coco数据配置文件" class="headerlink" title="修改coco数据配置文件"></a>修改coco数据配置文件</h2><p>   编辑mmdet/datasets/coco.py，修改CLASSES。例如SIIM比赛中只有一个Pneumothorax类，则改成如下形式：</p>   <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CLASSES = (<span class="string">'Pneumothorax'</span>,)</span><br></pre></td></tr></table></figure><h2 id="训练模型"><a href="#训练模型" class="headerlink" title="训练模型"></a>训练模型</h2><p>   注意：配置文件中的默认学习率是8个gpu和2个img/gpu(batch size= 8<em>2 = 16)。根据线性缩放规则，如果您使用不同的GPU数目或img/gpu，您需要设置与batch size成比例的学习率。例如，如果4GPUs </em> 2 img/gpu的lr=0.01，那么16GPUs * 4 img/gpu的lr=0.08。</p><h3 id="单GPU训练"><a href="#单GPU训练" class="headerlink" title="单GPU训练"></a>单GPU训练</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python tools/train.py $&#123;CONFIG_FILE&#125;</span><br></pre></td></tr></table></figure><p>可选参数：</p><ul><li>—work_dir ${YOUR_WORK_DIR} ：指定work_dir</li></ul><h3 id="多GPU训练"><a href="#多GPU训练" class="headerlink" title="多GPU训练"></a>多GPU训练</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./tools/dist_train.sh $&#123;CONFIG_FILE&#125; $&#123;GPU_NUM&#125; [optional arguments]</span><br></pre></td></tr></table></figure><p>可选参数：</p><ul><li><code>--validate [k]</code>：训练时每k epochs（默认为1）执行一次验证</li><li><code>--work_dir ${YOUR_WORK_DIR}</code>：指定work_dir</li><li><code>--resume_from ${CHECKPOINT_FILE}</code>：从指定的checkpoint文件开始训练</li></ul><p>对于刚刚配置的环境，我们只需输入如下命令就可以训练啦：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./tools/dist_train.sh configs/cascade_mask_rcnn_x101_64x4d_fpn_1x.py 4 --validate</span><br></pre></td></tr></table></figure><p>训练log</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br></pre></td><td class="code"><pre><span class="line">2019-07-19 11:47:51,271 - INFO - Distributed training: True</span><br><span class="line">2019-07-19 11:47:57,025 - INFO - load model from: open-mmlab://resnext101_64x4d</span><br><span class="line">2019-07-19 11:48:04,712 - WARNING - missing keys in source state_dict: layer3.15.bn1.num_batches_tracked, layer3.4.bn3.num_batches_tracked, layer2.0.bn2.num_batches_tracked, layer3.8.bn3.num_batches_tracked, layer3.12.bn2.num_batches_tracked, layer3.0.downsample.1.num_batches_tracked, layer3.7.bn1.num_batches_tracked, layer1.1.bn2.num_batches_tracked, layer3.2.bn3.num_batches_tracked, layer4.0.downsample.1.num_batches_tracked, layer3.20.bn1.num_batches_tracked, layer3.7.bn3.num_batches_tracked, layer3.15.bn3.num_batches_tracked, layer3.19.bn1.num_batches_tracked, layer3.22.bn3.num_batches_tracked, layer4.2.bn1.num_batches_tracked, layer4.2.bn2.num_batches_tracked, layer4.0.bn3.num_batches_tracked, layer2.1.bn2.num_batches_tracked, layer3.1.bn2.num_batches_tracked, layer3.9.bn2.num_batches_tracked, layer3.3.bn2.num_batches_tracked, layer1.2.bn1.num_batches_tracked, layer1.0.bn2.num_batches_tracked, layer3.11.bn1.num_batches_tracked, layer1.0.bn1.num_batches_tracked, layer2.3.bn1.num_batches_tracked, layer3.16.bn2.num_batches_tracked, layer3.3.bn3.num_batches_tracked, layer3.14.bn1.num_batches_tracked, layer3.12.bn3.num_batches_tracked, layer3.13.bn1.num_batches_tracked, layer3.6.bn2.num_batches_tracked, layer3.18.bn1.num_batches_tracked, layer2.3.bn3.num_batches_tracked, layer3.21.bn2.num_batches_tracked, layer2.2.bn3.num_batches_tracked, layer1.1.bn3.num_batches_tracked, layer3.9.bn1.num_batches_tracked, layer3.20.bn3.num_batches_tracked, layer3.3.bn1.num_batches_tracked, layer3.8.bn1.num_batches_tracked, layer3.0.bn2.num_batches_tracked, layer3.17.bn3.num_batches_tracked, layer3.0.bn3.num_batches_tracked, layer3.18.bn2.num_batches_tracked, layer3.16.bn1.num_batches_tracked, layer3.14.bn2.num_batches_tracked, layer3.16.bn3.num_batches_tracked, layer3.17.bn2.num_batches_tracked, layer4.1.bn2.num_batches_tracked, layer3.22.bn2.num_batches_tracked, layer3.2.bn2.num_batches_tracked, layer3.19.bn3.num_batches_tracked, layer3.0.bn1.num_batches_tracked, layer1.2.bn2.num_batches_tracked, layer4.1.bn3.num_batches_tracked, layer3.12.bn1.num_batches_tracked, layer3.5.bn2.num_batches_tracked, layer2.3.bn2.num_batches_tracked, layer3.11.bn2.num_batches_tracked, layer3.18.bn3.num_batches_tracked, layer3.8.bn2.num_batches_tracked, layer3.17.bn1.num_batches_tracked, layer3.22.bn1.num_batches_tracked, layer3.20.bn2.num_batches_tracked, layer3.11.bn3.num_batches_tracked, layer3.4.bn1.num_batches_tracked, layer2.0.bn1.num_batches_tracked, layer3.1.bn1.num_batches_tracked, layer3.6.bn1.num_batches_tracked, layer2.0.downsample.1.num_batches_tracked, layer4.0.bn2.num_batches_tracked, layer1.2.bn3.num_batches_tracked, layer3.13.bn3.num_batches_tracked, layer3.13.bn2.num_batches_tracked, layer4.1.bn1.num_batches_tracked, bn1.num_batches_tracked, layer3.10.bn3.num_batches_tracked, layer2.1.bn1.num_batches_tracked, layer3.5.bn1.num_batches_tracked, layer3.6.bn3.num_batches_tracked, layer3.19.bn2.num_batches_tracked, layer3.7.bn2.num_batches_tracked, layer2.0.bn3.num_batches_tracked, layer3.15.bn2.num_batches_tracked, layer3.9.bn3.num_batches_tracked, layer3.10.bn2.num_batches_tracked, layer1.1.bn1.num_batches_tracked, layer2.2.bn2.num_batches_tracked, layer2.2.bn1.num_batches_tracked, layer3.5.bn3.num_batches_tracked, layer3.2.bn1.num_batches_tracked, layer3.1.bn3.num_batches_tracked, layer4.2.bn3.num_batches_tracked, layer3.10.bn1.num_batches_tracked, layer3.21.bn1.num_batches_tracked, layer3.21.bn3.num_batches_tracked, layer3.4.bn2.num_batches_tracked, layer2.1.bn3.num_batches_tracked, layer1.0.downsample.1.num_batches_tracked, layer1.0.bn3.num_batches_tracked, layer4.0.bn1.num_batches_tracked, layer3.14.bn3.num_batches_tracked</span><br><span class="line"></span><br><span class="line">loading annotations into memory...</span><br><span class="line">Done (t=0.04s)</span><br><span class="line">creating index...</span><br><span class="line">index created!</span><br><span class="line">loading annotations into memory...</span><br><span class="line">Done (t=0.03s)</span><br><span class="line">creating index...</span><br><span class="line">index created!</span><br><span class="line">loading annotations into memory...</span><br><span class="line">loading annotations into memory...</span><br><span class="line">Done (t=0.05s)</span><br><span class="line">creating index...</span><br><span class="line">index created!Done (t=0.06s)</span><br><span class="line"></span><br><span class="line">creating index...</span><br><span class="line">index created!</span><br><span class="line">loading annotations into memory...</span><br><span class="line">Done (t=0.00s)</span><br><span class="line">creating index...</span><br><span class="line">index created!</span><br><span class="line">loading annotations into memory...</span><br><span class="line">Done (t=0.00s)</span><br><span class="line">creating index...</span><br><span class="line">index created!</span><br><span class="line">2019-07-19 11:48:08,173 - INFO - Start running, host: root@dl-All-Series, work_dir: /home/dl/d/12siim/0715hk/mmdetection/work_dirs/cascade_mask_rcnn_x101_64x4d_fpn_1x</span><br><span class="line">2019-07-19 11:48:08,174 - INFO - workflow: [(&apos;train&apos;, 1)], max: 50 epochs</span><br><span class="line">loading annotations into memory...</span><br><span class="line">Done (t=0.00s)</span><br><span class="line">creating index...</span><br><span class="line">index created!</span><br><span class="line">loading annotations into memory...</span><br><span class="line">Done (t=0.00s)</span><br><span class="line">creating index...</span><br><span class="line">index created!</span><br><span class="line">2019-07-19 11:50:30,248 - INFO - Epoch [1][50/375]      lr: 0.00003, eta: 14:45:23, time: 2.841, data_time: 0.199, memory: 10024, loss_rpn_cls: 0.7045, loss_rpn_bbox: 0.0066, s0.loss_cls: 0.5725, s0.acc: 88.9043, s0.loss_bbox: 0.0005, s0.loss_mask: 2.8232, s1.loss_cls: 0.3224, s1.acc: 74.6172, s1.loss_bbox: 0.0002, s1.loss_mask: 1.6205, s2.loss_cls: 0.1525, s2.acc: 90.1211, s2.loss_bbox: 0.0000, s2.loss_mask: 0.5753, loss: 6.7784</span><br><span class="line">2019-07-19 11:52:41,648 - INFO - Epoch [1][100/375]     lr: 0.00007, eta: 14:09:53, time: 2.628, data_time: 0.045, memory: 10024, loss_rpn_cls: 0.6970, loss_rpn_bbox: 0.0089, s0.loss_cls: 0.2083, s0.acc: 99.7930, s0.loss_bbox: 0.0003, s0.loss_mask: 0.7883, s1.loss_cls: 0.1744, s1.acc: 99.7988, s1.loss_bbox: 0.0001, s1.loss_mask: 0.4091, s2.loss_cls: 0.1105, s2.acc: 99.7949, s2.loss_bbox: 0.0000, s2.loss_mask: 0.2313, loss: 2.6281</span><br><span class="line">2019-07-19 11:54:53,230 - INFO - Epoch [1][150/375]     lr: 0.00010, eta: 13:57:00, time: 2.632, data_time: 0.041, memory: 10024, loss_rpn_cls: 0.6769, loss_rpn_bbox: 0.0073, s0.loss_cls: 0.0545, s0.acc: 99.7344, s0.loss_bbox: 0.0020, s0.loss_mask: 0.6995, s1.loss_cls: 0.0519, s1.acc: 99.7871, s1.loss_bbox: 0.0004, s1.loss_mask: 0.3705, s2.loss_cls: 0.0455, s2.acc: 99.8027, s2.loss_bbox: 0.0000, s2.loss_mask: 0.1762, loss: 2.0847</span><br><span class="line">2019-07-19 11:57:06,704 - INFO - Epoch [1][200/375]     lr: 0.00013, eta: 13:52:23, time: 2.669, data_time: 0.042, memory: 10024, loss_rpn_cls: 0.5973, loss_rpn_bbox: 0.0074, s0.loss_cls: 0.0639, s0.acc: 99.4219, s0.loss_bbox: 0.0106, s0.loss_mask: 0.6261, s1.loss_cls: 0.0481, s1.acc: 99.6797, s1.loss_bbox: 0.0028, s1.loss_mask: 0.3498, s2.loss_cls: 0.0360, s2.acc: 99.7715, s2.loss_bbox: 0.0004, s2.loss_mask: 0.1757, loss: 1.9182</span><br><span class="line">2019-07-19 11:59:20,874 - INFO - Epoch [1][250/375]     lr: 0.00017, eta: 13:49:37, time: 2.684, data_time: 0.039, memory: 10024, loss_rpn_cls: 0.3471, loss_rpn_bbox: 0.0087, s0.loss_cls: 0.0609, s0.acc: 98.8672, s0.loss_bbox: 0.0256, s0.loss_mask: 0.5709, s1.loss_cls: 0.0274, s1.acc: 99.5234, s1.loss_bbox: 0.0066, s1.loss_mask: 0.3234, s2.loss_cls: 0.0211, s2.acc: 99.7559, s2.loss_bbox: 0.0006, s2.loss_mask: 0.1756, loss: 1.5679</span><br><span class="line">2019-07-19 12:01:35,584 - INFO - Epoch [1][300/375]     lr: 0.00020, eta: 13:47:30, time: 2.693, data_time: 0.040, memory: 10024, loss_rpn_cls: 0.1487, loss_rpn_bbox: 0.0081, s0.loss_cls: 0.0710, s0.acc: 98.5605, s0.loss_bbox: 0.0343, s0.loss_mask: 0.5988, s1.loss_cls: 0.0186, s1.acc: 99.4336, s1.loss_bbox: 0.0084, s1.loss_mask: 0.3309, s2.loss_cls: 0.0099, s2.acc: 99.6973, s2.loss_bbox: 0.0013, s2.loss_mask: 0.1713, loss: 1.4013</span><br><span class="line">2019-07-19 12:03:48,274 - INFO - Epoch [1][350/375]     lr: 0.00020, eta: 13:43:39, time: 2.654, data_time: 0.044, memory: 10024, loss_rpn_cls: 0.0949, loss_rpn_bbox: 0.0086, s0.loss_cls: 0.0763, s0.acc: 98.4336, s0.loss_bbox: 0.0383, s0.loss_mask: 0.4798, s1.loss_cls: 0.0180, s1.acc: 99.4102, s1.loss_bbox: 0.0088, s1.loss_mask: 0.2716, s2.loss_cls: 0.0072, s2.acc: 99.6953, s2.loss_bbox: 0.0014, s2.loss_mask: 0.1467, loss: 1.1517</span><br><span class="line">[&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;] 288/286, 7.3 task/s, elapsed: 39s, ETA:     0s</span><br><span class="line"></span><br><span class="line">Loading and preparing results...</span><br><span class="line">DONE (t=0.00s)</span><br><span class="line">creating index...</span><br><span class="line">index created!</span><br><span class="line">Running per image evaluation...</span><br><span class="line">Evaluate annotation type *bbox*</span><br><span class="line">DONE (t=0.18s).</span><br><span class="line">Accumulating evaluation results...</span><br><span class="line">DONE (t=0.04s).</span><br><span class="line"> Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000</span><br><span class="line"> Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.002</span><br><span class="line"> Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000</span><br><span class="line"> Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000</span><br><span class="line"> Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000</span><br><span class="line"> Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000</span><br><span class="line"> Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.002</span><br><span class="line"> Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.005</span><br><span class="line"> Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.005</span><br><span class="line"> Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000</span><br><span class="line"> Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000</span><br><span class="line"> Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.005</span><br><span class="line">Loading and preparing results...</span><br><span class="line">DONE (t=0.01s)</span><br><span class="line">creating index...</span><br><span class="line">index created!</span><br><span class="line">Running per image evaluation...</span><br><span class="line">Evaluate annotation type *segm*</span><br><span class="line">DONE (t=0.19s).</span><br><span class="line">Accumulating evaluation results...</span><br><span class="line">DONE (t=0.04s).</span><br><span class="line"> Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000</span><br><span class="line"> Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000</span><br><span class="line"> Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000</span><br><span class="line"> Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000</span><br><span class="line"> Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000</span><br><span class="line"> Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000</span><br><span class="line"> Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000</span><br><span class="line"> Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.001</span><br><span class="line"> Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.001</span><br><span class="line"> Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000</span><br><span class="line"> Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000</span><br><span class="line"> Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.001</span><br></pre></td></tr></table></figure><h2 id="测试模型"><a href="#测试模型" class="headerlink" title="测试模型"></a>测试模型</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># single-gpu testing</span></span><br><span class="line">python tools/test.py <span class="variable">$&#123;CONFIG_FILE&#125;</span> <span class="variable">$&#123;CHECKPOINT_FILE&#125;</span> [--out <span class="variable">$&#123;RESULT_FILE&#125;</span>] [--<span class="built_in">eval</span> <span class="variable">$&#123;EVAL_METRICS&#125;</span>] [--show]</span><br><span class="line"></span><br><span class="line"><span class="comment"># multi-gpu testing</span></span><br><span class="line">./tools/dist_test.sh <span class="variable">$&#123;CONFIG_FILE&#125;</span> <span class="variable">$&#123;CHECKPOINT_FILE&#125;</span> <span class="variable">$&#123;GPU_NUM&#125;</span> [--out <span class="variable">$&#123;RESULT_FILE&#125;</span>] [--<span class="built_in">eval</span> <span class="variable">$&#123;EVAL_METRICS&#125;</span>]</span><br></pre></td></tr></table></figure><p>可选参数：</p><ul><li><code>RESULT_FILE</code>： 用于存放测试结果的pickle格式的文件名，若没有指定这个参数，最终结果将不会输出到文件里。</li><li><code>EVAL_METRICS</code>：需要评估的类型，可选选项有： <code>proposal_fast</code>, <code>proposal</code>, <code>bbox</code>, <code>segm</code>, <code>keypoints</code>.</li><li><code>--show</code>：若指定了该参数，检测结果将在新窗口中以图片形式显示出来。（只能用于单GPU测试。）</li></ul><p>对于测试数据集，我们输入了如下命令：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./tools/dist_test.sh configs/cascade_mask_rcnn_x101_64x4d_fpn_1x.py work_dirs/cascade_mask_rcnn_x101_64x4d_fpn_1x/epoch_50.pth 4 --<span class="built_in">eval</span> segm</span><br></pre></td></tr></table></figure><p>由于指定了 —eval 为 segm，最终的预测结果会输出到result.pkl.segm.json文件里。</p><p>参考文献：</p><ul><li>MMDetection官方文档：<a href="https://github.com/open-mmlab/mmdetection" target="_blank" rel="noopener">https://github.com/open-mmlab/mmdetection</a></li><li>COCO官方：<a href="http://cocodataset.org/#format-data" target="_blank" rel="noopener">http://cocodataset.org/#format-data</a></li><li>COCO数据集的标注格式：<a href="https://zhuanlan.zhihu.com/p/29393415" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/29393415</a></li><li>mmdetection训练自己的数据：<a href="https://blog.csdn.net/qq_36302589/article/details/86149293" target="_blank" rel="noopener">https://blog.csdn.net/qq_36302589/article/details/86149293</a></li><li>mmdetection的configs中的各项参数具体解释：<a href="https://blog.csdn.net/hajlyx/article/details/85991400" target="_blank" rel="noopener">https://blog.csdn.net/hajlyx/article/details/85991400</a></li><li>以及各路大佬的答疑解惑</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;​    &lt;a href=&quot;https://github.com/open-mmlab/mmdetection&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;MMDetection&lt;/a&gt;是商汤科技开源的用于深度学习目标检测的库，而SIIM-ACR Pne
      
    
    </summary>
    
      <category term="计算机视觉" scheme="http://a-kali.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/"/>
    
    
      <category term="计算机视觉" scheme="http://a-kali.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/"/>
    
      <category term="语义分割" scheme="http://a-kali.github.io/tags/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2/"/>
    
      <category term="Kaggle" scheme="http://a-kali.github.io/tags/Kaggle/"/>
    
      <category term="深度学习" scheme="http://a-kali.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="PyTorch" scheme="http://a-kali.github.io/tags/PyTorch/"/>
    
      <category term="MMDetection" scheme="http://a-kali.github.io/tags/MMDetection/"/>
    
      <category term="COCO" scheme="http://a-kali.github.io/tags/COCO/"/>
    
  </entry>
  
</feed>
